[["index.html", "R을 이용한 통계 분석 (개정판) 일러두기", " R을 이용한 통계 분석 (개정판) 김길환 2023-03-13 일러두기 이 책은 “경영통계분석실습” 과목의 교재로 사용하기 위해 제작되었습니다. 본 강의 이외의 목적으로 사용하시는 것은 저자의 허가가 필요합니다. "],["ch-statisics.html", "Chapter 1 통계 분석이란? 1.1 기술통계 분석 1.2 추론통계 분석 1.3 통계 분석의 절차 1.4 통계 데이터에서 변수의 종류", " Chapter 1 통계 분석이란? 오늘날을 지식정보화 시대라고 자주 일컫는다. 지식정보화 시대는 다음과 같은 특징을 가진다. 사회경제적 측면에서는 사회경제 시스템이 매우 복잡짐에 따라 시스템을 이해하고 적절하게 의사결정하기 위해서 시스템에 대한 자세하고 다양한 데이터를 신속하게 획득하고 처리할 필요성이 증대된다. 기술적 측면에서는 정보 기술의 발전이 데이터을 손쉽고 빠르게 처리할 수 있는 하부구조를 제공해 준다. 따라서 오늘날의 모든 조직에게는 조직 내외부의 데이터를 신속히 처리하여 자신에게 필요한 정보와 지식을 빨리 추출해낼 수 있는 역량이 요구된다. 최근 회자되고 있는 ’빅데이터 분석(big data analysis)’은 이러한 사회경제적, 기술적 추세를 대변한다. 통계 데이터 분석은 수집된 데이터를 이용하여 유용한 정보를 뽑아내는 행위이다. 통계 데이터 분석은 크게 기술통계 분석(descriptive statistics analysis)과 추론통계 분석(inferential statistics analysis)으로 구분된다. Table 1.1: 과목 수강생 데이터 일부 major grade gender class mid final hw scores 16 ME 2-year F class-1 46 45 88.30 63.79 17 ME 2-year F class-1 53 68 82.80 71.14 18 ME 2-year F class-1 46 53 84.30 64.99 19 ME 2-year F class-1 83 91 88.30 88.69 20 ME 2-year M class-1 55 56 91.00 70.59 21 ME 2-year F class-1 74 81 91.00 83.79 22 ME 2-year F class-1 36 41 91.00 60.39 23 Others 3-year F class-2 92 88 83.26 88.31 24 Others 4-year F class-2 75 67 91.33 80.00 25 Others 3-year M class-2 88 65 84.00 81.10 26 ME 4-year M class-2 88 81 88.59 87.28 27 ME 3-year M class-2 93 95 88.96 93.09 28 ME 3-year M class-2 90 88 90.59 90.58 29 ME 2-year M class-2 36 52 81.19 60.09 30 ME 3-year M class-2 41 67 81.56 66.87 31 ME 2-year M class-2 49 50 82.67 64.50 32 ME 2-year M class-2 67 61 88.96 75.09 33 ME 2-year M class-2 41 60 88.96 66.99 34 ME 2-year M class-2 84 74 74.15 79.64 35 ME 2-year M class-2 38 45 76.22 57.77 1.1 기술통계 분석 기술통계(descriptive statistics) 분석은 모집단의 특성을 분석자가 한눈에 파악할 수 있도록 데이터를 정리하고 표현하는 방법이다. 표 1.1처럼 한 강의를 수강하고 있는 20명의 학생의 명단이 있다고 하자. 이 명단을 훑어보는 것만으로 20명의 학생들의 특성을 파악하기는 어렵다. 만약 20명의 학생들의 남녀 분포에 대한 표가 주어져 있고 (표 1.2), 학년별 분포 및 전공 분포에 대한 막대그래프가 그려져 있다면 (그림 1.1), 강의를 듣는 학생의 특성을 좀 더 쉽게 파악할 수 있을 것이다. Table 1.2: 성별 분포 gender count F 8 M 12 Figure 1.1: 수강생 학년 및 전공 분포 기술통계 분석은 이와 같이 모집단으로부터 수집된 데이터를 잘 요약하여 모집단에 대하여 유용한 정보를 생산한다. 기술통계 분석에서는 데이터를 그래프, 표 또는 대표값을 나타내는 숫자(통계량)로 요약한다. 우리는 실생활에서 많은 기술통계 분석 자료를 접할 수 있다. 물가지표, 실업률, GDP 등의 경제통계치, 여론 조사 결과를 그래프나 표 등으로 표현하는 것이 기술통계 분석의 대표적인 예라고 할 수 있다. 기술통계 분석에서 주의할 점은 수많은 데이터를 몇 개의 통계치로 요약하는 과정에서 단순화에 따른 정보의 손실이 발생할 수 밖에 없으며, 분석자의 관심에 따라 데이터를 요약하는 방식이 달라질 수 밖에 없다는 것이다. 그러므로 모든 기술통계 분석에는 어느 정도의 정보의 편향과 한계가 내재한다. 그러므로 기술통계 분석을 하거나 기술통계 분석 자료를 이용할 때는 기술통계량의 특성과 한계를 잘 이해하고 있어야 한다. 그래야만 통계에 근거한 올바른 의사결정을 할 수 있다. 1.2 추론통계 분석 추론통계(inferential statistics) 분석은 관심의 대상이 되는 전체집단(모집단)에 대한 조사가 불가능하거나 비효율적일 때 모집단의 일부(표본)만을 관측하여 모집단의 특성을 어림짐작(추측)하는 분석 방법이다. 조사된 표본을 이용하여 모집단에 대해 추측을 하는 것이므로 추측통계라고도 한다. 다음은 추론통계 분석이 사용되는 대표적인 사례이다. 여론조사나 정당의 지지도 조사 등이 있다. 이 경우 유권자 전체의 의견을 묻는 것은 많은 비용이 발생하므로 일정 수의 유권자에게만 의견을 물어 전체 유권자의 의견이나 지지도를 추측한다. 의약품의 임상시험도 의약품의 안전성과 유효성을 모든 환자에게 투약하여 확인하는 것은 위험하므로 일정 수의 자원자에게 먼저 의약품을 투여햐여 안정성과 효과성을 추측한다. 야생동물 보호구역에서의 사자의 개체수 추정 등도 추론통계 분석의 대표적인 사례이다. 실제 모든 사자를 관측할 수 없으므로 일부 관측된 사자의 개체수로 전체 사자 개체 수를 짐작하는 방법을 이용한다. Figure 1.2: 추론통계 개념도 그림 1.2는 모집단과 표본, 그리고 추론통계와 기술통계의 역할이 무엇인지 보여준다. 추론통계 분석에서는 모집단의 일부만을 관측하므로 관측된 표본의 통계치(여론 조사에서 국정 지지도)가 모집단의 실제 통계치(국민의 실제 국정 지지도)와 똑같을 수는 없으며 어느 정도 차이가 발생한다. 따라서 추측통계치를 기반으로 의사결정을 하려면 이러한 추측 통계량의 신뢰성에 대한 판단이 필요하다. 즉, 추측한 값과 실제 값이 어느 정도 차이가 날 수 있는지에 대한 판단이 필요한다. 이를 판단하기 위해서는 모집단에서 표본을 뽑는 경우에 따라 표본 통계량이 확률적으로 어떻게 분포하는지에 대한 탐구가 필요하다. 그렇기 때문에 추론통계 분석은 확률 이론을 기반으로 하고 있다. Figure 1.3: 통계분석의 분분류 그림 1.3은은 지금까지 설명한 기술통계 분석과 추론통계 분석의 분류를 보여준다. 기술통계는 주로 모집단의 정보를 표, 그래프, 통계치로 요약하고, 추론통계는 모집단에 대한 가설을 통계적으로 검정하거나, 모집단의 통계치를 추정한다. 1.3 통계 분석의 절차 통계 분석에서는 그림 1.4와 같이 여러 단계를 거쳐 작업이 수행된다. Figure 1.4: 통계 분석의 단계 1.3.1 문제 정의 모든 통계 분석은 해결하고자 하는 문제의 정의로부터 시작된다. 분석의 목적 및 목표, 분석의 범위, 분석 결과 활용 방안, 분석 고려사항 등이 정의된다. 이 단계가 무시되거나 제대로 수행되지 않으면, 실제적인 의미가 없는 분석 결과가 도출된다. 1.3.2 데이터 수집 분석하고자 하는 문제가 잘 정의되었으면 분석에 필요한 데이터의 수집이 필요하다. 데이터의 수집 단계에서는 다음 작업이 수행된다. 데이터 명세: 분석에 필요한 데이터 항목을 정의한다. 데이터 수집 계획: 데이터 항목 별로 수집 방법, 수집 범위와 양, 수집 일정을 설계한다. 일반적으로 조사 방법론이나 실험 계획법 등을 참고하여 체계적인 절차에 따라 데이터 수집 방안을 설계한다. 데이터 수집 실행: 데이터 수집 계획에 따라 데이터 수집을 수행한다. 1.3.3 데이터 전처리 및 탐색 데이터가 수집되었으면 데이터를 전처리(pre-processing)하고 탐색한다. 데이터 전처리란 데이터를 분석에 맞도록 데이터를 변환하거나 데이터의 문제를 수정(정제)하는 작업을 의미한다. 데이터 변환: 일반적으로 수집된 데이터는 분석에 적합한 형태가 아니기 때문에 분석에 적합하도록 데이터를 결합, 분리, 변형하는 작업이 필요하다. 데이터 정제: 아울러 수집된 데이터에 문제가 없는지 탐색해 보아야 한다. 데이터가 소규모인 경우에는 데이터 사례를 하나씩 살펴볼 수도 있지만, 대부분의 경우 데이터의 규모가 매우 크므로 기술통계 방법을 사용하여 데이터를 요약하거나 그래프로 나타내어 데이터 문제를 살펴본다. 주로 데이터의 이상치, 결측치 등을 살펴보고 적절한 방법으로 데이터의 문제를 수정(정제)한다. 데이터 탐색: 다양한 기술통계 방법으로 데이터를 여러 측면에서 요약해 봄으로써, 해결하고자 하는 문제와 수집된 데이터에 대한 직관적 이해를 도모한다. 데이터 탐색을 통해 변수들의 분포 및 변환 필요성을 파악하고, 변수 간의 상관성을 탐색한다. 이러한 분석을 통해서 데이터에서 중요한 변수가 무엇인지 결정할 수 있고, 해결하고자 하는 문제를 적절히 설명 또는 예측할 수 있는 통계 모형 무엇인지에 대한 통찰을 얻게 된다. 데이터를 깊이 탐색하면 통계 모형에서는 확인할 수 없는 데이터 자체가 말해주는 문제에 대한 깊은 이해에 도달할 수 있다. 그림 1.5은 자동차의 속도와 제동 거리 데이터를 그래프를 이용하여 탐색한 결과이다. Figure 1.5: 동일한 데이터에 대한 세 가지 통계 모형 데이터에 대한 전처리 및 탐색은 순차적으로 한 번에 완료되기 보다는 순환적으로 여러 번 반복되는 과정이다. 데이터 전처리와 탐색 과정에서 얻어진 관찰과 통찰에 의해 데이터를 다시 수집하거나 데이터를 변형하는 작업이 반복될 수 있다. 또한 통계 모형 수립 단계에서 얻어진 통찰에 의해 다시 데이터를 수집과 전처리 및 탐색 과정이 반복될 수도 있다. 1.3.4 통계 모형 수립 단순한 문제들은 데이터에 한두 개의 변수만 있지만, 복잡한 문제의 경우 데이터에 수십에서 수십만 개의 변수가 존재한다. 한두 개의 변수만 가진 문제는 데이터 탐색만으로도 변수들 사이의 관계를 쉽게 확인할 수 있지만, 변수가 많아지면 변수들 사이의 관계를 체계적으로 파악할 수 있는 방법이 필요하다. 또한 변수의 수가 한두 개더라도 변수들 간의 상관성의 정도를 수치화하거나 상관성의 신뢰도를 추정하려고 한다면 이를 파악할 수 있는 방법도 필요하다. 통계 모형(statistical models)은 분석의 목적이 되는 변수와 다른 변수들의 관계를 수학적으로 모형화함으로써 목적 변수의 변화를 설명하거나 예측한다. 예를 들어 코로나19의 치사율이 높은 사람과 그렇지 않은 사람을 예측하여 치사 가능성 높은 사람에게 별도의 처방을 한다고 해보자. 이 문제에서 우리가 분석하고자 하는 목적이 되는 변수는 치사율이다. 만약에 치사율에 영향을 주는 다른 변수로 환자의 나이 하나만을 고려한다고 해 보자. 그러면 환자의 나이와 치사율의 관계의 유무는 산점도라는 그래프를 그려보면 쉽게 확인해 볼 수 있다. 그러나 환자의 나이가 치사율에 영향을 주는 정도를 수치화하거나 이 관계의 신뢰도를 확인하려고 한다면 두 변수의 관계를 수학적으로 정의한 통계적 모형이 필요하다. 아울러 치사율을 예측하기 위하여 환자의 나이뿐 아니라, 성별, 체중, 당뇨병 유무, 기관지 질환 여부, 유전적 특징 등도 함께 조사하였다고 하자. 목적 변수인 치사율과 관계된 변수들이 많고 이 변수들 간의 양과 음의 시너지 효과까지 같이 고려한다면, 이 변수들과 목적 변수의 관계를 그래프만으로 파악하는 것은 매우 어려워진다. 이러한 경우에 사용할 수 있는 것이 통계 모형이다. Figure 1.6: 동일한 데이터에 대한 세 가지 통계 모형 그런데 목적 변수와 설명 변수의 관계를 수학적으로 모형화하는 방법은 무한히 많다. 설명 변수와 목적 변수가 선형적인 관계만 있다고 가정하여 모형화할 수도 있고, 변수들 사이에 복잡합 비선형 관계가 있다고 가정하여 모형화 할 수도 있다. 설명 변수 중에서 중요한 일부만 추려서 모형을 만들 수도 있고, 모든 설명 변수를 다 사용하여 모형을 만들 수도 있다. 이러한 수많은 가능한 모형들 중에서 가장 적합한 모형은 문제마다 다를 수 있다. 어떤 문제의 경우에는 소수 변수만 사용된 단순한 선형 모형이 데이터를 가장 잘 설명할 수도 있고, 다른 경우에는 모든 변수가 이용되는 복잡한 비선형 모형이 데이터를 가장 잘 예측할 수도 있다. 그렇기 때문에 여러 개의 가능한 모형을 선택하여 데이터를 적합해 보고 그 중 데이터에 가장 잘 적합되는 모형을 최종 모형으로 선택하게 된다.1 그러나 무수히 많은 가능한 모형을 모두 데이터에 적합하는 것은 너무나 많은 분석 시간이 소요되므로 현실적이지도 않고 효율적이지도 않다. 그러므로 문제에 가장 적합한 수~수십 개의 모형으로 제한하여 모형을 생성하게 된다. 따라서 데이터 탐색의 과정을 통해 변수들의 분포와 관계를 탐색해 보고, 어떤 모형을 적합해 보는 것이 가장 적절한지 판단해야 한다. 그림 1.6은 자동차의 속도와 제동 거리의 관계를 세 가지 다른 통계 모형으로 적합해 본 결과이다. 통계 모형을 수립하는 과정은 만족스러운 최종 모형은 얻을 때까지 다음 세 작업을 반복하는 과정이다. 모형 정의: 목적 변수와 설명 변수의 수학적 관계를 정의한다. 모형 적합: 정의된 통계 모형을 수집된 데이터에 적합시킨다. 일반적으로 통계 모형은 설명 변수와 목적 변수의 관계를 나타내는 모수(parameters)가 있고, 통계 모형의 적합은 데이터를 가장 잘 설명할 수 있도록 이 모수를 조정하는 과정이다. 모형 평가: 적합된 모형이 얼마나 데이터를 잘 설명하는지 또는 예측하는지 평가해 본다. 정량적인 평가 척도를 가지고 모형의 적합성을 평가하는 것뿐만 아니라, 모형과 실제 데이터의 차이를 탐색하여 모형의 핵심 가정이 만족되는지 등을 살펴보아야 한다. 모형이 데이터를 잘 적합하지 못하면 오차의 이유를 탐색하고 오차를 줄이기 위해 모형에 반영되어야 하는 요소가 무엇인지를 판단하여 새로운 모형을 정의하여 앞의 과정을 반복해 나간다. 1.3.5 결론 도출 데이터에 대한 탐색적 분석과 통계 모형 수립에서 획득된 결과를 이용하여 문제에 대한 결론을 도출한다. 탐색적 분석과 통계 모형 수립에서 얻어진 문제에 대한 핵심 관찰 사실을 정리한다. 통계 분석에서 얻어진 결론과 기존에 알려진 지식들의 동일한 점과 상이한 점을 비교 분석하고, 차이가 있다면 왜 발생했는지 논의한다. 통계 분석을 통해서 얻어진 통찰을 문제 해결에 어떻게 이용할지 논의한다. 추후에 보강하거나 발전시켜야 할 통계 분석 문제가 무엇인지 논의한다. 이 책에서는 데이터 탐색과 통계 모형 수립 단계를 중심으로 통계 분석을 논의한다. 이는 책 하나에 통계 분석의 전 과정을 담기 어렵기 때문이기도 하거니와, 문제 정의, 데이터 수집, 결론 도출 단계는 문제마다 매우 다르기 때문에 정형화된 방식으로 설명하기 어렵기 때문이다. 그러므로 이 책에 다루지 않은 다른 단계들은 덜 중요하기 때문인 것으로 착각하는 것은 곤란하다. 사실 실제 통계 분석의 성패는 정확한 문제 정의와 좋은 품질의 데이터를 수집하는 것에 더 많이 달려 있다. 그리고 이러한 단계에 투여되는 시간과 비용이 더 큰 경우가 많다. 아울러 데이터 전처리는 통계 분석에서 많은 시간이 소요되는 단계이고 중요한 작업이지만 데이터를 다루는 소프트웨어(R 등의 프로그래밍 언어나 엑셀 등)를 다루는 기술이 필요한 분야이다. 이에 대해서는 저자의 별도의 책 R 프로그래밍에서 다루고 있으니 관련 문헌을 참조하기 바란다. 그러므로 이 책에서는 데이터에 대한 수집과 전처리가 잘 수행되어서 통계 분석에 적합한 형태로 이미 준비되었다는 가정 하에 데이터를 통계적으로 탐색하고 통계 모형을 수립하는 방법에 대해서 주로 다루고자 한다. 1.4 통계 데이터에서 변수의 종류 통계 데이터는 일반적으로 표 표 1.1나 그림 1.7과 같이 행과 열로 구성된 행렬 형식으로 구성된다. Figure 1.7: 일반적인 통계 데이터 형식 데이터 행렬에서 행은 일반적으로 하나의 관측 대상에 대한 정보로 구성된다. 표 1.1에서는 행은 한 학생에 대한 정보이다. 그래서 행을 ‘관측(observation)’이라고 한다. 데이터마이닝(data mining)이나 기계학습(machine learning) 등에서는 데이터의 한 행은 ’사례(instances)’ 또는 ’예(examples)’라고도 한다. 그리고 데이터베이스 이론에서는 한 행을 ’레코드(record)’라고도 한다. 데이터 행렬에서 열은 일반적으로 관측 대상의 한 속성에 대한 정보이다. 표 1.1에서 열은 학생의 전공, 학년, 성별 등의 속성 정보를 가지고 있다. 그래서 열을 ’속성(attributes)’라고 한다. 데이터마이닝, 기계학습, 패턴 인식 분야에서는 열이 한 관측 사례에 대한 특성을 나타내므로 ’특성(features)’이라고도 한다. 통계학에서는 ’변수(variable)’이라는 말로 열을 자주 표현한다. 이 책에서는 데이터 행렬의 열은 주로 변수라고 표현하지만, 속성, 열 등도 같은 의미로 사용할 것이다. 통계 데이터에서 변수는 크게 질적(qualitative) 변수와 양적(quantitative) 변수로 구분된다. 뒤에서 기술통계 분석과 추론통계 분석에서 보겠지만, 변수의 종류에 따라 통계 분석 방법에 차이가 발생한다. 그림 1.8에는 통계 분석에 사용되는 변수의 종류가 나열되어 있다. Figure 1.8: 변수의 종류 1.4.1 질적 변수 질적 변수(qualititive variables)는 학생들의 성별, 출신지역, 학년, 전공 등과 같이 관측치가 어떤 범주에 속하는지를 나타내는 변수를 말한다. 질적 변수는 값에 따라 서로 다른 질적 특성을 가지고 있는 사례로 구분되지만 수량적 의미를 가지지 않으므로 사칙연산 등의 수량적 조작은 할 수 없다. 질적 변수는 명목형(nominal)과 순서형(ordinal) 변수로 구분된다. 명목형 변수는 성별, 출신지역, 전공처럼 데이터 값의 크기나 순서가 의미없는 데이터이다. 남성과 여성에 어떤 일반화된 순서는 없다. 보통 명목형 데이터를 기술할 때 편의상 숫자를 이용하여 기술하는 경우가 많다. 예를 들어 남성은 ‘1’, 여성은 ’2’와 같이 기술하는 경우다. 이 때도 남성과 여성에 어떤 순서가 있다기보다는 서로 다른 속성을 나타내는 값이라는 의미만을 가진다. 순서형 데이터는 질적인 특성을 나타낸다는 점은 명목형 데이터와 같지만, 데이터의 값에 순서가 있다는 점이 다르다. 학생들의 학년은 1학년에서 4학년으로 증가함에 따라 순서에 의미를 부여할 수 있다. 그러나 이 경우에도 순서에만 의미가 있는 것이지 사칙연산이 가능한 양적인 의미를 가지고 있는 것은 아니다. 질적 변수는 범주형 변수(categorical variables)라고도 한다. 이름이 나타내듯이 범주형 변수는 범주 별로 발생 빈도가 얼마인지가 주요한 관심의 대상이 된다. 한 강의의 수강생에서 남성과 여성의 비율, 정당별 지지율 등이 그 예라고 할 수 있다. 데이터에 범주형 변수가 여러 개 있을 때, 두 범주형 변수의 관계를 빈도수를 교차하여 분석하기도 한다. A와 B 정당을 지지하는 비율이 남성과 여성별로 차이가 있는가에 대한 분석이 그 예라고 할 수 있다. 이 경우 범주형 변수가 순서형 변수이면 순서적인 의미를 가지는 분석도 할 수 있다. 예를 들어 학년이 올라갈수록 A정당 지지율이 높아지는가 등을 분석할 수도 있다. 1.4.2 양적 변수 양적 변수는 한 강의에 참석하는 학생들의 신장, 체중 등 수량적인 의미를 가지는 수치 변수를 말한다. 양적 변수는 수치적 의미를 가지므로 사칙연산 등이 가능하다. 양적 변수는 다시 비율형(ratio)과 구간형(interval) 변수로 구분된다. 비율형 변수는 절대 0점이 존재하는 양적 변수를 말한다. 신장, 체중 등이 이러한 변수의 예이다. 비율형 변수에서는 두 수치 변수의 차이뿐 아니라 두 변수의 비율에 의미를 부여할 수 있다. 즉 A학생이 B학생보다 10% 더 크다라는 비율적 서술이 가능하다. 반면 구간형 변수는 절대 0점이 존재하지 않아 수치들 사이의 차이에만 의미를 부여할 수 있고 비율에는 의미를 부여할 수 없는 변수를 말한다. 온도 등이 대표적인 예이다. 어제 기온이 섭씨 10도이고 오늘 기온이 섭씨 20도라고 오늘 날씨가 어제에 비해 2배 덥다라고 표현하지 않는다. 이는 온도의 0이 되는 지점이 절대적인 0이 아니기 때문이다. 양적 변수의 분석에서는 수치들의 중심값, 퍼진 정도 등이 관심의 대상이 된다. 여러 개의 양적 변수가 존재하면 변수 간의 상관성도 분석할 수 있다. 신장이 커지면 체중이 커지는가, 신장이 2배 커지면 체중은 평균적으로 몇 배 커지는가 등이 그 예라고 할 수 있다. 아울러 양적 변수와 질적 변수의 상관성에 대한 분석도 가능하다. 신장의 차이는 여성보다 남성이 큰지를 분석한다면 신장이란 양적 변수와 성별이란 질적 변수를 연관지어 분석하는 것이라 할 수 있다. 앞으로 우리는 기술통계 분석과 추론통계 분석에서 변수가 질적 변수인가 양적 변수인가에 따라 분석의 방식이 조금씩 달라지는 것을 보게 될 것이다. 가장 잘 적합된다는 의미가 모형이 데이터에 딱 들어맞아야 한다는 것은 아니다. 오히려 데이터에 딱 들어맞는 모형은 과적합된 모형일 수 있다. 그렇기 때문에 고전적인 통계 분석에서는 모형의 복잡도 대비 데이터 적합도를 고려하여 최종 모형을 선택하고, 데이터마이닝나 현대적인 통계 분석에서는 별도의 검증 데이터에서 여러 모형을 테스트하여 가장 성능이 좋은 모형을 최종 모형으로 선택한다.↩︎ "],["ch-intro.html", "Chapter 2 R 설치 및 시작 2.1 R 소개 2.2 R 설치하기 2.3 RStudio 2.4 RStudio로 R 시작하기", " Chapter 2 R 설치 및 시작 2.1 R 소개 R은 통계 계산과 그래픽을 위한 프로그래밍 언어이자 소프트웨어 환경이다. R은 1960년대와 1970년대 Bell 연구소에서 개발된 S라는 데이터 처리 언어에 기반을 두고 있다. 1990년대 중반 뉴질랜드 오클랜드 대학의 로스 이하카와 로버트 젠틀맨에 의해 시작되어 현재는 R의 핵심 기능은 R 코어 팀이, 다양한 추가 기능은 자발적 기여자들에 의해 개발되고 있다. R은 GPL 하에 배포되는 공개 소프트웨어로 누구나 자유롭게 이용할 수 있다. R은 빅데이터 분석에 널리 사용되고 있으며, 패키지 개발이 용이하여 통계 분석가들 사이에서 통계 소프트웨어 개발에 많이 쓰이고 있다. R은 데이터 조작, 계산, 그래픽 표현을 위한 소프트웨어이다. R의 주요 기능은 다음과 같다. 효율적이고 편련한 데이터 조작 및 처리 기능 데이트를 다양한 그래프로 표현해주는 데이터 시각화 기능 통계 분석 및 데이터 마이닝 알고리즘 수행 기능 분석 결과를 문서 및 발표 자료로 생성하는 기능 간단하며 효과적인 프로그래밍 언어로서의 기능 2.2 R 설치하기 2.2.1 R 배포판 내려받기 R을 설치하기 위해서는 R 배포판을 먼저 구해야 한다. R은 공개 소프트웨어이므로 무료로 R 공식 웹 사이트 (http://www.r-project.org/) 에서 내려받을 수 있다. R 공식 사이트의 첫 화면의 내용 중 download R 을 클릭하면 R 배포판을 내려받기할 CRAN 미러를 선택하는 화면으로 이동하게 된다. 지리적으로 가까운 CRAN 미러 서버를 선택하거나, 맨 위의 “0-Cloud”를 선택한다. 그러면 설치할 R 배포판을 선택하는 화면으로 이동한다. R 배포판을 선택하는 화면에서 Download R for Windows를 클릭하여 윈도우용 배포판을 선택한다.2 윈도우용 배포판 중 어떤 항목을 내려받을 것인지를 물어보는데 처음 설치하는 것이므로 Base를 선택한다. 그러면 32/64bits 겸용 윈도우용 R 바이너리 파일을 내려받을 수 있는 화면으로 이동한다. Download R x.x.x for windows를 클릭하여 배포판을 내려받는다. 여기서 x.x.x는 내려받기를 하는 R 배포판의 버전을 의미한다. 2.2.2 설치에 앞서 주의할 사항 한글 윈도우에서 R과 RStudio를 설치하여 사용할 때 이유를 알 수 없는 여러 문제가 발생할 수 있다. 이러한 문제의 대부분은 파일과 디렉토리(폴더)의 경로명에 한글이 들어간 경우에 발생한다. 특히 윈도우 사용자의 이름이 한글인 경우 이러한 문제가 빈번히 발생하는데, R이나 RStudio가 사용자 폴더의 하위 폴더에 필요한 파일과 디렉토리를 만들기 때문이다. 이러한 문제를 미연에 방지하려면 설치 전에 윈도우 사용자 이름이 한글인지 확인하고, 한글이면 영문 사용자 이름으로 관리자 계정을 하나 더 만들어 그 계정으로 R과 RStudio의 설치를 진행하는 것이 좋다. 물론 한글 사용자 이름을 사용하더라도 환경변수의 임시 디렉토리 설정을 변경하여 발생할 수 있는 대부분의 문제를 해결할 수 있지만, 새로운 패키나 함수를 사용할 때마다 이러한 문제가 잠복되어 있다가 다른 방식으로 다시 발생할 수 있다. R에 대한 이해가 높지 않은 초심자의 경우 이러한 문제가 발생하면 문제의 원인을 파악하기 어렵다. 그렇기 때문에 영문 이름으로 된 관리자 권한의 사용자로서 R과 RStudio를 설치하기를 강력히 권장한다. 2.2.3 R 설치하기 내려받은 R 설치 파일을 실행시켜 R을 설치한다. 설치 과정 중 사용할 언어 선택 화면이 나타나면 한국어를 선택한 후 [확인]을 클릭한다. GNU 라이선스 정보 화면이 나타나면 [다음]을 클릭한다. 설치할 위치를 선택하는 화면이 나타나면 [찾아보기]를 클릭하여 적절한 설치 폴더를 직접 지정하거나 기본 값으로 설치한다. [다음]을 클릭한다. 구성 요소 설치를 묻는 화면이 나타나면 위쪽에 있는 선택 리스트를 이용하여 32-bit 사용자 편의를 위한 쉬운 설치 또는 64-bit 사용자 편의를 위한 쉬운 설치 중 자신의 윈도우즈 시스템이 32-bit 윈도우인지 64-bit 윈도우인지에 따라 선택한다. 그리고 [다음]을 클릭한다.(자신의 윈도우 종류를 모르겠으면 사용자 편의를 위한 쉬운 설치를 선택하여 전체를 다 설치하여도 된다. Windows 10을 기준으로 몇 bits 운영체제인지를 확인하려면, 시작 메뉴에서 [제어판]을 선택한 후 [시스템]-[정보]를 선택하면 시스템 종류에 해당 정보가 나온다.) R을 시작할 때의 사용하는 스타트업 옵션을 조정할 것인지를 묻는 화면이 나온다. 지금은 그냥 No (기본값 사용)을 선택하도록 한다. 그리고 [다음]을 클릭한다. 시작 메뉴 폴더를 선택하도록 하는데, 기본 값인 `R’을 이용하도록 한다. [다음]을 클릭한다. 추가 사항 적용은 특별한 요구가 없는 한 기본 설정을 이용하도록 한다. [다음]을 클릭하면 설치가 실행된다. 설치가 완료되면 [완료]를 클릭한다. 윈도우즈 시작 메뉴에 가면 R 폴더가 생성되어 있고 그 안의 메뉴를 클릭하면 R이 실행된다. 2.3 RStudio R 배포판이 제공하는 기능만으로도 기본적인 프로그래밍이나 데이터 분석이 가능하다. 그러나 프로그래밍이나 데이터 분석 작업이 복잡해지면 R을 좀 더 편리하게 사용할 수 있는 통합된 개발 환경(IDE: Integrated Development Environment)이 큰 도움이 된다. RStudio는 R을 위한 강력한 통합 개발 환경을 제공해 준다. R과 마찬가지로 공개 소프트웨어로 누구나 자유롭게 이용할 수 있다. 따라서 많은 R 사용자가 RStudio를 사용하고 있다. 2.3.1 RStudio 설치 RStudio 웹페이지(http://www.rstudio.com/products/rstudio/download/) 에 접속하면 RStudio를 내려 받을 수 있다. RStudio는 데스크탑용과 서버용이 있다. 데스크탑 버전은 개별 사용자를 위한 버전이고, 서버용 버전은 여러 사람이 동시에 데이터를 분석하거나 원격에서 데이터를 분석하기에 좋은 환경이다. 서버용 버전의 관련 정보는 RStudio 홈페이지를 참조하기 바란다. RStudio Desktop은 무료용 Open Source License (Free) 버전과 상업용 Commercial License 버전이 있다. 데스크탑용 RStudio는 무료용이나 상업용이나 기능상 차이는 없다. 상업용에는 별도의 기술 지원이 추가된다. Open Source License (Free)에서 [DOWNLOAD]을 클릭하여 다운로드 페이지로 이동한다. 자동으로 접속자의 환경을 파악하여 적절한 운영체제의 RStudio 데스크탑 버전을 선택해 준다. 윈도우즈 사용자들은 [DOWNLOAD RSTUDIO FOR WINDOWS]가 나타날 것이다. 이를 클릭하면 RStudio가 다운로드 될 것이다. 만약 다른 운영체제의 RStudio가 필요하면 하단의 목록에서 적절한 배포판을 선택한다. (RStudio는 공개 소프트웨어로 프로그램 소스 파일도 함께 공개되어 있어, 같은 페이지 하단에서 볼 수 있는 바와 같이 RStudio 소스를 내려받을 수도 있다.) 내려받은 파일을 실행하면 RStudio 설치를 완료할 수 있다. 2.4 RStudio로 R 시작하기 RStudio를 설치하면 윈도우 시작메뉴에 RStudio를 실행할 수 있는 메뉴가 나타난다. 이를 실행하면 다음 그림처럼 RStudio가 실행된다. 기본 설정은 왼편에 R 콘솔이나 코드 편집기 창들이 위치하고, 오른편에 작업 환경, 명령어 히스토리, 파일, 그림, 패키지, 도움말 관련 창들이 위치하도록 되어 있다. 2.4.1 R 콘솔과 프롬프트 R은 기본적으로 텍스트 기반의 명령문을 입력받아 명령문에 대해 응답하는 대화형 방식으로 작동한다. R 콘솔은 사용자의 명령문을 입력받고 텍스트 기반 결과물을 출력하는 곳이다. R 콘솔은 사용자의 명령을 받을 준비가 되어 있다는 것을 나타내기 위해 명령 프롬프트인 `&gt;’ 기호를 표시한다. 프롬프트가 보이면 R 명령문을 입력하고 Enter 키를 누르면 입력된 R 명령문이 R에 전달되어 실행된다. 명령문의 실행 결과가 텍스트이면 R 콘솔에 결과가 나타나고 그래프이면 오른편의 Plots 창에 그래프가 나타난다. 이 책에서는 아래에 나오는 형태로 R 콘솔의 입출력을 표시한다. &gt;가 있는 행은 사용자가 입력한 행이고 &gt;가 없는 행은 R의 출력 결과로 표시한다. R을 맛보기 위해 R이 제공하는 cars 데이터에 대해 기초적인 분석을 수행해보자. 이 절에서 이용되는 R 명령어에 대해서는 현재 시점에선 이해할 필요가 없다. 이 책이 진행되면서 차근차근 설명될 것이다. 먼저 다음과 같이 cars 데이터를 화면에 출력해 보자. 콘솔에 cars라고 입력 후 Enter를 입력한다. &gt; cars speed dist 1 4 2 2 4 10 3 7 4 4 7 22 5 8 16 6 9 10 ... cars 데이터는 자동차의 속력(speed)과 제동 거리(dist)에 대한 50 개의 관찰 사례로 구성되어 있다. cars 데이터에 대하여 자세한 정보를 얻어보자. ?를 명령어에 붙이면 명령어에 대한 설명을 오른편의 Help 창에 도움말이 나타난다. &gt; ?cars summary() 함수를 이용하여 자동차의 속력과 제동 거리에 대한 최소값, 최대값, 평균, 사분위수 등 기본 통계치를 구해 보자. &gt; summary(cars) speed dist Min. : 4.0 Min. : 2.00 1st Qu.:12.0 1st Qu.: 26.00 Median :15.0 Median : 36.00 Mean :15.4 Mean : 42.98 3rd Qu.:19.0 3rd Qu.: 56.00 Max. :25.0 Max. :120.00 자동차의 속력과 제동 거리의 상관 관계를 보기 위해 plot() 함수를 이용하여 산점도(scatter plot)를 그려 본다. &gt; plot(cars) 자동차의 속력과 제동 거리의 관계를 선형 모형으로 나타내기 위해 다음 명령어를 이용하여 cars 데이터에 대한 선형회귀분석을 수행한다. &gt; lm.cars &lt;- lm(dist ~ speed, data=cars) &gt; lm.cars Call: lm(formula = dist ~ speed, data = cars) Coefficients: (Intercept) speed -17.579 3.932 제동 거리를 속도로 회귀분석해 보면 절편이 -17.579이고 기울기가 3.932가 됨을 알 수 있다. 앞에 그린 산점도에 abline() 함수를 이용하여 회귀 적합선을 그려 넣어 본다. &gt; plot(cars) &gt; abline(lm.cars, col=&quot;blue&quot;) 본 절에서 수행한 명령어가 궁금한 독자는 궁금한 명령에 대하여 help(명령어)나 ?명령어를 R 콘솔에 입력해 보라. 관련 도움말을 얻을 수 있을 것이다. 2.4.2 R 콘솔 사용과 관련된 몇 가지 팁 입력 시 주의 사항 R 명령문은 대문자와 소문자를 다른 문자로 간주한다. 그러니 함수명이나 변수명을 입력할 때 대소문자가 틀리지 않도록 해야 한다. 명령어의 철자가 틀려서 명령어가 실행되지 않는 일이 빈번히 발생한다. 그렇기 때문에 뒤에서 설명하는 코드 자동완성 기능을 사용하여 명령어를 완성하는 습관을 갖는 것이 좋다. 그래야 철자 오류 때문에 발생하는 명령 오류를 최소화할 수 있다. R 명령문 입력시 가장 많이 틀리는 부분이 ' ', \" \", ( ), { } 등이 서로 짝이 맞지 않는 경우다. R 명령문을 입력하고 Enter를 입력하였는데, 결과가 출력되지 않고 프롬프트가 +로 바뀌는 경우에는, 입력한 명령문이 완전하지 않기 때문에 나머지 입력을 받기 위해 기다리고 있다는 것을 나타낸다. 주로 앞서 설명한 ' ', \" \", ( ), { } 등이 서로 맞지 않아 발생하는 경우가 많다. 이를 해결하는 두 가지 방법이 있다. 명령문의 나머지를 + 프롬프트 뒤에 입력한 후 Enter를 입력하여 명령문을 마무리하거나, Esc를 눌러 지금까지 입력된 내용을 취소하는 것이다. RStudio의 콘솔은 몇 가지 편의 기능을 제공한다. 이 기능들을 이용하면 작업의 생산성을 향상시킬 수 있다. 코드 완성 RStudio 콘솔에서 Tab 키를 사용하여 코드를 자동 완성시킬 수 있다. 예를 들어 앞 절에 나온 lm.cars 변수를 사용하는 예제를 수행한 뒤라면, lm.c 까지만 입력한 후 Tab 키를 눌러보자. 그러면 자동으로 변수의 전체 이름을 완성해 줄 것이다. 코드 완성 기능을 이용하여 변수 이름을 입력하는 것을 습관화 하면 좋다. 변수의 이름을 잘못 입력하여 발생하는 오류를 줄일 수 있다. 코드 완성 기능은 함수에도 이용할 수 있다. sum까지만 입력한 후 Tab을 눌러보자. 그러면 다음 그림 처럼 sum으로 시작하는 함수의 목록이 나타난다. 목록 중 원하는 함수를 선택하면 해당 함수 이름을 콘솔에 자동 완성해 준다. 필요한 함수의 정확한 이름이 생각나지 않을 때 매우 유용하다. 코드 완성 기능은 함수의 인수 입력에도 이용할 수 있다. summary(라고 입력한 후에* Tab 키를 누르면 함수 인수의 목록과 설명이 나온다. R 함수들의 인수 이름을 정확히 기억하는 것은 쉽지 않다. 코드 완성 기능을 오류 없이 정확한 명령어를 빠르게 입력할 수 있도록 도와준다. 이전 명령문 불러오기 R 콘솔에서는 이전에 입력한 명령을 불러와 다시 실행하거나 수정하여 실행시킬 수 있다. 이전 명령은 위와 아래 화살표 키를 이용하여 불러온다. [위 화살표 키] 이전에 입력한 명령을 차례대로 불러온다. [아래 화살표 키] 위 화살표 키와 반대로 불러온다. [Ctrl + 위 화살표 키] 이전 명령의 목록을 보여준다. 2.4.3 R 스크립트 파일 만들기 R 콘솔에서 대화 형식으로 명령문을 입력하고 결과를 받는 것은 단순한 작업의 경우에는 편리하지만, 복잡한 분석을 위해 입력해야 할 명령문이 많거나 추후에 동일한 또는 유사한 작업을 할 예정이라면 R 스크립트 파일을 작성하여 명령문을 저장해 두는 것이 좋다. R 스크립트는 R에서 한꺼번에 실행할 명령문의 묶음을 단순한 텍스트 형식으로 기술한 파일이다. R 스크립트에는 실행할 명령문을 한 줄씩 입력한다. R은 스크립트를 읽어들여서 줄바꿈이 되는 곳을 기준으로 하나의 명령문으로 간주하여 한 줄씩 처리한다. 다음은 앞에서 콘솔에서 수행한 명령문을 R 스크립트로 작성한 예이다. 콘솔에서 입력한 명령을 그대로 텍스트 파일에 기술하면 된다. 다만 콘솔에 나타나는 프롬프트나 결과는 스크립트에 저장하지 않는다. 사용자가 직접 입력하는 명령문만 스크립트에 기술한다. summary(cars) lm.cars &lt;- lm(dist~speed, data=cars) lm.cars plot(dist~speed, cars) abline(lm.cars) RStudio 코드 편집기 RStudio의 코드 편집기는 R 스크립트 등 다양한 R 관련 파일을 작성하는 것을 도와준다. 문법 강조 표현, 코드 완성 등 다양한 기능들을 가지고 있다. 또한 코드 편집기에 입력한 R 명령을 콘솔에서 즉시 실행해 볼 수도 있다. 많은 R 사용자가 R 명령을 콘솔에서 직접 실행하는 것보다 코드 편집기에서 스크립트로 작성한 후 실행하는 것을 선호한다. 왜냐하면 코드 편집기를 이용하면 실행한 R 명령을 파일에 저장해 둘 수 있으므로, 나중에 동일한 코드를 재실행할 수 있을 뿐 아니라 함수 등으로 쉽게 변환할 수 있기 때문이다. RStudio에서 지원하는 주요 파일 형식 RStudio는 다음 형식의 파일에 대하여 문법 강조 표현 및 특화된 코드 편집 기능을 제공한다. R 스크립트: R 명령어 코드와 주석만을 포함하는 파일이다. R 노트북: R 명령어와 함께 실행 결과를 Mathematica 노트북 형태로 저장해주는 파일이다. R Markdown 문서: 마크다운이라는 매우 단순한 형식으로 문서 모양을 지정할 수 있다. R 명령어와 마크다운이 같이 한 문서에 사용되어 동적인 문서를 생성한다. R 마크다운으로 작성된 문서는 HTML, 워드 문서, PDF 문서로 최종 결과를 출력할 수 있다. Shiny Web App: RStudio에서 개발한 R을 이용해 웹 응용을 쉽게 개발하도록 지원하는 웹 응용 개발 체계이다. R Sweave 문서: LaTex 문서 내에 R 명령어를 포함하여 동적인 LaTex 파일을 만들어 주는 파일 형식이다. R HTML 문서: HTML 문서 내에 R 명령어를 포함하여 동적으로 HTML 파일을 만들어 주는 파일 형식이다. R Presentation 문서: HTML5 기능을 이용하여 HTML 기반의 동적인 프리젠테이션 파일을 만들어 주는 파일 형식이다. R Documentation 문서: R 프로그램에 대한 문서화를 지원해 주는 파일 형식이다. 스크립트 파일 만들기 일반적인 사용자는 보통 R 스크립트 파일, R 마크다운 파일, R 프리젠테이션 파일을 많이 사용한다. RStudio에서 새로운 파일을 생성하려면 File-&gt;New File 메뉴를 이용하거나 다음처럼 새 파일을 만드는 명령 단추를 클릭한다. 기존 파일을 열기 위해서는 File-&gt;Open File… 또는 File-&gt;Recent Files 메뉴를 이용하거나, 파일 열기 명령 단추를 클릭한다. RStudio에서 여러 파일을 열게 되면 탭으로 각 파일을 표시해 준다. 매우 많은 파일이 열려서 탭을 모두 표시할 수 없으면 우측 상단에 &gt;&gt; 또는 좌측 상단에 &lt;&lt; 아이콘이 표시되어 보이지 않는 파일 탭 사이를 전환할 수 있도록 해 준다. 편집기의 코드 완성 기능 코드 편집기는 Tab 키를 이용하여 자동 코드 완성을 지원한다. 코드 완성 기능은 콘솔과 마찬가지니 콘솔의 설명을 참조하기 바란다. 문자 찾기와 바꾸기 코드 편집기는 문서의 문자를 찾거나 바꾸는 기능을 지원한다. Ctrl +F 단축키를 이용하거나 Edit-&gt;Find 또는 Edit-&gt;Replace and Find 메뉴를 이용한다. 코드 실행 RStudio는 코드 편집기의 코드를 직접 실행시킬 수 있다. 실행할 코드는 콘솔에 자동 입력되어 실행되고 그 결과도 콘솔에 표시된다. 코드의 한 줄 또는 일부 여러 줄을 실행하려면 그 줄을 선택한 후 코드 편집기의 도구 모음에서 Run를 실행하거나 Ctrl+Enter 키를 이용한다. 코드 전체를 실행하기 위해서는 코드 편집기의 도구 모음에서 Source -&gt; Source with Echo를 실행하거나 Ctrl+Shift+Enter 키를 이용한다. 코드 편집기의 도구 모음에서 그냥 Source를 실행하면 파일의 명령문이 실행은 되나 결과가 콘솔에 출력되지 않는다. 주석 처리 R 스트립트에 명령문이 아닌 내용을 입력하고 싶으면 #을 앞에 사용하여 주석 처리를 한다. # 뒤에 입력된 내용은 명령문으로 간주하지 않고 무시한다. 주석문은 명령문의 의미를 나중에 이해하기 쉽도록 기술하거나, R 스크립트 개발 과정에서 디버깅이나 다른 이유로 명령문을 실행에서 제외할 때 사용한다. 직접 #를 입력하는 방법뿐 아니라, Edit-&gt;Comment/Uncomment Lines 메뉴나 코드 편집기 상단의 코드 명령 단추에서 해당 메뉴를 이용하면 선택한 코드 부분 전체를 주석 처리하거나 주석 처리를 취소할 수 있다. 들여쓰기 코드를 작성할 때 동일한 논리적 단위들을 동일하게 들여쓰기하면 코드를 읽기가 쉬워진다. RStudio는 코드 작성시 현재의 들여쓰기 옵션에 따라 자동으로 들여쓰기를 해 준다. 코드를 작성한 후 들여쓰기를 직접 조정하고 싶으면, 코드를 선택한 후 Tab 키를 누른다. 그러면 Tab 키를 누른 횟수만큼 들여쓰기가 된다. 반대로 Shift+Tab 키를 누르면, 누른 횟수만큼 내어쓰기가 된다. 참고로 RStudio는 Tab 한 회에 공백 2문자만큼 들여쓰기를 한다. 이를 조절하고 싶으면 [Toos]-[Global Options]-[Code] 메뉴에 가서 Tab 한 회당 들여쓰기할 공백 문자 수를 조절하면 된다. 이 책에서는 윈도우에 R을 설치한다고 가정한다. R 배포판은 설치 방법이나 그래픽 인터페이스의 몇 가지 기능을 제외하고 운영 체제에 따른 차이는 없다. ↩︎ "],["ch-R-Data-Basic.html", "Chapter 3 R 데이터 형식과 변수 3.1 단순한 데이터 형식 3.2 숫자 연산 3.3 논리값 연산 3.4 문자열 연산 3.5 변수와 할당 3.6 함수를 이용한 연산", " Chapter 3 R 데이터 형식과 변수 R은 통계 데이터 분석 툴이기도 하지만 그 자체로 프로그래밍 언어이다. 한국어, 영어와 같은 모든 언어가 그러하듯이 R에도 자기만의 어휘와 표현법, 표현 형태들이 있다. 외국어에 익숙해지려면 기본적인 문법 요소와 다양한 문형들을 익혀야 하는 것처럼 R도 R의 기본 표현법과 표현 형태를 익혀야만 사용할 수 있다. 고급 문법과 문형에 익숙할수록 더 유창한 언어 실력을 보일 수 있듯이 R도 고급 표현을 익히면 더 다양한 분석을 수행할 수 있다. 이 장에서는 R의 가장 기초적인 데이터 요소를 배운다. 이 장의 내용은 프로그래밍 언어에 익숙한 독자들에게는 이미 익숙한 내용일 것이다. 그런 독자들은 다음 장부터 시작하여도 무방하다. 3.1 단순한 데이터 형식 3.1.1 R의 기본적 데이터 형식: 숫자, 문자열, 논리값 R은 데이터를 다룬다. 그러므로 R에서 다룰 수 있는 데이터 형식을 이해하는 것이 무엇보다 중요하다. R에서 다루는 기본적인 데이터 형식(data type)으로는 숫자, 문자열, 논리값, raw 형식이 있다. 어떤 학생의 키가 172.2이면 이 데이터의 형식은 숫자이다. 그 학생의 이름이 `홍길동’이면 이 데이터는 문자열 데이터이다. 그리고 이 학생이 남자인지 여부를 TRUE 또는 FALSE로 표현하였다면 이 데이터의 형식은 논리값이다. 대부분의 통계 데이터의 형태는 이러한 숫자, 문자, 논리값을 기반으로 구성된다. R에서는 숫자, 문자열, 논리값 말고도 raw라는 바이트 형식도 있다. 음원이나 이미지 데이터를 처리하려면 바이트 형식의 데이터를 처리하여야 한다. 그러나 통계 분석에서는 거의 사용되지 않는 타입이어서 이 책에서는 따로 설명하지 않도록 한다. 다음은 R의 콘솔에서 숫자, 문자열, 논리값을 차례대로 입력한 예이다. &gt; 다음 부분을 R 콘솔에 입력한 후 Enter 키를 누른다. 그러면 입력한 내용이 R에 전달되어 출력 결과가 그 다음 줄에 나타난다(&gt;가 없는 줄). &gt; 10 [1] 10 &gt; TRUE [1] TRUE &gt; &quot;홍길동&quot; [1] &quot;홍길동&quot; 3.1.2 10 vs “10” 여기서 주의할 점은 숫자와 논리값과는 달리 문자 데이터는 따옴표로 시작과 끝을 표현해 주어야 한다는 것이다. 큰 따옴표나 작은 따옴표를 모두 사용할 수 있으나, 시작과 끝의 따옴표의 종류가 같아야 한다. 따라서 사칙연산이 가능한 숫자 10과 문자열 “10”은 서로 다르다. 숫자 10은 더하기나 빼기 가능하지만, 문자열 “10”은 더하기나 빼기 등의 수학적 연산이 불가능하다.3 마찬가지로 논리값 TRUE와 문자열 “TRUE”도 다른 의미를 가진다. 논리값 TRUE로는 논리 연산이 가능지만 문자열 “TRUE”로는 논리적 연산이 불가능하다. 문자열 데이터에 따옴표를 사용하는 이유는 plot이라는 문자를 그대로 입력할 수 있다고 하면, 그래프를 그리라는 plot() 함수 명령어인지, \"plot\"이라는 문자열인지 구분할 수 없을 것이다. 그렇기 때문에 대부분의 프로그래밍 언어에서 문자열 데이터를 따옴표를 사용하여 표현한다. 3.2 숫자 연산 3.2.1 사칙 연산 R은 숫자 형식의 데이터에 대하여 더하기, 빼기, 곱하기, 나누기 등의 사칙연산에 대한 기본적 기능을 제공한다. 아래의 &gt; 이후의 부분을 입력 후 Enter 키를 누르면 그 아래에 출력 결과가 나온다. &gt; 2 + 2 [1] 4 &gt; 2 - 2 [1] 0 &gt; 2 * 2 [1] 4 &gt; 2 / 2 [1] 1 3.2.2 거듭 제곱 연산 또한 ^ 연산자를 이용해 거듭제곱도 가능하다. 아래의 예는 2의 1제곱부터 4제곱까지의 결과이다. 여기서 4개의 거듭제곱 연산 명령문 (Enter 키를 쳐서 R로 보내는 내용)을 한 줄로 보내기 위해 ;로 각각의 명령문을 나누어 한번의 Enter 키로 명령을 실행하였다. 각 명령문의 결과는 다른 줄로 출력되었음을 볼 수 있다. &gt; 2^1; 2^2; 2^3; 2^4 [1] 2 [1] 4 [1] 8 [1] 16 거듭제곱 연산자로 ^ 대신 Python에서처럼 ** 연산자를 대신 사용할 수도 있다. &gt; 5^3 [1] 125 &gt; 5**3 [1] 125 3.2.3 몫과 나머지 R에서 나눗셈은 소수점 형식의 실수(real numbers)로 계산된다. 만약 정수의 나눗셈에서 몫과 너머지를 구하려면 %/%과 %% 연산자를 사용한다. &gt; 11 / 3 # 실수로 나눗셈 [1] 3.666667 &gt; 11 %/% 3 # 몫 [1] 3 &gt; 11 %% 3 # 나머지 [1] 2 3.2.4 비교 연산 그리고 == vs. = R은 사칙연산뿐 아니라 부등호와 등호를 이용한 비교연산도 가능하다. 아래는 비교 연산을 수행한 경우이다. &gt;=와 &lt;= 연산자는 같거나 크다 또는 같거나 작다를 의미한다. == 연산자는 같다를 의미하고 != 연산자는 같지 않다를 의미한다. 여기서 주의할 점은 등호가 =가 아니라 ==라는 점이다. = 연산자는 뒤에서 살펴보겠지만 변수에 값을 할당하는데 이용된다. &gt; 2 &gt; 2; 2 &gt;= 2; 2 &lt; 2 ; 2 &lt;= 2 [1] FALSE [1] TRUE [1] FALSE [1] TRUE &gt; 2 == 2; 2 != 2 [1] TRUE [1] FALSE 3.3 논리값 연산 논리값은 &amp;, |, !, xor(x, y) 연산자를 이용하여 논리적 AND, OR, NOT, XOR 연산의 수행도 가능하다. &gt; TRUE &amp; FALSE [1] FALSE &gt; TRUE | FALSE [1] TRUE &gt; !TRUE [1] FALSE &gt; xor(TRUE, TRUE) [1] FALSE 다음처럼 숫자의 비교 연산과 함께 사용되어 복잡한 연산을 수행할 수 있다. &gt; (3 &lt; 5) &amp; (5 &lt; 7) [1] TRUE &gt; (3 &lt; 9) &amp; (9 &lt; 7) [1] FALSE &gt; (3 &lt; 9) | (9 &lt; 7) [1] TRUE 3.4 문자열 연산 3.4.1 문자열 결합 연산: paste() 문자열에 대한 연산으로는 paste() 함수를 이용하여 문자열을 연결하는 연산이 있다. paste() 함수는 문자열을 공백 하나를 사이에 두고 하나의 문자열로 합쳐준다. 숫자처럼 문자가 아닌 것은 문자로 변환한 후 합쳐준다. sep인자를 이용하면 두 문자열의 사이에 다양한 문자를 넣을 수 있다. &gt; paste(&quot;대한민국&quot;, &quot;충청남도&quot;, &quot;천안&quot;) [1] &quot;대한민국 충청남도 천안&quot; &gt; paste(&quot;대한민국&quot;, &quot;충청남도&quot;, &quot;천안&quot;, sep=&quot;-&quot;) [1] &quot;대한민국-충청남도-천안&quot; &gt; paste(&quot;대한민국&quot;, &quot;충청남도&quot;, &quot;천안&quot;, sep=&quot;/&quot;) [1] &quot;대한민국/충청남도/천안&quot; &gt; paste(&quot;대한민국&quot;, &quot;충청남도&quot;, &quot;천안&quot;, sep=&quot;&quot;) [1] &quot;대한민국충청남도천안&quot; 공백 없이 문자열을 연결하는 경우가 매우 빈번하기 때문에 R은 이를 수행하는 paste0()라는 함수도 제공한다. &gt; paste0(&quot;3&quot;, &quot;학년&quot;) [1] &quot;3학년&quot; 3.4.2 문자열 분리 연산: strsplit() paste()와 반대로 하나의 문자열을 여러 문자열로 분리해 내는 strsplit() 함수도 있다. split인자에 문자열을 분리하는 기준이 되는 문자 또는 문자열을 지정해 준다. 다음은 날짜와 시간을 나타내는 문자열을 여러 지점에서 분리해보는 예이다. &gt; strsplit(&quot;2021-3-11 11:16:22&quot;, split=&quot; &quot;) [[1]] [1] &quot;2021-3-11&quot; &quot;11:16:22&quot; &gt; strsplit(&quot;2021-3-11 11:16:22&quot;, split=&quot;-&quot;) [[1]] [1] &quot;2021&quot; &quot;3&quot; &quot;11 11:16:22&quot; &gt; strsplit(&quot;2021-3-11 11:16:22&quot;, split=&quot;:&quot;) [[1]] [1] &quot;2021-3-11 11&quot; &quot;16&quot; &quot;22&quot; &gt; strsplit(&quot;2021-3-11 11:16:22&quot;, split=&quot;16&quot;) [[1]] [1] &quot;2021-3-11 11:&quot; &quot;:22&quot; strsplit()의 split 인자는 사실 정규식 표현도 가능하다. (정규식에 대해서는 regular expression에 대한 다른 자료를 참조하길 바란다.) 다음은 정규식을 이용하여 -나, (공백)나, : 문자가 있는 곳 모두를 분리한 예이다. &gt; strsplit(&quot;2016-3-11 11:16:22&quot;, split=&quot;[- :]&quot;) [[1]] [1] &quot;2016&quot; &quot;3&quot; &quot;11&quot; &quot;11&quot; &quot;16&quot; &quot;22&quot; 3.5 변수와 할당 3.5.1 변수는 메모리 공간에 붙이는 레이블 R에서 연산을 수행하다 보면 연산의 중간 결과를 저장해둘 필요가 있다. 이 때 이용할 수 있는 것이 변수이다. 변수는 데이터를 저장해 두는 공간이라고 생각하면 이해하기 쉽다. 변수는 사실 데이터를 저장해 두는 공간에 레이블을 붙여두는 것이다. 다시 그 데이터가 필요할 때 레이블을 이용하여 데이터가 저장된 공간에 가서 그 데이터 값을 가져와 이용하게 된다. 3.5.2 변수명에 대한 규칙 변수란 데이터 저장 공간에 붙이는 레이블이라고 했다. 이 레이블을 변수 이름 또는 변수명이라고 한다. 변수명은 분석자가 자유롭게 부여할 수 있으나 몇 가지 제약 사항이 있다. 변수명에는 알파벳, 숫자, _, .을 사용할 수 있다. 따라서 다음은 모두 적절한 변수명이다. sales TV_sales TV_5_sales TV.sales TV.5.sales 주의할 점은 -은 변수명에 사용될 수 없다. 만약 a-b라는 변수명이 있으면 이 표현이 a라는 변수의 값에서 b라는 변수의 값을 빼라는 명령인지, a-b라는 변수인지 구별할 수 없기 때문이다. 변수명은 알파벳이나 .으로 시작할 수 있으나 숫자나 _로는 시작할 수 없다. 그리고 .으로 변수명을 시작했으면 그 다음에는 반드시 알파벳이 변수명에 사용되어야 한다. 따라서 다음은 잘못된 변수명이다. _sales 5sales 변수명으로 R에서 기본으로 제공하는 명령어를 사용할 수 없다. 3.5.3 변수에 값 할당하기 할당(assignments)이란 어떤 변수에 데이터를 저장하는 것을 말한다. 예를 들어 x에 5라는 숫자 데이터를 할당하였다면 5라는 숫자가 x라는 레이블이 붙은 저장 공간에 들어간 것과 마찬가지이다. 우리는 x라는 레이블을 이용하여 필요할 때 x라는 레이블이 붙은 저장공간에 저장된 데이터 값을 가져올 것이다. 3.5.4 할당 연산자 변수에 데이터를 할당하는 것은 &lt;- 또는 = 연산자를 이용하여 이루어진다. 이 책에는 할당 연산자로 &lt;-을 이용할 것이다. 주의할 점은 &lt; -처럼 띄워쓰면 안되고 항상 &lt;-처럼 붙여써야 R은 할당 연산자로 이해를 한다. 할당 연산자의 모양에서도 알 수 있듯이 &lt;- 연산자 오른쪽의 데이터를 왼쪽의 변수에 집어넣는다. x라는 변수에 저장된 데이터 값을 알고 싶으면 x를 입력한 후 Enter 키를 누르면 x의 값이 출력된다. &gt; x &lt;- 5 &gt; x [1] 5 3.5.5 연산에 변수 사용하기 x를 이용하여 다양한 명령을 수행할 수 있다. 뿐만 아니라 괄호 등을 이용하여 복잡한 연산을 수행할 수 있다. &gt; x + 2 [1] 7 &gt; x * 2 [1] 10 &gt; x^2 [1] 25 &gt; (x+3)^2 + 5 [1] 69 &gt; x [1] 5 위의 마지막 결과에서 볼 수 있듯이 변수의 값은 &lt;- 연산자에 의해 다시 다른 값으로 할당되지 않으면 연산에서 사용되어도 원래의 값이 변하지 않는다. 3.5.6 변수에 값 재할당하기 변수는 데이터의 저장공간일 뿐이므로 현재 들어간 데이터 값 대신 다른 값을 재할당할 수도 있다. 다음의 예는 x에 7을 재할당한 후 앞서 수행한 연산을 다시 수행해 본 것이다. &gt; x &lt;- 7 &gt; x + 2 [1] 9 &gt; x*2 [1] 14 &gt; x^2 [1] 49 &gt; 2^x [1] 128 이제 x라는 레이블이 붙은 저장공간에 7이라는 숫자 데이터가 들어가 있으므로 x를 이용한 연산 결과가 앞의 예와는 다르게 나옴을 볼 수 있다. 3.5.7 할당문은 우변이 수행된 후 좌변으로 할당이 이루어진다. 한 명령문 안에서 x의 값을 가져와 연산에 이용한 후 그 결과를 다시 x에 재할당할 수 있다. 이 경우 &lt;- 연산자 오른편의 연산이 먼저 수행된 후 &lt;- 연산자에 의해 왼편의 변수로 할당이 이루어진다. &gt; x &lt;- x + 1; x [1] 8 &gt; x &lt;- 2 + x; x [1] 10 &gt; x &lt;- x*2; x [1] 20 &gt; x &lt;- x^2; x [1] 400 마찬가지로 한 변수의 값을 이용하여 연산을 수행한 후 다른 변수에 값을 할당할 수도 있다. 아래 예에서도 볼 수 있듯이 x가 연산에 이용되더라도 재할당이 이루어지지 않으면 x라고 레이블이 붙은 저장공간에 들어가 있는 데이터 값은 동일하다. &gt; x [1] 400 &gt; y &lt;- 2 * x &gt; y [1] 800 &gt; x [1] 400 여기서도 변수의 값은 할당문에 의해 할당 또는 재할당이 이루어지지 않으면 변화가 없음을 다시 확인할 수 있다. 3.5.8 변수 제거하기: rm() 변수를 생성하면, 그 변수는 R 세션이 종료될 때까지 유지된다. 만약 RStudio를 종료하여 수행하던 R 세션이 종료되면 변수에 저장하였던 데이터는 사라진다. 만약 변수에 저장된 데이터를 다음에도 사용하려면 별도의 파일에 데이터를 저장하여야 한다. 그런데 여러 가지 이유로 R 세션 종료 전에 변수를 제거하고 싶을 때가 있다. 사용하던 변수를 제거하려면 rm() 함수를 이용하면 된다. 제거할 변수를 rm() 함수 내에 기술하면 이 변수가 사라지게 된다. &gt; x; y [1] 400 [1] 800 &gt; rm(x, y) &gt; x Error in eval(expr, envir, enclos): 객체 &#39;x&#39;를 찾을 수 없습니다 &gt; y Error in eval(expr, envir, enclos): 객체 &#39;y&#39;를 찾을 수 없습니다 rm() 함수로 변수를 제거하면 변수가 사용하는 메모리는 자유롭게 되며, R이 다른 용도로 이 메모리를 사용할 수 있다. 사실 요즘에는 컴퓨터의 메모리의 용량이 매우 크므로 작은 데이터를 분석할 때는 메모리 사용에 크게 주의를 기울일 필요는 없다. 그러나 데이터가 커지고 분석이 복잡해지면 메모리 사용량이 급격히 늘어날 수 있으므로 필요없는 변수를 적절히 제거해 주는 것이 필요하다. 여기서 주의할 점은 rm()에 의해서 메모리가 자유롭게 되더라도 R이 사용하던 메모리가 운영체제로 바로 반환되지는 않는다는 것이다. 이를 처리하려면 gc() 함수를 이용하여 garbage collection을 하도록 해야 한다. 그러나 사실 R은 주기적으로 garbage collection을 하므로 특별한 이유가 없으면 이를 별도로 수행할 필요는 없다. 3.5.9 변수 목록 확인하기: ls() ls() 함수를 이용하면 현재 환경에서 정의되어진 모든 변수의 이름을 출력해 준다. 반면 rm() 함수는 list 인자에 변수의 이름을 주면 해당 변수를 메모리에서 제거한다. 따라서 아래와 같은 방식을 이용하면 현재 환경에 정의되어 있는 모든 변수를 제거할 수 있다. &gt; a &lt;- 5 &gt; b &lt;- 7 &gt; ls() [1] &quot;a&quot; &quot;b&quot; &quot;hook_output&quot; &gt; #rm(list=ls()) &gt; #ls() 3.5.10 변수를 할당하는 또 다른 방법: assign() assign() 함수로도 변수의 할당은 할 수 있다. 대부분의 경우는 assign() 함수를 이용하는 것보다는 앞서 설명한 할당 연산자를 이용하여 변수에 값을 할당하는 것이 편리하고 이해하기도 쉽다. 그러나 가끔 많은 변수를 자동적으로 생성해야 하는 경우나 데이터베이스에서 변수의 이름을 읽어들여와 값을 할당하는 등의 경우에는 assign() 함수를 이용하는 것이 필요하다. assign() 함수는 첫번째 인수로 변수의 이름을 문자열로 받고, 두번째 인수로 변수에 할당할 값을 받는다. &gt; x1 Error in eval(expr, envir, enclos): 객체 &#39;x1&#39;를 찾을 수 없습니다 &gt; assign(&quot;x1&quot;, 5) &gt; x1 [1] 5 &gt; assign(&quot;x1&quot;, x1 + 3) &gt; x1 [1] 8 위의 예에서 x1이라는 변수가 없었는데, assign() 함수에 의해 x1 변수가 할당되었음을 볼 수 있다. 주의할 점은 보통의 할당문에서는 변수가 문자열과 구분되도록 따옴표 없이 사용되나, assign() 함수에서는 변수의 이름을 문자열로 따옴표와 함께 표현해 주어야 한다는 것이다. 3.6 함수를 이용한 연산 R의 기본 기능에는 다양한 함수가 포함되어 있다. 사용자도 자신만의 함수를 만들 수 있다. 함수는 인수로 입력 값을 받은 후 함수의 처리 결과를 반환한다. 함수에 어떤 값을 입력해야 하고 어떤 값을 반환받을 수 있는지는 함수마다 다르다. 3.6.1 함수 호출 하기 R에서 함수를 이용하려면 다음의 형태로 함수를 호출하여야 한다. &gt; 함수이름(인수1, 인수2, ...) 함수 출력 값 아래는 제곱근을 구하는 sqrt() 함수의 예이다. 함수의 입력 인수(arguments)로는 4가 주어졌고 제곱근을 구하는 함수는 입력된 4를 가지고 결과인 2를 반환하고 있다. 함수는 연산자와 함께 사용될 수 있고 함수의 결과가 다시 다른 함수의 입력 인수가 될 수도 있다. &gt; sqrt(4) [1] 2 &gt; (sqrt(9) + 2) / 4 [1] 1.25 &gt; sin( (sqrt(9) + 2)/ 4 ) [1] 0.9489846 Rows: 12 Columns: 2 ── Column specification ──────────────────────────────────────────────────────── Delimiter: &quot;:&quot; chr (2): 수학 함수, 설명 ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Table 3.1: 수학 관련 주요 함수 수학 함수 설명 ceiling(x) x의 값을 정수로 올림 floor(x) x의 값을 정수로 내림 trunc(x) x의 값의 소수점 자리를 버림 round(x) x의 값을 반올림 round(x, digits=n) x의 값을 소수점 n자리에서 반올림 sqrt(x) x의 제곱근 exp(x) x의 지수함수 값 log(x) 자연대수를 밑으로 하는 로그 값 log(x, base=a) a를 밑으로 하는 로그 값 sin(x), cos(x), tan(x) x의 삼각함수의 값 factorial(n) n! choose(n,k) n 개 중 k를 뽑는 조합의 수 표 3.1은 R에 내장되어 있는 수학 관련 주요 함수를 보여준다. 3.6.2 실수를 정수로 변환하는 함수 다음은 함수를 이용하여 숫자에 대한 올림, 내림, 버림, 반올림 등을 수행한 예이다. &gt; a &lt;- 3.141593 &gt; ceiling(a) # 올림 [1] 4 &gt; floor(a) # 내림 [1] 3 &gt; trunc(a) # 버림 [1] 3 &gt; round(a) # 반올림 [1] 3 &gt; round(a, digits=2) # 반올림의 소수점 자릿수 지정 [1] 3.14 3.6.3 순열과 조합 함수 다음은 순열(factorial)과 조합(combination)의 값을 구한 결과이다. 30에 대한 순열 값은 매우 커서 공학 형식으로 숫자가 표시된다. 이를 일반적인 형식으로 표시하기 위해서 format() 함수를 이용하였다. &gt; factorial(5) # 5! [1] 120 &gt; factorial(30) # 30! = 2.652529 * 10^32 [1] 2.652529e+32 &gt; format(factorial(30), scientific = FALSE) # 지수표현 대신 일반적인 숫자로 표현 [1] &quot;265252859812191032188804700045312&quot; &gt; choose(5, 2) # 5 개의 요소에서 2 개를 조합하는 경우의 수 [1] 10 &gt; choose(45, 6) # 로또의 경우의 수: 45 개의 공에서 6 개를 공을 조합하는 경우의 수 [1] 8145060 Python 등의 언어를 사용해본 독자는 더하기 연산으로 문자열을 연결하는 것에 익숙할 것이다. R의 기본 기능은 이러한 문자열 연산을 지원하지 않는다. 사실 Python에서도 숫자의 더하기와 문자의 더하기는 전혀 다른 의미를 갖는다. 10 + 10은 20을 결과로 출력하지만, “10” + “10”은 문자열의 연결인 “1010”을 결과로 준다.↩︎ "],["ch-R-Data-Structure.html", "Chapter 4 R 데이터 구조 4.1 벡터 4.2 행렬과 배열 4.3 리스트 4.4 데이터 프레임", " Chapter 4 R 데이터 구조 R은 숫자, 문자열, 논리값이라는 데이터 형식을 가지고 더 복잡한 데이터 구조를 만든다. R에서 흔히 사용되는 4가지 데이터 구조는 벡터, 행렬, 리스트, 데이터 프레임이다. 그림 4.1은 벡터, 행렬/배열, 리스트, 데이터 프레임의 구조를 도식화한 것이다. 벡터는 동일한 형식의 데이터를 1차원으로 연결한 데이터 구조이고, 행렬은 동일한 형식의 데이터를 2차원으로, 배열을 2차원 이상의 차원으로 데이터를 연결한 데이터 구조이다. 반면 리스트와 데이터 프레임은 서로 다은 형식의 데이터를 하나의 데이터 구조로 묶어 준다. Figure 4.1: R 데이터의 기본 구조 이 책에서는 R 데이터 구조에 대한 문법 중에 벡터와 데이터 프레임에 대한 기본적인 문법만 다루고 나머지 부분은 생략하고자 한다. 통계분석에서 가장 중요한 데이터 구조가 데이터 프레임이므로 데이터 프레임에 대한 기본적인 이해가 필요하고, 데이터 프레임의 각 열은 벡터이므로 벡터에 대한 이해도 필요하기 때문이다. R의 데이터 구조에 대한 좀 더 전반적인 이해를 원하는 독자는 졸저 R 프로그래밍을 참조하기 바란다. 4.1 벡터 벡터는 R의 통계 분석에서 가장 중요한 데이터 형식이다. 다른 범용의 프로그래밍 언어와는 다르게 R은 벡터 단위의 연산 및 조작을 지원함으로써 통계 데이터 분석에 매우 편리한 이점을 제공한다. 4.1.1 벡터는 동일 형식 데이터의 나열 벡터는 50명 학생들의 키 데이터 (162.1, 175.8, 183.2, …), 50명 학생들의 성별 데이터 (“여”, “남”, “남”, …)처럼 한가지 형식의 데이터를 나열한 것이다. 여기서 형식이란 1과 2 등의 숫자 형식, “여”와 “남” 등의 문자열 형식, TRUE와 FALSE의 논리값 형식을 의미한다. 숫자 벡터에는 숫자 데이터만 나열되고, 문자열 벡터나 논리값 벡터에는 각각 문자열과 논리값만이 나열된다. 벡터가 포함하고 있는 데이터의 개수를 벡터의 길이 또는 크기라고 한다. 따라서 50 명 학생의 키 데이터는 길이가 50인 벡터가 된다. 사실 R은 벡터가 아닌 숫자, 문자, 논리값은 없다. 10이라는 숫자 하나도 사실은 길이가 1인 숫자 벡터이고, 문자열도 논리값도 길이가 1인 문자 벡터와 논리 벡터일 뿐이다. 벡터를 사용하기 위해서는 벡터를 생성하는 법, 벡터를 연산하는 법, 벡터의 일부분을 필터링/인덱싱하는 법을 배워야 한다. 4.1.2 벡터를 생성하는 법 4.1.2.1 c() 함수를 이용한 벡터의 생성 벡터는 기본적으로 벡터의 요소를 c() 함수로 연결하여 만든다. 다음 예처럼 1, 3, 5라는 숫자를 차례로 연결하여 벡터를 만들고 싶으면, 다음처럼 c() 함수에 각 요소를 차례로 인수로 기술한다. &gt; x &lt;- c(1, 3, 5) &gt; x [1] 1 3 5 다음 예처럼 문자열이나 논리값을 연결하여 문자열 벡터와 논리값 벡터를 만들 수 있다. 아울러 연결하고자 하는 요소의 개수는 원하는 만큼 나열할 수 있다. &gt; y &lt;- c(&quot;빨강&quot;, &quot;파랑&quot;, &quot;노랑&quot;) &gt; y [1] &quot;빨강&quot; &quot;파랑&quot; &quot;노랑&quot; &gt; z &lt;- c(TRUE, FALSE, FALSE, TRUE) &gt; z [1] TRUE FALSE FALSE TRUE c() 함수는 요소를 하나씩 연결하는 것뿐만 아니라 여러 개의 요소를 가진 벡터들을 연결하여 더 큰 벡터를 만들 수도 있다. &gt; w &lt;- c(7, 9); w [1] 7 9 &gt; c(x, w) [1] 1 3 5 7 9 &gt; c(w, x) [1] 7 9 1 3 5 앞의 예는 세 요소를 가진 벡터 x와 두 요소를 가진 벡터 w를 연결하여 새로운 벡터를 만든 예이다. 나열 순서에 따라 새롭게 만들어지는 벡터의 요소들의 위치가 어떻게 되는지 확인해 보라. 이론적으로 말하자면 사실 앞서 본 숫자 1, 3, 5도 요소가 하나인 벡터이고, 요소가 하나짜리 벡터를 연결하여 x와 w라는 벡터를 만든 것이다. 4.1.2.2 수열 패턴을 이용한 숫자 벡터의 생성 1에서부터 10까지의 자연수로 이루어진 벡터를 만든다고 해 보자. 앞에서 배운 c() 함수를 이용하여 이 벡터를 만드려면 10개의 요소를 일일이 나열하여야 하므로 매우 번거로운 작업이 된다. 이럴 때 사용할 수 있는 것이 수열 패턴을 이용하여 숫자 벡터를 만드는 것이다. : 연산자를 이용하면 다음처럼 하나씩 증가하거나 감소하는 수열 패턴으로 벡터를 만들 수 있다. : 연산자 앞에 기술된 숫자를 시작으로 하여 뒤에 기술된 숫자가 앞에 기술된 숫자보다 크면 하나씩 증가하는, 작으면 감소하는 패턴을 만든다. &gt; 1:10 [1] 1 2 3 4 5 6 7 8 9 10 &gt; 20:11 [1] 20 19 18 17 16 15 14 13 12 11 seq() 함수를 사용하면 수열의 시작점(from)과 종료점(to), 그리고 수열이 얼만큼 증가 또는 감소될 지(by)를 지정할 수 있다. &gt; seq(from=1, to=10, by=2) [1] 1 3 5 7 9 &gt; seq(from=11, to=100, by=11) [1] 11 22 33 44 55 66 77 88 99 &gt; seq(from=100, to=0, by=-15) [1] 100 85 70 55 40 25 10 4.1.2.3 비교 연산을 이용한 논리값 벡터 만들기 논리값 벡터는 자주 비교 연산을 이용하여 만들어진다. 예를 들어 중간고사 점수가 80점 이상인 학생은 TRUE, 나머지 학생은 FALSE로 하는 논리값 벡터를 만든다고 해 보자. 다음처럼 학생의 점수가 scores라는 변수에 들어가 있다고 해 보자. 그러면 다음처럼 비교 연산을 이용하여 간단히 논리값 벡터를 만들 수 있다. &gt; scores &lt;- c(75, 92, 88, 60, 80) &gt; scores [1] 75 92 88 60 80 &gt; scores &gt;= 80 [1] FALSE TRUE TRUE FALSE TRUE &gt; scores &gt; 80 [1] FALSE TRUE TRUE FALSE FALSE 논리값 연산을 이용하면 더 복잡한 조건의 요소만 TRUE가 되도록 논리값 벡터를 만들 수 있다. 다음은 80점 이상이지만 90점 미만인 학생만 TRUE로 만든 예이다. &gt; scores &gt;= 80 &amp; scores &lt; 90 [1] FALSE FALSE TRUE FALSE TRUE 그런데 앞의 비교 연산의 왼편에 있는 scores는 다섯 개의 요소를 가지고 있지만, 오른편에는 오직 하나의 숫자로만 이루어진 벡터가 있다. R은 연산을 해야 하는 벡터의 길이가 다르면 요소의 재활용이라는 원리를 사용하여 연산을 수행한다. 그러면 벡터의 연산이 어떻게 이루어지는지 살펴보자. 4.1.3 벡터의 연산 R에서 벡터에 대한 연산은 대부분 동일 위치의 요소끼리 그리고 요소의 재활용이라는 두 가지 원칙에 따라 수행된다. 동일 위치의 요소끼리라는 원칙은 동일한 길이의 두 벡터가 연산이 이루어지면 같은 위치의 요소끼리 연산이 이루어 진다는 것이다. &gt; a &lt;- 1:6; a [1] 1 2 3 4 5 6 &gt; b &lt;- seq(from=10, to=60, by=10); b [1] 10 20 30 40 50 60 &gt; a + b [1] 11 22 33 44 55 66 &gt; a * b [1] 10 40 90 160 250 360 숫자 벡터뿐 아니라 문자열, 논리값 벡터도 같은 원칙에 의해서 연산이 이루어진다. &gt; x [1] 1 3 5 &gt; y [1] &quot;빨강&quot; &quot;파랑&quot; &quot;노랑&quot; &gt; paste(y, x, sep=&quot;-&quot;) [1] &quot;빨강-1&quot; &quot;파랑-3&quot; &quot;노랑-5&quot; &gt; c(TRUE, FALSE, TRUE) &amp; c(FALSE, FALSE, TRUE) [1] FALSE FALSE TRUE &gt; c(TRUE, FALSE, TRUE) | c(FALSE, FALSE, TRUE) [1] TRUE FALSE TRUE 길이가 같은 벡터는 동일한 위치의 요소끼리 연산이 된다면, 길이가 다른 벡터의 연산을 어떻게 이루어질까? 연산을 해야할 벡터의 길이가 서로 다르면 짧은 길이의 벡터의 요소가 반복적으로 요소 재활용이 되어 길이가 긴 벡터의 길이만큼 늘어난 후, 동일한 위치의 요소끼리 연산이 수행된다. &gt; a + c(10, 20) [1] 11 22 13 24 15 26 &gt; a * c(1, 10, 100) [1] 1 20 300 4 50 600 &gt; a * 1000 [1] 1000 2000 3000 4000 5000 6000 마지막 연산은 길이가 1인 벡터가 a에 맞추어 6 개의 요소가 되도록 반복되어 재활용된 후 같은 위치의 요소끼리 연산이 이루어졌다. 마찬가지로 앞서 학생들의 점수를 비교 연산한 예에서도 오른편의 숫자가 학생들의 점수의 개수만큼 반복되어 비교가 이루어졌다. 4.1.4 벡터의 필터링/인덱싱 데이터를 분석하다 보면, 데이터의 특정 요소만 추출하여 분석해 보고 싶을 때가 있다. 40세 이상의 고객만 추출하여 분석한다든지, 남자 학생에 대해서만 별도의 분석을 하는 경우가 그러한 예라고 할 수 있다. 이렇게 데이터에서 특정 부분만 추출하여 새로운 데이터를 만드는 작업을 필터링(filtering)이라고 한다. 벡터 필터링은 특정 벡터에서 특정 요소만을 추출하는 것을 의미한다. R에서 벡터 필터링은 인덱스 벡터를 이용하여 수행된다. 여기서 인덱스란 벡터에서 특정 요소의 위치를 의미한다. 예를 들어 5개의 요소로 구성된 벡터에서 두번째 요소를 추출하려면 두번째라는 위치가 그 요소의 인덱스가 된다. 그런데 어떤 벡터에서 추출하고자 하는 요소가 여러 개일 수도 있다. 이 경우 추출해야할 위치를 여러 개 나열해야 하고, 이렇게 나열한 요소의 위치 정보를 인덱스 벡터라고 한다. 물론 하나의 요소만 추출하고자 한다면 인덱스 벡터는 길이가 1이 될 것이다. 벡터 필터링을 하려면 다음처럼 벡터의 이름 다음에 인덱스 벡터를 대괄호 안에 기술하면 된다. &gt; vector[index_vector] 인덱스 벡터는 자연수 벡터, 음의 정수 벡터, 논리값 벡터, 이름 벡터의 네 가지 형태를 가질 수 있다. 이 중에서 자연수, 음의 정수, 논리값 인덱스 벡터를 각각 살펴보도록 하자. 자연수 인덱스 벡터는 벡터에서 뽑아내고자 하는 요소의 위치를 자연수로 기술하는 인덱스 벡터이다. 다음은 학생들의 성적 벡터인 scores 벡터에서 각 위치의 데이터를 뽑아내는 예이다. &gt; scores[2] [1] 92 &gt; scores[2:4] [1] 92 88 60 &gt; scores[c(1, 4)] [1] 75 60 음의 정수 인덱스 벡터는 벡터에서 어떤 위치의 요소만 제외하고 뽑을 때 사용하는 인덱스 벡터이다. &gt; scores[-2] [1] 75 88 60 80 &gt; scores[-c(1, 4)] [1] 92 88 80 인덱스 벡터에서 가장 자주 사용되고 유용한 인덱스 벡터가 논리값 인덱스 벡터이다. 논리값 인덱스 벡터는 뽑아내고자 하는 위치의 요소에는 TRUE, 뽑지 않은 위치의 요소에는 FALSE를 기술한다. &gt; scores[c(TRUE, FALSE, TRUE, TRUE, FALSE)] [1] 75 88 60 자연수 인덱스 벡터나 음의 정수 인덱스 벡터와는 달리 논리값 인덱스 벡터는 벡터의 모든 요소에 TRUE나 FALSE가 기술되어야 한다. 만약 논리 인덱스 벡터의 길이가 원래 벡터보다 짧으면 다음처럼 벡터의 요소의 재활용이 인덱스 벡터에 적용된다. &gt; scores[c(TRUE, FALSE)] [1] 75 88 80 논리값 인덱스 벡터가 자주 사용되는 이유는 특정 조건에 맞는 요소만 벡터에서 뽑아낼 수 있기 때문이다. 다음은 학생 점수가 80점 이상인 학생의 데이터와 80점 이상이고 90점 미만인 학생의 데이터를 뽑아낸 예이다. &gt; scores[scores &gt;= 80] [1] 92 88 80 &gt; scores[scores &gt;= 80 &amp; scores &lt; 90] [1] 88 80 위의 예에서는 데이터가 5 개밖에 없으므로 자연수 인덱스 벡터를 사용하여도 필터링이 가능하다. 그러나 데이터가 수백, 수천개가 된다고 상상해 보자. 그러면 논리값 인덱스 벡터가 얼마나 유용한 도구인지 쉽게 이해할 수 있을 것이다. 이것으로 벡터에 대한 기본적인 사항을 다루었다. 그렇지만 이는 매우 기본적인 사항이므로 좀 더 복잡한 벡터의 조작이 필요한 독자는 R 프로그래밍의 R 벡터 장을 참조하기 바란다. 마찬가지로 행렬/배열, 리스트, 데이터 프레임 구조에 대해서도 생성, 인덱싱, 연산의 방법을 배워야 한다. 4.2 행렬과 배열 벡터보다 조금 더 복잡한 데이터 구조가 행렬과 배열이다. 행렬과 배열은 벡터처럼 모든 요소가 동일한 데이터의 타입을 가져야 한다. 4.2.1 행렬과 배열은 다차원적 데이터 구조 지금까지 배운 벡터는 일차원적인 데이터 구조였다. 벡터의 길이가 50이라면 벡터의 각 요소의 위치는 \\(1, 2, \\ldots, 50\\)까지 하나의 숫자로 특정할 수 있다. 반면 행렬과 배열은 다차원적인 데이터 구조이다. 행렬은 2차원적 데이터 구조로 행과 열로 구성된다. 행렬의 각 요소의 위치는 어떤 행과 어떤 열에 포함되는지를 나타내는 두 개의 숫자로 특정할 수 있다. 배열은 행렬을 일반화한 것으로 다차원적인 데이터 구조이다. 예로 3차원 배열은 세 개의 숫자에 의해 데이터의 위치를 특정할 수 있다. 4.2.2 행렬과 배열의 필요성 행렬의 예로 다음을 고려해 보자. 어떤 강의의 수강생을 성별, 학년의 두 가지 기준으로 분류한다고 해 보자. 그러면 표 4.1 같은 형식으로 데이터를 정리할 수 있을 것이다. 이와 같이 두 범주형 변수에 대해 관측도수를 요약한 표를 교차표(cross table) 또는 분할표라고 한다. Table 4.1: 어떤 과목의 수강생 분할표 1학년 2학년 3학년 4학년 남 0 5 7 5 여 2 4 8 2 표 4.1 같은 데이터는 일차원적인 벡터 형태로 데이터를 저장하면 각 데이터 요소가 어떤 의미를 갖는지 파악하기가 쉽지 않다. 이러한 경우에는 2차원으로 구성된 행렬을 이용하는 것이 좋다. 통계분석에서 행렬은 주로 시계열 데이터를 다루거나, 빈도표나 분할표(교차표) 등의 표로된 기술통계량을 기술할 때 주로 사용된다. 이 책에서는 시계열 데이터는 다루지 않을 것이며, 빈도표와 분할표도 R 함수의 결과로서만 출력하고 이를 다시 조작하거나 연산하는 작업을 하지 않을 것이므로 행렬에 대한 문법은 더 이상 다루지 않을 것이다. 행렬과 배열에 대한 생성, 연산, 필터링 등의 자세한 문법은 R 프로그래밍의 R 행렬 장을 참조하기 바란다. 4.3 리스트 벡터나 행렬은 포함되는 요소가 모두 같은 타입이어야 했다. 리스트는 숫자와 문자 등 다른 타입의 데이터를 결합시키는 데이터 구조이다. 리스트는 여러 형식의 데이터를 담아두는 데이터 구조로, 리스트의 요소들은 같은 모드나 타입일 필요가 없을 뿐 아니라 리스트 안에 또 다른 리스트를 포함할 수 있다. 따라서 리스트는 컴퓨터의 폴더 구조처럼 계층적 구조를 가질 수 있다. 리스트의 구조는 사용자가 자유롭게 지정할 수 있으므로 매우 복잡한 형식의 데이터를 다룰 수 있다. 4.3.1 리스트 이해의 중요성 실제 데이터 분석을 수행할 때 사용자가 리스트를 직접적으로 생성하는 경우는 그리 많지 않다. 그러나 리스트를 이해하는 것은 매우 중요한데 그 이유는 다음과 같다. 첫째, 데이터 분석에서 가장 중요한 데이터 구조는 데이터 프레임이다. 그리고 데이터 프레임은 리스트를 기반으로 하고 있다. 따라서 데이터 프레임의 근간이 되는 리스트에 대해 명확하게 이해하는 것이 데이터를 효율적으로 조작하는 데 도움이 된다. 둘째, 통계 및 데이터 마이닝을 위해 사용하는 다양한 R의 함수는 복잡한 분석의 결과를 리스트 타입으로 제공하는 경우가 많다. 따라서 데이터 분석의 결과를 효과적으로 이용하기 위해서는 리스트 구조를 이해할 필요가 있다. 리스트에 대한 생성, 연산, 필터링 등의 자세한 문법은 R 프로그래밍의 R 리스트 장을 참조하기 바란다. 4.4 데이터 프레임 데이터 프레임이란 데이터 구조를 다룬다. 보통 다른 통계 소프트웨어에서 데이터 분석의 기본 단위인 데이터 집합 또는 데이터 행렬이라고 불리는 것이다. 데이터 프레임은 행렬을 일반화한 것으로 생각하면 이해하기 쉽다. 행렬에 속한 데이터는 모두 같은 타입인데 반해, 데이터 프레임은 각 열마다 각기 다른 타입의 데이터를 가질 수 있다. 데이터 프레임에는 한 열은 숫자 타입의 데이터가, 다른 한 열은 문자 타입의 데이터가 각각 들어갈 수 있다. 표 1.1처럼 한 강의를 수강하고 있는 학생의 데이터에서 중간고사, 기말고사 같이 숫자 데이터도 있지만, 학생 이름과 성별처럼 문자 데이터도 있다. 데이터의 형태는 다르지만 한 학생에 대한 정보를 얻기 위해서는 숫자, 문자, 논리 값을 포함한 데이터를 다룰 수 있어야 한다. 이 경우에 사용할 수 있는 데이터 구조가 데이터 프레임이라 할 수 있다. 본질적으로 데이터 프레임은 data.frame 클래스인 리스트로서, 각 요소가 벡터이고 벡터의 길이가 같은 리스트이다. 4.4.1 데이터 프레임의 열(변수)은 벡터이다. 표 1.1처럼 한 강의를 수강하고 있는 학생의 데이터에서 각 열은 벡터이다. 성별(gender)은 문자열 벡터이고, 중간고사(mid) 점수는 숫자 벡터이다. 만약 학생 별로 이번 수강이 재수강 여부인지를 TRUE/FALSE로 나타낸다면 논리값 벡터가 될 것이다. 데이터 프레임의 각 열을 선택하는 방법은 다음과 같다. 데이터프레임_이름$열_이름 다음은 iris라는 Fisher의 붓꽃 데이터이다. 이 데이터는 150개의 붓꽃에 대한 꽃받침(sepal)과 꽃입(petal)의 길이(length)와 두께(width)와 품종(Species)에 대한 열을 가지고 있다. 다음은 head() 함수로 iris의 앞의 6줄만 확인한 후, 꽃받침의 길이(Sepal.Length) 열을 뽑아낸 결과이다. &gt; head(iris) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa &gt; iris$Sepal.Length [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 [19] 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 [37] 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 [55] 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 [73] 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 [91] 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 [109] 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 [127] 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 [145] 6.7 6.7 6.3 6.5 6.2 5.9 데이터 프레임의 열은 벡터라고 했다. 그러므로 $ 연산자로 데이터 프레임의 열을 지정하면, 데이터 프레임의 열을 벡터처럼 사용할 수 있다. 앞에서 본 꽃받침의 길이(iris$Sepal.Length)는 숫자 벡터이다. 그러므로 숫자 벡터에 사용되는 평균과 표준편차를 구하는 함수인 mean()과 sd() 함수를 사용할 수 있고, 숫자 벡터에서 배운 연산, 필터링을 사용할 수 있다. &gt; mean(iris$Sepal.Length) [1] 5.843333 &gt; sd(iris$Sepal.Length) [1] 0.8280661 &gt; iris$Sepal.Length[iris$Sepal.Length &gt; 7] [1] 7.1 7.6 7.3 7.2 7.7 7.7 7.7 7.2 7.2 7.4 7.9 7.7 한 가지 주의할 점은, 앞으로 볼 R의 통계분석을 위한 함수들이 사용자의 편의를 위해 분석에 사용할 데이터 프레임을 data 또는 .data 등의 인수로 지정한 후, 이 데이터 프레임의 열을 함수 안에서 지정할 때 $ 연산자를 사용하지 않고 열의 이름만 지정하여 사용하는 경우가 있다. 예를 들어 xtab() 함수는 빈도표나 교차표를 구할 때 사용하는데, 다음처럼 data 인수에 데이터 프레임을 지정한 후 빈도를 구할 열을 $ 연산자 없이 지정하고 있다. &gt; xtabs(~ Species, data=iris) Species setosa versicolor virginica 50 50 50 그러나 이처럼 data 등의 인수로 함수에서 사용할 데이터 프레임을 명확하게 지정한 경우가 아니면, 데이터 프레임의 열은 항상 $ 연산자를 사용하여 지정해야 한다. 다음은 table() 함수를 사용하여 동일한 빈도표를 구한 경우이다. &gt; table(iris$Species) setosa versicolor virginica 50 50 50 다시 말해 데이터 프레임의 열은 $ 연산자로 지정하는 것이 원래의 문법이나, 데이터 프레임을 사용하는 많은 함수들이 사용자의 편의를 위해 data 인수에 이미 데이터 프레임을 지정했으면, 열의 이름만으로 열을 지정하도록 편의를 제공하고 있지만, 그렇지 않은 함수들도 있으므로 표준적인 문법과 편의 기능을 서로 혼동하지 말아야 한다는 것이다. 4.4.2 데이터프레임을 행렬 형식으로 필터링 행렬 형식으로 필터링은 2차원 인덱스 구조를 갖는다. 데이터 프레임은 열의 길이가 모두 같기 때문에, 보통의 리스트에는 없는 행렬과 같은 필터링 방법이 존재한다. 특히 기존의 데이터 프레임에 행을 삭제 또는 추가할 필요가 있는 경우 이러한 행렬 방식의 필터링 방법은 매우 유용한다. 데이터 프레임의 인덱스 벡터의 사용은 다음과 같이 행렬처럼 행과 열을 독립적으로 지정하는 2차원 인덱스 구조를 가진다. &gt; 데이터프레임[행_인덱스_벡터, 열_인덱스_벡터] 다음은 iris 데이터 프레임에서 행렬 인덱스 벡터를 이용하여 데이터의 일부를 지정한 예이다. 행과 열의 인덱스 벡터를 비워두면 모든 행이나 열을 지정한다. 행과 열의 인덱스 벡터에 자연수 인덱스 벡터, 음의 정수 인덱스 벡터, 논리값 인덱스 벡터, 문자열 인덱스 벡터를 지정하면 해당되는 행과 열이 지정된다. &gt; iris[1,] # 행: 자연수 인덱스 벡터, 열: 모두 지정 Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa &gt; iris[2:3,] # 행: 자연수 인덱스 벡터, 열: 모두 지정 Sepal.Length Sepal.Width Petal.Length Petal.Width Species 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa &gt; iris[-(2:3),] # 행: 음의 정수 인덱스 벡터, 열: 모두 지정 Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa 7 4.6 3.4 1.4 0.3 setosa 8 5.0 3.4 1.5 0.2 setosa 9 4.4 2.9 1.4 0.2 setosa 10 4.9 3.1 1.5 0.1 setosa 11 5.4 3.7 1.5 0.2 setosa 12 4.8 3.4 1.6 0.2 setosa 13 4.8 3.0 1.4 0.1 setosa 14 4.3 3.0 1.1 0.1 setosa 15 5.8 4.0 1.2 0.2 setosa 16 5.7 4.4 1.5 0.4 setosa 17 5.4 3.9 1.3 0.4 setosa 18 5.1 3.5 1.4 0.3 setosa 19 5.7 3.8 1.7 0.3 setosa 20 5.1 3.8 1.5 0.3 setosa 21 5.4 3.4 1.7 0.2 setosa 22 5.1 3.7 1.5 0.4 setosa 23 4.6 3.6 1.0 0.2 setosa 24 5.1 3.3 1.7 0.5 setosa 25 4.8 3.4 1.9 0.2 setosa 26 5.0 3.0 1.6 0.2 setosa 27 5.0 3.4 1.6 0.4 setosa 28 5.2 3.5 1.5 0.2 setosa 29 5.2 3.4 1.4 0.2 setosa 30 4.7 3.2 1.6 0.2 setosa 31 4.8 3.1 1.6 0.2 setosa 32 5.4 3.4 1.5 0.4 setosa 33 5.2 4.1 1.5 0.1 setosa 34 5.5 4.2 1.4 0.2 setosa 35 4.9 3.1 1.5 0.2 setosa 36 5.0 3.2 1.2 0.2 setosa 37 5.5 3.5 1.3 0.2 setosa 38 4.9 3.6 1.4 0.1 setosa 39 4.4 3.0 1.3 0.2 setosa 40 5.1 3.4 1.5 0.2 setosa 41 5.0 3.5 1.3 0.3 setosa 42 4.5 2.3 1.3 0.3 setosa 43 4.4 3.2 1.3 0.2 setosa 44 5.0 3.5 1.6 0.6 setosa 45 5.1 3.8 1.9 0.4 setosa 46 4.8 3.0 1.4 0.3 setosa 47 5.1 3.8 1.6 0.2 setosa 48 4.6 3.2 1.4 0.2 setosa 49 5.3 3.7 1.5 0.2 setosa 50 5.0 3.3 1.4 0.2 setosa 51 7.0 3.2 4.7 1.4 versicolor 52 6.4 3.2 4.5 1.5 versicolor 53 6.9 3.1 4.9 1.5 versicolor 54 5.5 2.3 4.0 1.3 versicolor 55 6.5 2.8 4.6 1.5 versicolor 56 5.7 2.8 4.5 1.3 versicolor 57 6.3 3.3 4.7 1.6 versicolor 58 4.9 2.4 3.3 1.0 versicolor 59 6.6 2.9 4.6 1.3 versicolor 60 5.2 2.7 3.9 1.4 versicolor 61 5.0 2.0 3.5 1.0 versicolor 62 5.9 3.0 4.2 1.5 versicolor 63 6.0 2.2 4.0 1.0 versicolor 64 6.1 2.9 4.7 1.4 versicolor 65 5.6 2.9 3.6 1.3 versicolor 66 6.7 3.1 4.4 1.4 versicolor 67 5.6 3.0 4.5 1.5 versicolor 68 5.8 2.7 4.1 1.0 versicolor 69 6.2 2.2 4.5 1.5 versicolor 70 5.6 2.5 3.9 1.1 versicolor 71 5.9 3.2 4.8 1.8 versicolor 72 6.1 2.8 4.0 1.3 versicolor 73 6.3 2.5 4.9 1.5 versicolor 74 6.1 2.8 4.7 1.2 versicolor 75 6.4 2.9 4.3 1.3 versicolor 76 6.6 3.0 4.4 1.4 versicolor 77 6.8 2.8 4.8 1.4 versicolor 78 6.7 3.0 5.0 1.7 versicolor 79 6.0 2.9 4.5 1.5 versicolor 80 5.7 2.6 3.5 1.0 versicolor 81 5.5 2.4 3.8 1.1 versicolor 82 5.5 2.4 3.7 1.0 versicolor 83 5.8 2.7 3.9 1.2 versicolor 84 6.0 2.7 5.1 1.6 versicolor 85 5.4 3.0 4.5 1.5 versicolor 86 6.0 3.4 4.5 1.6 versicolor 87 6.7 3.1 4.7 1.5 versicolor 88 6.3 2.3 4.4 1.3 versicolor 89 5.6 3.0 4.1 1.3 versicolor 90 5.5 2.5 4.0 1.3 versicolor 91 5.5 2.6 4.4 1.2 versicolor 92 6.1 3.0 4.6 1.4 versicolor 93 5.8 2.6 4.0 1.2 versicolor 94 5.0 2.3 3.3 1.0 versicolor 95 5.6 2.7 4.2 1.3 versicolor 96 5.7 3.0 4.2 1.2 versicolor 97 5.7 2.9 4.2 1.3 versicolor 98 6.2 2.9 4.3 1.3 versicolor 99 5.1 2.5 3.0 1.1 versicolor 100 5.7 2.8 4.1 1.3 versicolor 101 6.3 3.3 6.0 2.5 virginica 102 5.8 2.7 5.1 1.9 virginica 103 7.1 3.0 5.9 2.1 virginica 104 6.3 2.9 5.6 1.8 virginica 105 6.5 3.0 5.8 2.2 virginica 106 7.6 3.0 6.6 2.1 virginica 107 4.9 2.5 4.5 1.7 virginica 108 7.3 2.9 6.3 1.8 virginica 109 6.7 2.5 5.8 1.8 virginica 110 7.2 3.6 6.1 2.5 virginica 111 6.5 3.2 5.1 2.0 virginica 112 6.4 2.7 5.3 1.9 virginica 113 6.8 3.0 5.5 2.1 virginica 114 5.7 2.5 5.0 2.0 virginica 115 5.8 2.8 5.1 2.4 virginica 116 6.4 3.2 5.3 2.3 virginica 117 6.5 3.0 5.5 1.8 virginica 118 7.7 3.8 6.7 2.2 virginica 119 7.7 2.6 6.9 2.3 virginica 120 6.0 2.2 5.0 1.5 virginica 121 6.9 3.2 5.7 2.3 virginica 122 5.6 2.8 4.9 2.0 virginica 123 7.7 2.8 6.7 2.0 virginica 124 6.3 2.7 4.9 1.8 virginica 125 6.7 3.3 5.7 2.1 virginica 126 7.2 3.2 6.0 1.8 virginica 127 6.2 2.8 4.8 1.8 virginica 128 6.1 3.0 4.9 1.8 virginica 129 6.4 2.8 5.6 2.1 virginica 130 7.2 3.0 5.8 1.6 virginica 131 7.4 2.8 6.1 1.9 virginica 132 7.9 3.8 6.4 2.0 virginica 133 6.4 2.8 5.6 2.2 virginica 134 6.3 2.8 5.1 1.5 virginica 135 6.1 2.6 5.6 1.4 virginica 136 7.7 3.0 6.1 2.3 virginica 137 6.3 3.4 5.6 2.4 virginica 138 6.4 3.1 5.5 1.8 virginica 139 6.0 3.0 4.8 1.8 virginica 140 6.9 3.1 5.4 2.1 virginica 141 6.7 3.1 5.6 2.4 virginica 142 6.9 3.1 5.1 2.3 virginica 143 5.8 2.7 5.1 1.9 virginica 144 6.8 3.2 5.9 2.3 virginica 145 6.7 3.3 5.7 2.5 virginica 146 6.7 3.0 5.2 2.3 virginica 147 6.3 2.5 5.0 1.9 virginica 148 6.5 3.0 5.2 2.0 virginica 149 6.2 3.4 5.4 2.3 virginica 150 5.9 3.0 5.1 1.8 virginica &gt; iris[1:5, c(2, 4)] # 행: 자연수 인덱스 벡터, 열: 자연수 인덱스 벡터 Sepal.Width Petal.Width 1 3.5 0.2 2 3.0 0.2 3 3.2 0.2 4 3.1 0.2 5 3.6 0.2 &gt; iris[1:5, -4] # 행: 자연수 인덱스 벡터, 열: 음의 정수 인덱스 벡터 Sepal.Length Sepal.Width Petal.Length Species 1 5.1 3.5 1.4 setosa 2 4.9 3.0 1.4 setosa 3 4.7 3.2 1.3 setosa 4 4.6 3.1 1.5 setosa 5 5.0 3.6 1.4 setosa &gt; iris[iris$Sepal.Length &gt; 7, ] # 행: 논리값 인덱스 벡터, 열: 모두 지정 Sepal.Length Sepal.Width Petal.Length Petal.Width Species 103 7.1 3.0 5.9 2.1 virginica 106 7.6 3.0 6.6 2.1 virginica 108 7.3 2.9 6.3 1.8 virginica 110 7.2 3.6 6.1 2.5 virginica 118 7.7 3.8 6.7 2.2 virginica 119 7.7 2.6 6.9 2.3 virginica 123 7.7 2.8 6.7 2.0 virginica 126 7.2 3.2 6.0 1.8 virginica 130 7.2 3.0 5.8 1.6 virginica 131 7.4 2.8 6.1 1.9 virginica 132 7.9 3.8 6.4 2.0 virginica 136 7.7 3.0 6.1 2.3 virginica &gt; iris[iris$Sepal.Length &gt; 7, 3:5] # 행: 논리값 인덱스 벡터, 열: 자연수 인덱스 벡터 Petal.Length Petal.Width Species 103 5.9 2.1 virginica 106 6.6 2.1 virginica 108 6.3 1.8 virginica 110 6.1 2.5 virginica 118 6.7 2.2 virginica 119 6.9 2.3 virginica 123 6.7 2.0 virginica 126 6.0 1.8 virginica 130 5.8 1.6 virginica 131 6.1 1.9 virginica 132 6.4 2.0 virginica 136 6.1 2.3 virginica 4.4.3 데이터 프레임의 문법과 조작 데이터 프레임의 생성, 연산, 필터링하는 R의 기본 문법을 더 자세히 알고자 하면, R 프로그래밍의 R 데이터 프레임 장을 참조하기 바란다. 앞서 언급하였듯이 데이터 프레임은 데이터 분석에서 가장 중요한 데이터 구조이다. 그렇기 때문에 분석에 적절하게 데이터 프레임을 변형하거나 결합하는 작업이 데이터 전처리에서 빈번하게 이루어진다. 이 때 데이터 프레임의 생성, 연산, 필터링하는 R의 기본 문법을 사용하여도 데이터 프레임을 조작할 수 있지만, 최근의 추세는 Hadley Wickham 등이 제공하고 있는 tidyverse 패키지를 사용하는 경우가 많다. tidyverse 패키지를 사용하여 데이터 프레임을 조작하는 방법을 알고자 하는 독자는 R 프로그래밍의 dplyr을 이용한 데이터 변환과 R 고급 데이터 변환 장을 참조하기 바란다. "],["chap-visulaize.html", "Chapter 5 R 데이터 시각화 기초 5.1 ggplot2 패키지 설치하기 5.2 ggplot2 시작하기 5.3 그래프 속성과 데이터 열 매핑하기 (aesthetic mapping) 5.4 ggplot 명령문을 입력할 때 자주 발생하는 문제들 5.5 geom 함수와 그래프 계층 5.6 측면(facets)으로 나누어 그리기 5.7 기타 ggplot2의 문법 요소", " Chapter 5 R 데이터 시각화 기초 데이터 시각화란 데이터를 그래프 등의 시각적 요소로 요약하여 보여주는 것을 의미한다. R에서는 데이터 시각화를 R의 기본 기능에 포함된 graphics 패키지를 사용하여 시각화하는 방법과 ggplot2패키지를 이용하는 방법이 있다. 이 장에서는 ggplot2를 이용하여 데이터를 시각화하는 기본적인 방법을 배운다. 여기서는 통계분석에 필요한 기본적인 그래프를 그리기 위한 기본적인 문법을 소개하는 것이지 ggplot2에 대한 체계적인 설명을 하지 않을 것이다. ggplot2는 자유로운 형식으로 그래프를 그릴 수 있는 그래프 문법을 가지고 있기 때문에, ggplot2에 대한 더 체계적인 이해를 원하는 독자는 졸저 ’R 프로그래밍’의 ggplot2를 이용한 데이터 시각화를 참조하기 바란다. 5.1 ggplot2 패키지 설치하기 R은 패키지란 단위로 R에서 사용할 수 있는 기능을 제공한다. R을 설치하면 base, stat, dataset, graphics 등의 기본 패키지가 자동으로 설치되고, R을 시작할 때마다 이러한 기본 패키지가 자동으로 적대되어 사용될 수 있도록 준비된다. 만약 R에서 기본으로 제공하는 패키지 말고 다른 패키지를 사용하려면 그 패키지를 R에 설치해야 한다. ggplot2 패키지는 기본 기능에 포함되지 않으므로 먼저 설치를 해야 한다. ggplot2 패키지를 설치하려면 다음 명령을 실행하면 된다. 패키지의 이름은 문자열이므로 따옴표 안에 기술해야 한다. &gt; install.packages(&quot;ggplot2&quot;) 또는 RStudio의 우측 하단의 Packages 탭에서 [Install]을 클릭한 후 ggplot2라고 입력을 하면 된다. 패키지 설치는 한 번만 수행하면 된다. 패키지를 사용하려면 메모리에 적재를 하여야 한다. 패키지를 메모리에 적재하는 것은 library() 함수를 사용한다. 이 때 주의할 점은 이미 설치된 패키지를 지정할 때는 따옴표 없이 변수처럼 패키지를 기술해야 한다는 것이다. &gt; library(ggplot2) 패키지의 설치는 한 번만 수행하면 되지만, 패키지를 메모리에 적재하는 작업을 패키지를 사용할 때마다 수행하여야 한다. 한번 메모리에 적재된 패키지는 R 세션이 종료되기 전까지 유지된다. 그러므로 하나의 R 세션에서는 다시 library() 함수로 동일한 패키지를 적재하지 않아도 된다. 그러나 R 세션을 종료하고 다시 시작하였다면, 기본 패키지가 아니면 자동 적재되지 않으므로 사용하기 전에 패키지를 다시 적재하여야 한다. 5.2 ggplot2 시작하기 이 절에서는 ggplot2에서 제공하는 mpg 데이터를 이용하여 ‘배기량이 커지면 연비가 낮아지는가?’ 라는 물음을 그래프를 이용하여 탐색해 보자. mpg는 1999년과 2008년에 미국 EPA에서 조사하여 발표한 자동차 주요 모델별 연비 데이터이다. 다음 명령을 이용하여 mpg 데이터를 출력해 보자. mpg 데이터는 tibble이라는 데이터 프레임의 일종으로, 사용자의 화면의 크기에 따라 출력 내용을 조정한다. 그러므로 화면의 크기에 따라 출력되는 내용이 책과는 조금 다를 수 있다. &gt; mpg # A tibble: 234 × 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 audi a4 1.8 1999 4 auto… f 18 29 p comp… 2 audi a4 1.8 1999 4 manu… f 21 29 p comp… 3 audi a4 2 2008 4 manu… f 20 31 p comp… 4 audi a4 2 2008 4 auto… f 21 30 p comp… 5 audi a4 2.8 1999 6 auto… f 16 26 p comp… 6 audi a4 2.8 1999 6 manu… f 18 26 p comp… 7 audi a4 3.1 2008 6 auto… f 18 27 p comp… 8 audi a4 quattro 1.8 1999 4 manu… 4 18 26 p comp… 9 audi a4 quattro 1.8 1999 4 auto… 4 16 25 p comp… 10 audi a4 quattro 2 2008 4 manu… 4 20 28 p comp… # … with 224 more rows mpg는 1999년과 2008년에 미국 EPA에서 조사하여 발표한 자동차 주요 모델별 연비 데이터이다. 데이터는 234 개의 행이 있으며, 각 행은 다음과 같은 변수로 구성되어 있다. manufacturer: 자동차 제조사 model: 자동차 모델명 displ: 자동차 배기량 year: 제조년도 cyl: 엔진 실린더 수 trans: 자동차 트랜스미션 종류 drv: 자동차 구동 방식. f=전륜구동, r=후륜구동, 4=사륜구동 cty: 도심 연비 (마일/갤론) hwy: 고속도로 연비 (마일/갤론) fl: 연료 종류 class: 자동차 분류 mpg 데이터에 대한 더 자세한 설명은 콘솔에 다음을 입력하여 R 도움말을 참조하기 바란다. &gt; ?mpg 5.2.1 ggplot2 그래프의 기본 문법 mpg 데이터로부터 배기량과 고속도로 연비의 관계를 살펴보기 위해서 배기량(displ)을 x 축으로, 고속도로 연비(hwy)를 y 축으로 하는 산점도를 그려보자. 산점도에서 배기량이 커짐지면 연비가 줄어드는 경향을 관찰할 수 있다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_point() 그러면 이 산점도 그린 ggplot2 명령어의 문법을 살펴보자. ggplot2의 명령어는 항상 ggplot() 함수로 시작하고, + 연산자를 사용하여 그래프에 추가될 요소를 덧붙여 나간다. 이렇게 함수를 +로 연결하여 사용하는 방식은 ggplot2 패키지의 독특한 문법으로 대부분의 다른 R 명령어에서는 이러한 방식을 사용하지 않는다. ggplot() 함수는 그래프의 좌표축과 좌표평면을 만드는 함수이다. 그러므로 다음처럼 ggplot() 함수만 사용하고 그래프에 추가할 요소를 지정하지 않으면 좌표축과 좌표평면만 그린다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) ggplot() 함수의 첫번째 인수는 그래프를 그릴 때 사용할 데이터를 지정하고, 두번째 인수는 그래프 속성과 데이터 열의 관계를 지정한다. 그래프 속성과 데이터 열의 관계는 항상 aes() 함수 내에 기술되고, 다음처럼 &lt;그래프 속성&gt;=&lt;데이터 열&gt;의 형식으로 기술된다. ggplot(데이터, aes(속성1=열1, 속성2=열2, ...)) + geom함수() 앞의 산점도에서는 x라는 그래프의 가로축 속성에 mpg 데이터의 배기량 열 displ이 매핑되었고, y라는 그래프의 세로축 속성에 고속도로 연비 열 hwy가 매핑되었다. 다음은 그래프의 가로축에 데이터의 도심 연비 열인 cty을 매핑하여 산점도를 그린 예이다. 도심 연비가 좋은 차가 고속도로 연비도 좋다는 것을 알 수 있다. &gt; ggplot(mpg, aes(x=cty, y=hwy)) + geom_point() ggplot() 함수에 +로 연결되는 geom 함수는 그래프에 그릴 도형을 지정한다. geom_point() 함수는 ggplot() 함수에 정의된 그래프 속성과 열의 관계를 이용하여 그래프에 점(points)이라는 도형을 그린다. ggplot2에는 점을 그리는 geom_point() 함수뿐 아니라 다양한 도형을 그리는 geom 함수들이 있다. 만약 다음처럼 geom_point() 함수가 아니라 geom_smooth() 함수를 연결하면 점이 아니라 데이터의 추세선을 ggplot() 함수에 정의된 그래프 속성과 열의 관계를 이용하여 그래프에 그린다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_smooth() `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ggplot() 함수에 여러 개의 geom 함수를 연결하여 두 개 이상의 그래픽적 도형을 그래프에 그릴 수 있다. 이 경우 먼저 기술된 geom 함수의 도형이 아래 층에 그려지고 뒤에 기술된 geom 함수의 도형이 윗 층에 그려진다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_point() + geom_smooth() `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 5.3 그래프 속성과 데이터 열 매핑하기 (aesthetic mapping) 앞의 산점도에서 배기량에 따라 연비가 줄어드는 관계를 조금 벗어나는 관측치들이 있다. 이 예외적인 관측치들이 자동차 종류의 차이 때문에 발생했다, 라고 가설을 세웠다 하자. 이 가설을 확인해 보려면 자동차 종류별로 관측치를 시각화할 필요가 있다. 앞서 본 geom_point() 함수는 ’점’이라는 도형을 좌표평면 상에서 그린다. 점이라는 도형은 x-축의 위치(x)와 y-축의 위치(y)뿐 아니라 색상(color), 모양(shape), 크기(size), 투명도(alpha) 등의 다른 시각적 속성을 가지고 있다. 우리는 이러한 속성 중 하나에 mpg 데이터의 class 열을 대응시켜 자동차 종류 별로 좌표평면에서 시각적으로 구분되는 점으로 표현할 수 있다. 5.3.1 범주형 변수와 색상(color) 속성의 매핑 다음은 관측치의 종류(class)에 따라 점을 서로 다른 색상(color)으로 표현한 예이다. 자동차의 종류에 따라 점이 다른 색상으로 표현되고, 어떤 색상이 어떤 자동차 종류에 대응되었는지에 대한 범례가 자동 생성된다. &gt; ggplot(mpg, aes(x=displ, y=hwy, color=class)) + geom_point() 앞선 그래프에서 이상치로 표현되었던 점들 중 한 점만 제외하고 모두 2seater 자동차의 관측치였음을 알 수 있다. 이 종류의 차는 스포츠카로 배기량에 비해 가벼운 몸체를 가지고 있어 예외적인 연비가 관측된 것으로 보인다. 다음으로 class 열을 shape, size, alpha 등의 속성에 대응시켜 어떤 결과가 나오는지 살펴보자. 5.3.2 범주형 변수와 모양(shape) 속성의 매핑 shape 속성은 점의 모양을 결정한다. 다음은 앞의 산점도를 구동 방식(drv)에 따라 점의 모양이 다르게 표시한 예이다. &gt; ggplot(mpg, aes(x=displ, y=hwy, shape=drv)) + geom_point() 점의 모양과 색상을 하나의 데이터 열에 매핑하여 좀 더 데이터가 뚜렷이 구분되게 그래프를 그리기도 한다. &gt; ggplot(mpg, aes(x=displ, y=hwy, shape=drv, color=drv)) + geom_point() 물론 다음처럼 점의 색상과 모양을 각각 데이터의 다른 열에 매핑할 수도 있다. 다음은 점의 색은 자동차의 종류(class)에 모양은 자동차의 구동방식(drv)에 매핑한 결과이다. &gt; ggplot(mpg, aes(x=displ, y=hwy, shape=drv, color=class)) + geom_point() shape을 사용할 때 주의할 점은 shape은 최대 6개의 모양으로만 점을 구분하기 때문에 class 열처럼 6개보 많은 종류가 있는 열에 매핑되면 데이터가 제대로 표시가 되지 않는다. 다음 예처럼 shape 속성에 class 열을 매핑하니 경고가 나타나고 suv 데이터를 표시하지 못한 것을 확인할 수 있다. &gt; ggplot(mpg, aes(x=displ, y=hwy, shape=class)) + geom_point() Warning: The shape palette can deal with a maximum of 6 discrete values because more than 6 becomes difficult to discriminate; you have 7. Consider specifying shapes manually if you must have them. Warning: Removed 62 rows containing missing values (`geom_point()`). 5.3.3 연속형 변수와 크기(size), 색상(color), 투명도(alpha) 속성의 매핑 모양(shape) 속성은 소수의 구분되는 값으로 표현되는 범주형 변수를 표현하기 좋다. 데이터의 열이 연속형 변수이면 연속적인 값을 표현하기 좋은 가로축(x), 세로축(y), 크기(size), 투명도(alpha) 등을 이용하는 것이 좋다. 색상(color)은 범주형 변수와 연속형 변수에 모두 매핑될 수 있다. 범주형 변수로 매핑되면 구분되는 색상으로, 연속형 변수로 매핑되면 색상의 그라데이션으로 값을 표시한다. 다음은 도심 연비와 고속도로 연비를 가로축과 세로축으로 하는 그래프에서 점의 크기 속성을 배기량 열에 매핑한 결과이다. 도심 연비와 고속도로 연비가 좋은 차들은 배기량이 작은 차임을 알 수 있다. &gt; ggplot(mpg, aes(x=cty, y=hwy, size=displ)) + geom_point() 다음은 동일한 도심 연비와 고속도로 연비 산점도에서 그래프에서 점의 색상을 배기량 열에 매핑한 결과이다. 범주형 변수가 매핑될 때와는 달리 색상의 연속적인 변화인 그라데이션을 사용하여 배기량을 표현하고 있음을 볼 수 있다. &gt; ggplot(mpg, aes(x=cty, y=hwy, color=displ)) + geom_point() 다음은 동일한 도심 연비와 고속도로 연비 산점도에서 그래프에서 점의 투명도를 실린더 수 열에 매핑한 결과이다. &gt; ggplot(mpg, aes(x=cty, y=hwy, alpha=cyl)) + geom_point() 5.4 ggplot 명령문을 입력할 때 자주 발생하는 문제들 ggplot은 매우 강력한 기능을 가지고 있지만 Excel 등의 GUI 프로그램에만 익숙한 사람은 문자 기반 명령어를 입력하는 것에 어려움을 느낄 수 있다. 컴퓨터는 사람만큼의 유연성을 발휘하지 못하므로 컴퓨터는 자신이 실행해야 할 명령문의 문법에 매우 까다롭게 반응한다. ggplot 명령어 입력시 흔히 발생하는 문제들은 다음과 같다. R 명령문은 대소문자를 구분한다. 따라서 Color와 color는 ggplot에서 서로 다른 인수로 인식되어 오류가 발생한다. ggplot 명령문의 키워드의 철자가 틀리면 다른 키워드로 간주하기 때문에 오류가 발생할 수 있다. 이를 방지하려면 키워드의 일부만 입력한 후 Tab 키를 눌러 자동완성 기능을 사용하여 입력하는 것을 권장한다. ggplot2의 명령문을 입력할 때 여러 함수를 합쳐서 실행하기 위하여 + 연산자를 이용한다.4 ggplot2의 명령문이 길어지면 명령문을 여러 줄로 쓰는 것이 필요한데, 보통 +로 연결되는 곳에서 줄바꿈하는 것이 읽기에 좋다. 이 때 주의할 점이, 줄바꿈을 + 앞이 아니라 뒤에서 해야 한다는 것이다. + 앞에서 하면 R은 명령문의 입력이 완성된 것으로 간주하기 때문이다. 다음은 산점도와 추세선을 한 그래프에 그린 예이다. &gt; ggplot(mpg, aes(x=displ, y=hwy, color=drv)) + geom_point() + geom_smooth() `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 그런데 위의 명령어는 길기 때문에 스크립트 파일을 작성할 때 보기에 불편하다. 이러한 경우에 위의 명령은 다음처럼 세 줄로 나누어 기술될 수 있다. 세 함수를 연결하는 + 위치가 어디에 있는지 살펴보라. (다음 예에서 왼쪽의 &gt; 프롬프트 아래 있는 +는 R 콘솔에서 명령문이 계속되고 있음을 나타내는 표시이다. 이 표시와 사용자가 입력한 +를 혼동하면 안 된다.) &gt; ggplot(mpg, aes(x=displ, y=hwy, color=drv)) + + geom_point() + + geom_smooth() 만약 다음처럼 + 위치가 잘못되면 오류가 발생한다. 왜 이런 결과가 나왔고 오류 메시지의 의미는 무엇일까? R은 Enter로 명령문을 구분한다. 그러므로 첫번째 줄은 +가 없으므로 완벽한 명령문이기 입력된 것으로 간주하고 실행이되어 좌표평면만 그린 것이다. 그러고 나서 두번째 줄을 새로운 명령문으로 실행을 한다. 그런데 갑자기 명령문이 +로 시작하니 R은 명령문에 오류가 있다고 판단한다. 왜냐하면 + 연산은 왼편과 오른편에 더할 요소가 있어야 하는데, 왼편의 요소가 기술되지 않았기 때문이다. &gt; ggplot(mpg, aes(x=displ, y=hwy, color=drv)) &gt; + geom_point() Error: ! Cannot use `+` with a single argument ℹ Did you accidentally put `+` on a new line? R 명령문이 조금 길어지면 가장 흔하게 발생하는 실수가 ( )와 \" \"을 짝을 맞추어 제대로 입력하지 못하는 것이다. ggplot2의 명령문도 많은 함수를 사용하다 보니 이를 주의하여야 한다. 이러한 실수를 하게 되면면 R 콘솔은 명령이 계속 입력 중이라고 생각하여 &gt;가 아니라 +를 콘솔의 프롬프트로 표시한다. 이 경우 가장 간단한 해결책은 Esc 키를 눌러 명령 입력에서 빠져나와 다시 명령문을 입력하는 것이다. 5.5 geom 함수와 그래프 계층 ggplot2의 장점은 필요에 따라 다양한 형식의 그래프를 쉽게 만들 수 있고, 만들 수 있는 형식도 무궁무진하다는데 있다. 그리고 ggplot2 그래프의 계층적 구조가 이러한 무궁무진한 그래프 형식을 만들어 내는 핵심 요소라 할 수 있다. ggplot2는 좌표평면 위에 여러 계층으로 그래프를 겹쳐 그려서 하나의 좌표평면에 나타냄으로써 복잡한 형식의 그래프를 만들어 낼 수 있다. 다음 그래프는 배기량과 고속도로 연비의 산점도와 추세선을 한 그래프에 그렸다. ggplot() 함수에 지정한 데이터와 그래프 속성과 데이터 열 매핑이 산점도(geom_point())와 추세선(geom_smooth())에 모두 동일하게 정의되었음을 볼 수 있다. &gt; ggplot(mpg, aes(x=displ, y=hwy, color=drv)) + geom_point() + geom_smooth() `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ggplot() 함수가 여러 개의 geom 함수와 연결되면, 하나의 좌표평면에 각각의 geom() 함수의 결과를 층층이 그린다. 이 때, 명령문에 나타나는 순서에 따라 첫번째 나온 geom 함수의 도형이 가장 아래 계층에, 다음에 나오는 geom 함수의 도형이 차례로 그 윗 계층에 그려진다. 5.5.1 geom 함수에서 속성 매핑하기 앞의 배기량과 고속도로 연비의 산점도와 추세선을 그린 그래프에서 추세선을 선 종류(linttype)가 구동 방식(drv)에 따라 다르게 표현하고 싶다. 그런데 산점도는 점이라는 도형으로 그래프를 그리므로 선 종류라는 속성을 가지고 있지 않다. 그리고 산점도도 점의 모양(shape)이 구동 방식에 따라 다르게 표현하고 싶다고 하자. 마찬가지로 추세선은 선이라는 도형으로 그래프를 그리므로 점의 모양이라는 속성을 가지고 있지 않다. 이렇듯 여러 geom 함수를 연결하여 그래프를 그릴 때, 특정 geom 함수에만 해당하는 속성은 해당 geom 함수에서 속성과 데이터 열을 매핑하는 것이 좋다. geom 함수도 ggplot() 함수처럼 aes() 함수를 이용하여 그래프 속성과 데이터 열을 매핑하는데, 이 매핑이 geom 함수의 첫 번째 인수로 기술된다는 점만 다르다. &gt; ggplot(mpg, aes(x=displ, y=hwy, color=drv)) + + geom_point(aes(shape=drv)) + + geom_smooth(aes(linetype=drv)) `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 따라서 지금까지 배운 내용으로 ggplot2 그래프를 그리는 문법을 확장하면 다음과 같다. ggplot(데이터, aes(공통속성1=열1, 공통속성2=열2, ...)) + geom함수1(aes(geom함수1의 속성1=열1, geom함수1의 속성2=열2, ...)) + geom함수2(aes(geom함수2의 속성1=열1, geom함수2의 속성2=열2, ...)) + .... 확장된 문법으로 맨처음 그린 배기량과 고속도로 연비의 산점도와 추세선 그래프에서, 산점도의 점은 구동 방식에 따라 다른 색으로 표시하지만, 추세선은 모든 데이터에 대하여 하나만 그리려면 어떻게 해야 할까? 답은 다음처럼 색상 속성을 공통 속성으로 ggplot()에 매핑하지 않고 산점도만의 속성 매핑이 되도록 geom_point()에 기술하는 것이다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + + geom_point(aes(color=drv)) + geom_smooth() `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 마찬가지로 추세선을 구동 방식에 따라 다른 색상으로 표시하나 점은 모두 동일한 색으로 표시하고 싶으면 다음처럼 색상이 추세선만의 속성 매핑이 되도록 geom_smooth()에 기술하는 것이다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + + geom_point() + geom_smooth(aes(color=drv)) `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 또한 ggplot() 함수에 데이터와 도형 속성에 대한 매핑이 되어 있어도, geom 함수에서 데이터와 도형 속성의 매핑을 재지정할 수도 있다. 이 경우 각 geom 함수에서 사용하는 data와 mapping은 다음 규칙에 의해 결정된다. geom 함수는 ggplot() 함수에 설정된 data와 mapping을 상속받아 그래프를 그린다. 만약 geom 함수에 data 인수가 설정되면 ggplot() 함수에 설정된 data는 무시된다. 만약 geom 함수에 mapping 인수가 설정되면 ggplot() 함수에 설정된 mapping에 geom 함수에 설정된 mapping이 추가된다. 만약 동일한 도형 속성에 대한 정의가 두 군데 나타나면 geom 함수의 설정이 사용된다. 자세한 내용은 R 프로그래밍의 그래프 계층(layers)과 도형(geoms) 절을 참조하기 바란다. 5.6 측면(facets)으로 나누어 그리기 다음 그래프는 배기량과 고속도로 연비의 관계를 살펴보기 위하여 이 두 변수의 관계를 산점도로 살펴보고 나서, 이 두 변수의 관계가 자동차 종류에 따라 어떻게 달라지는지를 살펴보기 위해 그래프의 색상 속성을 자동차 종류를 나타내는 열에 매핑하여 다르게 표시되도록 하였다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_point() &gt; ggplot(mpg, aes(x=displ, y=hwy, color=class)) + geom_point() 이렇듯 두 변수의 관계를 제삼의 변수 관점에서 세분화하여 살펴보는 방법으로 제삼의 변수를 그래프 속성에 매핑하는 방법 말고도 제삼의 변수의 변수값에 따라 데이터를 별도의 그래프로 나누어 그려보는 방법이 있다. ggplot2에서는 이러한 방식을 측면(facets)으로 나누어 그래프를 그린다고 한다. 5.6.1 facet_wrap()로 일차원 측면 그래프 그리기 다음은 facet_wrap() 함수의 사용법을 보여준다. ~ 은 R에서 수식을 표현할 때 사용되는데, facet_wrap() 함수는 수식을 첫 번재 인수로 입력받는다. facet_wrap() 함수는 ~ 우변에 서술된 변수의 변수값 별로 데이터를 나누어 그래프를 각각 그린다. 이 때 측면(facets)을 지정하는데 사용되는 변수는 범주형 데이터이어야 한다. facet_wrap()은 측면 그래프가 많아지면 줄바꿈하여 그래프를 표시한다. nrow나 ncol을 설정하면 그래프의 행과 열의 수를 지정하여 줄바꿈 처리를 제어할 수 있다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_point() + + facet_wrap(~class, nrow = 2) 측면으로 나누어 그려진 그래프는 서로 비교가 용이하도록 동일한 좌표축으로 그려진다. 측면 그래프의 상단에는 어떤 측면의 데이터에 대한 그래프인지를 표시한다. 맨 처음 측면 그래프는 2seater 측면에서 배기량과 고속도로 연비의 산점도를 보여주고, 맨 마지막 측면 그래프는 SUV 측면에서 배기량과 고속도로 연비의 산점도를 보여준다. 두 개 이상의 변수를 조합하여 측면 그래프을 만드려면 다음처럼 수식의 우변에 두 개의 변수를 +로 연결하여 기술하면 된다. 다음은 구동 방식(drv)와 조사 년도(year)의 값에 따라 그래프를 나누어 그린 예이다. 역시 모든 그래프의 좌표축은 동일하고 그래프 상단에 어떤 측면의 그래프인지를 표시하고 있는데 윗줄에 표시된 내용은 구동 방식의 값이고 아랫줄은 조사년도의 값이다. 따라서 첫 번째 측면 그래프는 4륜 구동이고 1999년도 조사한 데이터 측면에서 배기량과 고속도로 연비의 산점도를 보여준다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_point() + + facet_wrap(~drv + year, nrow = 2) 5.6.2 facet_grid()로 이차원 측면 그래프 그리기 그래프를 두 변수의 측면에서 나누어 그릴 때는 face_wrap() 보다는 facet_grid()를 사용하는 것이 좋다. facet_grid()도 수식을 첫 번재 인수로 입력 받는데, 수식의 좌변과 우변에 측면으로 나누는데 사용할 변수를 지정할 수 있다. 수식의 좌변에 기술된 변수를 기준으로 측면 그래프를 행으로 배열하고, 우변에 기술된 변수를 기준으로 측면 그래프를 열로 배열한다. 다음 그래프는 행은 구동 방식으로, 열은 실린더 수를 기준으로 나누어 측면 그래프를 그린 예이다. 그러므로 두 번째 행-세 번째 열의 그래프는 전륜 구동(f)이고 실린더가 6자동차의 산점도를 나타낸다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_point() + + facet_grid(drv~cyl) facet_wrap() 함수와 마찬가지로 수식의 좌변과 우변에 +로 하나 이상의 변수를 지정할 수도 있다. &gt; ggplot(mpg, aes(x=displ, y=hwy)) + geom_point() + + facet_grid(drv+year~cyl) 5.7 기타 ggplot2의 문법 요소 ggplot2에는 지금까지 설명한 문법 요소 외에도 통계 변환(stat), 위치 조정(position), 스케일 변환(scale), 좌표축 변환(coord), 테마(theme) 등의 요소가 있다. ggplot2를 사용하여 복잡한 시각화를 수행하려면 이러한 문법 요소에 대한 체계적 이해와 습득이 필요하다. 그러나 이 책은 데이터 시각화 전반을 소개하는 것이 목적이 아니기 때문에, 통계데이터 분석을 위한 그래프를 그릴 때 이러한 문법 요소가 필요하면 그 요소를 단편적으로 설명할 예정이다. 그러므로 좀 더 ggplot2 그래프에 대한 체계적인 이해를 원하는 독자는 R 프로그래밍의 ggplot2를 이용한 데이터 시각화를 참조하기 바란다. 이 절의 나머지 부분에서는 나머지 문법 요소 중 그래프의 외양을 변경하는 매우 간단한 한 가지 문법 요소만 살펴보도록 한다. 5.7.1 그래프 레이블을 조정하기 ggplot2 패키지의 labs() 함수는 그래프의 제목, 좌표축 이름, 범례의 이름을 쉽게 바꿀 수 있게 해준다. 다음은 mpg 데이터의 배기량과 고속도로 연비의 산점도를 자동차 종류 별로 다른 색상으로 그린 예이다. 그런데 ggplot2에서는 기본적으로 좌표축 레이블과 색상의 범례 레이블로, 좌표축과 색상에 매핑된 열의 이름을 사용한다. 그리고 그래프에 제목은 달지 않는다. &gt; ggplot(mpg, aes(x=displ, y=hwy, color=class)) + geom_point() 만약 자동으로 부여된 레이블이 마음에 들지 않으면 이를 labs() 함수로 변경할 수 있다. 위 그래프에서 다음처럼 범례 이름, 축의 이름 한글로 바꾸고, 그래프의 제목도 달아 보자. &gt; ggplot(mpg, aes(x=displ, y=hwy, color=class)) + geom_point() + + labs(title=&quot;배기량과 고속도로 연비 산점도&quot;, + x=&quot;배기량(리터)&quot;, y=&quot;고속도로 연비&quot;, color=&quot;자동차 종류&quot;) labs() 함수는 ggplot2 그래프에 + 연산으로 결합하여 사용되면, 그래픽 속성 매핑에 사용된 x, y, color 인수에 사용할 이름을 지정하면 된다. 그래프의 제목을 지정하려면 title이라는 인수를 사용한다. 함수를 +로 결합시키는 것은 ggplot2에서만 사용하는 방식으로 다른 R 함수에는 적용되지는 않는다.↩︎ "],["ch-introDescStat.html", "Chapter 6 기술통계 분석이란? 6.1 기술통계 기법의 중요성 6.2 기술통계 기법의 분류 6.3 bizstatp 패키지의 course 데이터 6.4 데이터 전체에 대한 요약 정보 파악하기", " Chapter 6 기술통계 분석이란? 6.1 기술통계 기법의 중요성 통계 데이터 분석에서 가장 쉽게 빠지는 오류 중에 하나가 데이터 자체에 대한 깊은 탐구 이전에 추론통계 기법을 성급히 적용하는 것이다. 추론통계 기법은 확률적 원리를 기반으로 하고 있는 강력한 데이터 분석 방법이긴 하지만, 추론통계 분석에서 사용되는 모형들은 데이터의 분포에 대한 많은 가정을 수반한다. 실제 데이터가 그러한 가정에 부합되지 않으면 추론통계 분석의 결과는 올바른 결과가 될 수 없다. 그러므로 추론통계 기법을 사용하기 전에 그러한 기법의 사용이 타당한지 데이터의 실제 분포에 대한 확인이 필요하다. 그러므로 통계 데이터 분석의 첫 단계이면서 가장 중요한 작업은 데이터 자체를 찬찬히 들여다 보는 것이다. 데이터가 들려주는 현상의 이면에 대하여 마음을 열고 경청하는 것이다. 앞서 설명하였듯이 통계 데이터는 방대하다. 그냥 찬찬히 들여다 보는 것만으로는 데이터의 이면을 파악하기 힘들다. 기술통계 분석 기법은 데이터의 다양한 측면을 일목요연 하게 파악할 수 있도록 도와준다. 따라서 추론통계 기법을 사용하기 이전에 우리는 다양한 관점에서 데이터를 요약해 보아야 한다. 그러기 위해서는 기술통계 분석 기법에 숙달되어야 한다. 기술통계 분석은 분석의 시작 단계로서의 중요성 뿐만 아니라, 다른 사람들에게 통계 데이터에 대한 요약된 정보를 제공하기 위해서도 필요하다. 실제 기업의 실무에서는 현상에 대한 소통을 위해 기술통계 분석이 추론통계 분석보다 빈번하게 이용된다. 6.2 기술통계 기법의 분류 그림 6.1은 기술통계 기법의 종류를 보여준다. 기술통계 기법은 크게 세 가지 관점에서 나누어 살펴볼 수 있다. 데이터 요약을 수치로 할 것인지 그래프로 할 것인지에 따라 기술통계 분석은 크게 수치로 요약하는 기법과 그래프로 요약하는 기법으로 나눌 수 있다. 1.4 절에서 우리는 통계 데이터에서 변수가 질적 정보를 다루는 범주형 변수와 양적 정보를 다루는 수치형 변수로 나누어진다고 하였다. 기술통계 분석에서는 분석하고자 하는 변수의 종류에 따라 요약의 방법이 달라진다. 기술통계는 주로 변수 하나하나의 분포를 알아보기 위해 사용되기도 하지만, 변수 사이의 상관성을 확인하기 위해서도 사용된다. 이 책에서는 먼저 범주형 변수에 대한 수치와 그래프로 요약하는 기술통계 기법을 먼저 살펴보고, 수치형 변수에 대한 기술통계 기법을 살펴본다. 그리고 마지막으로 범주형 변수와 수치형 변수가 혼재되어 있는 경우의 기술통계 기법에 대하여 살펴본다. Figure 6.1: 기술통계 기법의 분류 6.3 bizstatp 패키지의 course 데이터 이 책에서는 R을 사용하여 기술통계 기법을 설명하면서 어떤 대학 과목의 수강생에 대한 데이터를 탐색해 나갈 것이다. 6.3.1 bizstatp 패키지 설치 방법 이 데이터는 bizstatp라는 패키지에 포함되어 있는데, 이 패키지는 지금까지 보았던 CRAN을 통해 배포되는 공식 패키지가 아니라, 이 책으로 공부하는 수강생들을 위해 제작하여 배포되는 비공식적인 패키지이다. 따라서 지금까지 설치했던 방법과는 조금 다른 방식으로 설치를 수행하여야 한다. 6.3.1.1 Github을 통한 패키지 설치 bizstatp 패키지는 Github에 최신 버전이 공개되어 있다. Github에 올려놓은 패키지를 설치하려면 먼저 CRAN에서 devtools 패키지를 먼저 설치되어야 한다. 다음 명령을 R 콘솔에서 수행하든지 아니면 RStudio의 오른쪽 아래의 Package 탭을 이용하여 devtools 패키지를 설치한다. &gt; install.packages(&quot;devtools&quot;) devtools 패키지가 설치되었다면 R 콘솔에서 다음 명령을 실행하여 bizstatp 패키지를 설치한다. &gt; devtools::install_github(&quot;kilhwan/bizstatp&quot;) 설치가 완료되었으면 제대로 설치되었는지 확인하기 위해서 bizstatp 패키지를 적재하고 패키지에 포함되어 있는 course 데이터를 출력해 보자. &gt; library(bizstatp) &gt; course major year gender class mid final hw score 1 Others 4 M 1 62 66 83.60 73.47 2 Others 3 F 1 46 37 88.70 61.50 3 ME 2 M 1 94 82 87.90 89.18 4 ME 2 M 1 73 71 88.70 78.47 5 ME 2 M 1 96 93 90.60 93.88 6 ME 2 M 1 54 43 84.30 64.39 7 ME 2 M 1 52 72 84.70 72.60 8 ME 2 M 1 27 42 82.80 55.54 9 ME 2 M 1 41 41 84.30 59.89 ...... 이 모든 과정이 잘 이루어졌으면 설치가 잘 수행된 것이다. 따라서 다음 R 세션에서 bizstatp 패키지를 재설치하지 않고 library() 함수로 메모리에 적재만 다시 하면 된다. 같은 R 세션에서는 한번 패키지를 적재하면 다시 적재할 필요가 없다. 6.3.2 course 데이터 앞의 결과에서 보듯이 course 데이터는 어는 대학 과목의 수강생 데이터이다. 그 과목을 들은 수강생 45명의 전공(major), 학년(grade), 성별(gender), 분반(class), 중간고사 점수(midterm), 기말고사 점수(final), 숙제 점수(hw), 최종 평가 점수(scores)가 포함되어 있다. 전공은 ME 전공인가 기타 전공인가로 구분되어 있고, 분반은 해당 과목이 2개의 분반으로 진행되었으므로 1분반, 2분반으로 구분되어 있다. 이 책 전체를 통해서 위와 같이 course 데이터를 포함하고 있는 bizstatp 패키지가 이미 적재되어 있다고 가정하고 설명을 한다. 6.4 데이터 전체에 대한 요약 정보 파악하기 변수 하나하나를 분석하기에 앞서 데이터의 전체적인 모습을 먼저 파악하는 것이 좋다. 그래야 어떤 변수를 더 중점적으로 분석할지 판단할 수 있고 데이터에 문제가 없는지 분석 전에 파악할 수 있기 때문이다. 6.4.1 summary() 함수를 이용하여 변수 별로 통계 요약하기 데이터의 모든 열에 대하여 수치적으로 요약해 보고 싶으면 summary() 함수를 사용한다. &gt; summary(course) major year gender class mid final ME :40 1: 1 F:18 1:22 Min. :27.00 Min. :23.00 Others: 5 2:32 M:27 2:23 1st Qu.:45.50 1st Qu.:47.00 3: 9 Median :59.00 Median :65.50 4: 3 Mean :61.61 Mean :63.16 3rd Qu.:79.75 3rd Qu.:76.50 Max. :97.00 Max. :95.00 NA&#39;s :1 NA&#39;s :1 hw score Min. : 0.00 Min. :10.00 1st Qu.:82.80 1st Qu.:61.50 Median :84.30 Median :72.60 Mean :83.37 Mean :71.46 3rd Qu.:88.70 3rd Qu.:80.49 Max. :91.33 Max. :95.00 summary() 함수는 데이터의 프레임의 각 열에 대한 통계요약 정보를 보여준다. 범주형 변수(열)는 각각의 범주 별로 절대 빈도(관측 횟수)를 보여준다. gender 열을 요약한 결과를 보면 course 데이터에 여자(F)가 18 명, 남자(M) 27 명 포함되어 있음을 볼 수 있다. 수치형 변수(열)는 최소값(Min.), 최대값(Max.), 평균(Mean), 1분위수(1st Qu.), 중위수(Median), 3분위수(3rd Qu.)로 요약하여 정보를 보여준다. score 열에 대한 요약 정보를 확인하라. 아울러 열에 결측치가 있으면 NA라는 항목으로 결측치의 개수를 보여준다. 중간고사(mid) 열과 기말고사(final) 열에 한 개씩 데이터가 없는 결측치가 있음을 볼 수 있다. 6.4.2 plot() 함수를 이용한 변수 사이의 상관성 파악 변수들 사이의 상관성을 빠르게 검토하고 싶으면 R의 기본 graphics 패키지의 plot() 함수를 사용한다. plot() 함수를 데이터 프레임에 적용하면 데이터 프레임의 모든 두 변수 조합에 대한 산점도를 행렬 형태로 보여준다. &gt; plot(course) course 데이터의 수치형 변수들 간의 산점도만 파악하려면 5 번째에서 8 번째 변수가 수치형 변수이므로 다음처럼 course 데이터의 열을 필터링하면 수치형 변수 사이의 산점도를 확인할 수 있다. &gt; plot(course[, 5:8]) 중간고사(mid), 기말고사(final), 총점(score) 사이의 강한 양의 상관성이 보이나, 숙제 점수(hw)과 다른 변수의 상관성을 약함을 확인할 수 있다. "],["ch-categoricalDescStat.html", "Chapter 7 범주형 변수에 대한 R 기술통계 7.1 한 범주형 변수에 대한 분포 분석 7.2 둘 이상의 범주형 변수의 상관성 분석 7.3 범주형 변수의 분석 사례", " Chapter 7 범주형 변수에 대한 R 기술통계 1.4 절에서 살펴보았듯이 범주형 변수는 관측대상이 속하는 범주를 나타내는 데이터이다. bizstatp 패키지에 있는 course 데이터의 전공(major), 학년(year), 성별(gender), 분반(class) 열이 범주형 변수이다. 이런 변수들은 한 학생이 어떤 범주에 포함되는지를 나타낸다. 예를 들어 course 데이터의 첫 행을 보면 이 학생은 비 ME 전공, 4학년, 남성(M), 1분반의 범주에 속함을 알 수 있다. &gt; library(bizstatp) &gt; head(course) major year gender class mid final hw score 1 Others 4 M 1 62 66 83.6 73.47 2 Others 3 F 1 46 37 88.7 61.50 3 ME 2 M 1 94 82 87.9 89.18 4 ME 2 M 1 73 71 88.7 78.47 5 ME 2 M 1 96 93 90.6 93.88 6 ME 2 M 1 54 43 84.3 64.39 범주형 변수에 대한 기술통계 분석은 범주 별로 관측빈도의 분포를 구하는 것이 주를 이룬다. course 데이터를 예로 들면 이 과목을 수강하는 남성과 여성의 빈도, 학년별 빈도, 전공별 빈도 등이 범주형 변수 분석의 일차적 관심사라 할 수 있다. 또한 범주형 변수는 특히 사람들의 태도나 의견을 조사하는 사회과학이나 마케팅 조사분석에서 자주 사용되는 척도이다. 이 장에서는 한 범주형 변수에 대한 분포를 분석하는 방법과 여러 개의 범주형 변수 간의 상관성을 분석하는 방법으로 나누어 R을 이용한 기술통계 방법을 설명한다. 7.1 한 범주형 변수에 대한 분포 분석 한 범주형 변수를 분석할 때 관심의 초점은 범주별 분포를 확인하는 것이다. 범주별 분포로부터 다음과 같은 통계적 질문에 대한 답을 탐구한다. 어떤 범주가 가장 많은 빈도를 보이는가? 왜 이 범주가 많이 발생하였는가? 빈도가 희소한 범주는 무엇이고 왜 발생이 적은가? 범주별 발생 빈도의 분포가 분석자의 예상과 맞는가? 틀리다면 그 원인은 무엇인가? 7.1.1 범주형 변수 분포를 수치로 요약하기 - 빈도표 구하기 범주별 분포를 수치로 요약할 때는 크게 다음 두 가지 방식 중 하나를 이용한다. 절대 빈도표: 범주 별로 실제 관측된 횟수(빈도)를 표로 나타낸다. 상대 빈도표: 전체 관측 횟수를 1로(100%)로 하였을 때 범주 별 상대적 빈도(비율 또는 백분율)을 표로 나타낸다. 절대 빈도표는 실제 관측 빈도를 확인할 수 있어 더 정확한 방식이지만, 범주 별 빈도를 한눈에 파악하기 어려운 단점이 있다. 다음은 course 데이터의 학년 변수에 대한 절대 빈도표와 상대 빈도표를 R에서 구한 예이다. Table 7.1: 학년 변수의 절대 빈도표 year Freq 1 1 2 32 3 9 4 3 Table 7.2: 학년 변수의 상대 빈도표(%) year Freq 1 2.22 2 71.11 3 20.00 4 6.67 7.1.1.1 절대 빈도표 만들기 R에는 절대 빈도표를 만들기 위해 다음 명령어들을 사용할 수 있다. 기본 base 패키지의 table() 함수 (별도의 패키지 적재 불필요 없음) 기본 stat 패키지의 xtabs() 함수 (별도의 패키지 적재 불필요 없음) reshape2 패키지의 acast() 또는 dcast() 함수 (reshape2 패키지 적재 필요) dplyr 패키지의 count() 함수 (dplyr 패키지 적재 필요) 이 책에서는 R의 기본 기능으로 제공하는 table()과 xtabs() 함수를 이용하는 방법을 설명한다. table()과 xtabs() 함수를 사용하는 방법은 문법과 빈도표를 표현하는 방식이 모두 단순하고 직관적이서 사용자가 이해하기 쉽고 사용하기 편리하다. 또한 만들어진 빈도표를 R의 기본 가설검정 함수에 바로 사용할 수 있는 장점도 있다. 다만 빈도표를 자유자재로 변형하기가 까다로운 단점이 있다. 그러므로 빈도표를 이용하여 다양한 후속 작업을 하는 경우에는 dplyr 패키지를 사용하여 빈도표를 구하는 것이 좋다. 아울러 reshape2 패키지는 빈도표 또는 분할표를 만들 때 행과 열을 다양한 형식으로 배열할 수 있는 장점이 있다. 만약 빈도표를 원하는 방식으로 변형하여 출력하기를 원하면 reshape2 패키지를 사용하는 것이 좋다. table() 함수로 절대 빈도표 만들기 table() 함수로 한 변수의 절대 빈도표를 만드는 문법은 다음과 같다. table(벡터) table(데이터프레임$열이름) 다음은 x라는 문자열 벡터에 대한 절대빈도표를 table() 함수로 구한 예이다. &gt; x &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;) &gt; table(x) x a b 1 2 table() 함수는 벡터를 인수로 받으므로, 데이터프레임의 열의 빈도를 구하기 위해서는 $ 연산자를 이용하여 데이터 프레임의 열을 지정하여야 한다. 다음은 course 데이터에서 학년, 전공, 성별, 분반별 절대 빈도표를 구한 결과이다. 해당 과목은 2학년이 주로 수강하였고, ME 전공이 주로, 남학생이 더 많이 수강하였음을 알 수 있다. &gt; table(course$year) 1 2 3 4 1 32 9 3 &gt; table(course$major) ME Others 40 5 &gt; table(course$gender) F M 18 27 &gt; table(course$class) 1 2 22 23 xtabs() 함수로 절대 빈도표 만들기 데이터 프레임에 있는 열을 table() 함수로 빈도표를 만드려면, $ 연산자를 사용하여 데이터 프레임의 열을 지정해야 한다. 뒤에서 보겠지만 여러 열을 조합하여 분할표를 만드려면 매번 데이터 프레임의 열을 $ 연산자로 지정하여야 한다. 이는 매우 번거롭고 오류 발생을 증가시킨다. xtabs() 함수를 사용하면 data 인수에 데이터 프레임을 지정한 후 빈도표나 분할표를 만들 때 사용할 데이터 프레임의 열을 수식(formula)의 형식으로 지정할 수 있다. 다음은 xtabs()의 기본 문법이다. xtabs(수식, data=데이터프레임) 수식은 데이터프레임의 열의 수학적 관계를 나타내는 R 객체로 다음처럼 ~로 수식의 좌변과 우변에 표시될 열을 지정한다. 열이름1 + 열이름2 + ... ~ 열이름A + 열이름B + ... xtabs() 함수를 이용하여 한 범주형 변수의 절대 빈도표를 구하는 문법은 다음과 같다. 수식의 좌변은 비워둔 채로 빈도를 구할 변수를 우변에 기술한다. xtabs()의 첫 인수는 반드시 수식이어야 하므로 ~가 생략되면 안된다. xtabs(~ 열이름, data = 데이터프레임) 다음은 xtabs()를 사용하여 course의 학년 변수의 절대 빈도표를 구한 예이다. &gt; xtabs(~ year, data = course) year 1 2 3 4 1 32 9 3 table()과 동일한 결과와 형식인데 다른 점은 빈도표로 요약되는 열의 이름이 함께 출력되는 점이다. xtabs()는 한 변수의 모든 관측치에 대한 절대 빈도표를 구할 수 있을 뿐 아니라 subset 인수를 사용하면 특정 조건에 부합되는 관측치만 뽑아 절대 빈도표를 구할 수 있다. subset 인수에는 논리값 벡터가 설정되어야 하고 논리값 벡터의 TRUE 위치의 요소만 필터링되어 빈도표가 구해진다. xtabs(~ 열이름, data = 데이터프레임, subset = 논리값벡터) 다음은 4.1.2.3 절에서 설명한 비교 연산을 사용하여 남학생의 학년별 절대 빈도표와 2분반의 학년별 절대 빈도표를 구한 예이다. &gt; xtabs(~ year, data = course, subset = gender == &quot;M&quot;) year 1 2 3 4 1 18 6 2 &gt; xtabs(~ year, data = course, subset = class == 2) year 1 2 3 4 1 14 6 2 xtabs()는 subset 외에도 다양한 조건을 지정하여 빈도표를 만들 수 있다. 관심있는 독자는 xtabs() 함수의 도움말을 참조하기 바란다. 마지막으로 뒤에 상대 빈도표를 만들 때 사용하기 위하여 학년, 전공, 성별, 분반별 절대 빈도표를 변수에 할당하도록 한다. &gt; freqYear &lt;- xtabs(~ year, data = course); freqYear year 1 2 3 4 1 32 9 3 &gt; freqMajor &lt;- xtabs(~ major, data = course); freqMajor major ME Others 40 5 &gt; freqGender &lt;- xtabs(~ gender, data = course); freqGender gender F M 18 27 &gt; freqClass &lt;- xtabs(~ class, data = course); freqClass class 1 2 22 23 7.1.1.2 상대 빈도표 만들기 R 기본 패키지에서 상대 빈도표는 절대 빈도표를 이용하여 만들어진다. 상대 빈도표를 만드는 명령어는 proportions()와 prop.table()이 있는데, 두 함수는 같은 기능을 한다. prop.table()은 이전 버전의 R에서 사용되던 이름인데 하위 버전과의 호환성을 위해서 제공되는 함수이다. 그러므로 이 책에서는 proportions()을 사용하여 상대 빈도표를 구한다. proportions()을 이용하여 상대 빈도표를 구하는 문법은 다음과 같다. proportions(절대빈도표) 다음은 학년과 성별에 대한 상대 빈도표를 구한 예이다. 상대 빈도표는 전체를 1로 하여 각 범주의 상대적 빈도(비율)을 계산한다. &gt; proportions(freqYear) year 1 2 3 4 0.02222222 0.71111111 0.20000000 0.06666667 &gt; proportions(freqGender) gender F M 0.4 0.6 상대 빈도표를 백분율로 표현하고 싶으면, 비율로 나오는 상대 빈도표에 100을 곱하면 된다. 그러면 4.1.3 절에서 설명한 벡터 연산에서의 요소의 재활용과 같은 원리로 모든 요소에 100이 곱해져서 전체가 100으로 표현된 백분율로 값이 표현된다. 즉, 2학년의 비율은 71.11 %이었다. &gt; proportions(freqYear) * 100 year 1 2 3 4 2.222222 71.111111 20.000000 6.666667 만약 백분율 표시를 반올림하여 표시하고자 하면 round() 함수를 사용한다다. 다음은 round() 함수의 사용 예와 round() 함수를 사용하여 백분율로 표현된 상대 빈도표를 소수 둘째 자리로 반올림 한 결과이다. &gt; round(1.2345, digits=2) [1] 1.23 &gt; round(proportions(freqYear) * 100, digits=2) year 1 2 3 4 2.22 71.11 20.00 6.67 7.1.2 범주형 변수 분포를 그래프로 요약하기 7.1.2.1 막대 그래프 그리기 빈도표를 가지고도 범주 별로 발생 빈도를 확인할 수 있지만, 그래프로 표현하는 것이 이해하기 더 쉽다. 범주별 발생 빈도를 그래프로 표현하는 대표적 방법이 막대 그래프이다. 막대 그래프는 범주 별로 발생 빈도에 따라 막대의 길이를 다르게 하여 범주별 빈도 차이를 파악하기 쉽게 해준다. 이 절에서는 ggplot2 패키지를 이용하여 막대 그래프를 그리는 방법을 알아본다. 절대 빈도로 막대 그래프 그리기 ggplot2 패키지의 geom_bar() 함수를 이용하면 x 속성에 매핑된 범주형 변수에 대하여 범주별 절대 빈도(관측 도수)에 따라 막대 그래프를 그려준다. 다음은 geom_bar() 함수를 사용하여 절대 빈도로 막대 그래프를 그리는 문법이다. ggplot(데이터, aes(x = 범주형변수)) + geom_bar() 다음은 course 데이터의 학년(year) 범주형 변수에 대해 절대 빈도로 막대 그래프를 그린 예이다. 범주형 변수의 범주를 가로축으로, 각 범주의 절대 빈도(count)를 세로축으로 하여 막대 그래프가 그려지는 것을 볼 수 있다. &gt; library(ggplot2) # R 세션을 다시 시작하였으면 ggplot2를 먼저 적재한다. &gt; ggplot(course, aes(x = year)) + geom_bar() 막대 그래프의 막대의 채우기 색상을 변경하려면 geom_bar()의 fill 인수에 색을 지정해 주면 된다. (지정할 수 있는 색상 이름을 확인하려면 colors() 명령을 콘솔에서 실행해 보라. 그러면 657 개의 색상 이름이 출력될 것이다.) 여기서 주의할 점은 나중에 보게 될 aes() 안에 기술하게 되는 fill 속성과 이 fill 인수는 둘 다 막대의 채우기 색상을 지정하지만, 문법적으로 차이가 있다는 것이다. 이 두 방식의 차이에 대한 자세한 설명은 R 프로그래밍의 도형의 속성에 대응시키기 vs. 도형의 속성 인수를 설정하기 절을 참고하기 바란다. &gt; ggplot(course, aes(x = gender)) + geom_bar(fill=&quot;orange&quot;) 상대 빈도로 막대 그래프 그리기 절대 빈도뿐만 아니라 상대 빈도로 빈도표를 표현할 수 있는 것 같이 막대 그래프도 상대 빈도를 세로축으로 하여 그릴 수 있다. 상대 빈도로 막대 그래프를 그리는 문법은 다음과 같다. ggplot(데이터, aes(x = 범주형변수, y = ..prop.., group = 1)) + geom_bar() 상대 빈도로 막대 그래프를 그리는 함수도 geom_bar() 함수이다. x 속성에 범주형 변수를 매핑하는 것은 동일하나, 세로축이 절대 빈도가 아니라 상대 빈도라는 것을 지정하기 위해 y속성을 ..prop..이라는 열에 매핑한다. ..prop.. 원 데이터에 있는 열이 아니라 geom_bar() 함수가 범주형 변수를 절대 빈도와 상대 빈도로 요약한 내부 데이터의 열 이름이다. 그리고 group 속성에 1을 매핑한다.5 상대 빈도는 group 별로 전체가 1이 되도록 상대 빈도를 계산하는데, 전체 관측치를 대상으로 상대 빈도를 구하려면 모든 데이터가 동일한 그룹에 속해야 한다. 그래서 모든 관측치가 group = 1이라는 동일한 그룹이 되도록 설정하였다. 좀 더 자세한 설명을 원하는 독자는 R 프로그래밍의 범주형 변수의 통계 요약 절과 group 속성 절을 참조하라. 다음은 course 데이터의 학년 열에 대한 상대 빈도 막대 그래프를 그린 예이다. 그래프의 모양은 절대 빈도로 막대 그래프를 그린 것과 동일하지만, 세로축의 척도가 상대 빈도로 변하였고, 세로축의 이름도 비율(proportion)을 나타내는 prop이라는 이름으로 바뀐 것을 볼 수 있다. 상대 빈도로 막대 그래프를 그리자 3 학년 학생의 비율이 약 20%였음을 쉽게 확인할 수 있다. 절대 빈도로 그린 막대 그래프에서는 이를 바로 확인하기는 어렵다. &gt; ggplot(course, aes(x = year, y=..prop.., group=1)) + geom_bar() Warning: The dot-dot notation (`..prop..`) was deprecated in ggplot2 3.4.0. ℹ Please use `after_stat(prop)` instead. 막대 그래프의 좌표축 반전시키기 범주형 변수의 범주의 수가 많아지면 막대 그래프에 표시되어야 할 막대의 수도 많아진다. 이러한 경우 가로축과 세로축을 반전시켜 막대를 가로로 표현하는 것이 보기 좋을 때가 많다. ggplot2에서는 coord_flip() 함수를 사용하면 간단히 좌표축이 서로 반전되어 표현된다. 다음은 mpg 데이터의 자동차 종류(class) 열에 대한 막대 그래프를 원래의 좌표축으로, 그리고 반전된 좌표축으로 그린 예이다. &gt; ggplot(mpg, aes(x = class)) + geom_bar() &gt; ggplot(mpg, aes(x = class)) + geom_bar() + coord_flip() 빈도 순으로 막대 그리기 범주가 매우 많은 경우에는 가장 빈번히 발생하는 범주를 쉽게 파악하기 위해서는 빈도 순으로 막대가 나타나도록 범주의 순서를 정렬하는 것이 좋다. 범주형 변수의 나열 순서를 빈도 순으로 바꾸고 싶으면 다음처럼 reorder() 함수를 사용하여 범주가 나타나는 순서를 바꾼 다음에 x 속성에 매핑한다. ggplot(데이터, aes(x = reorder(범주형변수, 범주형변수, length)) + geom_bar() 다음은 mpg 데이터의 자동차 종류(class) 열에 대한 막대 그래프를 빈도 순으로 정렬하여 그린 예이다. 좌표축도 반전을 시켜보았다. &gt; ggplot(mpg, aes(x = reorder(class, class, length))) + + geom_bar() + coord_flip() + labs(x = &quot;자동차 종류&quot;) 앞서 설명한 reorder() 함수의 원리를 좀 더 자세히 살펴보자. reorder() 함수의 일반적 문법은 다음과 같다. reorder(범주형변수, 기준변수, FUN) reorder() 함수는 첫번째 인수로 제공된 범주형 변수의 범주의 순서를 결정하기 위하여, 먼저 같은 길이의 기준 변수를 범주형 변수의 범주에 따라 부분 집합으로 나눈다. 그리고 각 범주에 대응되는 기준 변수의 부분 집합에 FUN 인수에 정의된 함수를 정의한다. 이 함수는 벡터를 입력받아 하나의 숫자를 반환하는 함수이어야 한다. 각 범주 별로 FUN 함수의 값을 구한 후, 이 값을 내림차순으로 정렬하여 범주의 순서를 결정한다. 다음의 예는 course 데이터에서 학년(year) 변수를 각 학년의 빈도 순으로 정렬한 예이다. 이 예에서 범주를 정렬할 변수는 year이므로 reorder() 함수의 첫 번째 인수로 year 변수가 입력되었고, 정렬의 기준도 year의 빈도에 따라 정렬할 것이므로 기준 변수도 year가 입력되었다. 그리고 벡터의 길이를 계산하는 length() 함수를 이용하여 학년 별로 나누어진 데이터의 개수를 계산하여, 그 개수를 기준으로 내림차순으로 범주가 정렬된 것을 확인할 수 있다. &gt; course$year [1] 4 3 2 2 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 3 4 3 4 3 3 2 3 2 2 2 2 2 2 3 1 [39] 2 2 2 2 2 2 2 Levels: 1 &lt; 2 &lt; 3 &lt; 4 &gt; reorder(course$year, course$year, length) [1] 4 3 2 2 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 3 4 3 4 3 3 2 3 2 2 2 2 2 2 3 1 [39] 2 2 2 2 2 2 2 attr(,&quot;scores&quot;) 1 2 3 4 1 32 9 3 Levels: 1 &lt; 4 &lt; 3 &lt; 2 &gt; ggplot(course, aes(x=reorder(year, year, length))) + + geom_bar() 다음의 예는 course 데이터에서 성별(gender) 변수를 각 학년의 총점(score)의 평균 순으로 정렬한 예이다. 이 예에서 범주를 정렬할 변수는 gender이므로 reorder() 함수의 첫 번째 인수로 gender 변수가 입력되었고, 정렬의 기준은 score의 평균에 따라 정렬할 것이므로 기준 변수는 score가 입력되었다. 그리고 숫자 벡터에서 평균을 계산하는 mean() 함수를 이용하여 성별로 나누어진 총점의 평균을 계산하여, 그 값을 기준으로 내림차순으로 범주가 정렬된 것을 확인할 수 있다. &gt; course$gender [1] M F M M M M M M M M M F F M F F F F F M F F F F M M M M M M M M M M M M M M [39] F M F F F F F Levels: F M &gt; reorder(course$gender, course$score, mean) [1] M F M M M M M M M M M F F M F F F F F M F F F F M M M M M M M M M M M M M M [39] F M F F F F F attr(,&quot;scores&quot;) F M 71.97611 71.11741 Levels: M F &gt; ggplot(course, aes(x=reorder(gender, score, mean))) + + geom_bar() &gt; ggplot(course, aes(x=reorder(gender, score, mean), y=score)) + + geom_boxplot() 7.1.2.2 파이 차트 그리기 TV 뉴스나 신문 기사를 보면 상대적 빈도를 그래프로 표현할 때 막대그래프 외에도 파이 차트를 이용하는 경우가 많다. 기술통계학에서는 파이 차트보다는 막대 그래프로 빈도를 표현하는 것을 권장한다. 왜냐하면 사람은 길이의 차이는 민감하게 파악하지만 넓이의 차이는 쉽게 구별하지 못하기 때문이다. 그러나 파이 차트는 매우 대중적으로 사용되므로 어떻게 그리는지 알아본다. ggplot2에서 막대 그래프를 파이 차트로 바꾸는 것은 조금 어렵다. 그래프 문법에 따라 좌표축의 형태를 직교좌표계에서 극좌표계로 바꾸어주면 파이 차트를 그릴 수 있으나 절차가 복잡하여 ggplot2에서 파이 차트를 그리는 방법은 생략하도록 한다. 대신 R의 기본 graphics 패키지의 pie() 함수를 사용하여 파이 차트를 그려본다. pie() 함수의 기본 문법은 다음과 같다. 빈도표는 7.1.1 절에서 설명한 방식으로 구한 빈도표를 의미한다. pie(빈도표) 다음은 앞서서 만들어 둔 학년 변수의 빈도표 freqYear을 사용하여 파이 그래프를 그린 예이다. main이라는 인수를 사용하여 그래프의 제목도 달아 보았다. &gt; pie(freqYear, main = &quot;학년별 수강생 비율&quot;) 위 예에서 범주의 이름과 함께 원모양의 파이가 빈도에 따라 분할되어 그려짐을 볼 수 있다. 그런데 막대그래프는 세로축의 눈금으로 각 범주의 절대 또는 상대 빈도를 알 수 있지만 파이 차트은 분할된 영역의 빈도가 얼마를 나타내는지 파악하기가 힘들다. 따라서 보통 파이 차트는 분할된 영역에 상대 빈도의 값을 표현할 때가 많다. pie() 함수의 label 인수를 사용하면 범주 별로 표시될 레이블을 지정할 수 있다. 다음 예의 첫째 줄은 범주 별 레이블을 생성하는 명령문이다. 이에 대한 자세한 문법적 설명을 생략하도록 한다. 둘째 줄은 pie() 함수의 label 인수에 첫째 줄에서 생성한 레이블을 입력하여 파이 차트를 그리는 명령문이다. &gt; yearLabels &lt;- paste0(names(freqYear), &quot;학년: &quot;, round(proportions(freqYear) * 100, digits=2),&quot;%&quot;) &gt; pie(freqYear, label = yearLabels, main = &quot;학년별 수강생 비율&quot;) 7.2 둘 이상의 범주형 변수의 상관성 분석 범주형 변수 하나하나의 분포를 확인하였으면, 여러 범주형 변수 사이의 상관성을 확인해 보아야 한다. 범주형 변수 사이의 상관성 분석을 통해 다음과 같은 통계적 질문들에 대한 답을 탐구한다. 한 범주형 변수의 값에 따라 다른 한 범주형 변수의 발생 빈도가 영향을 받는가? 예를 들어 다음과 같은 질문에 대해 탐구할 수 있다. 성별에 따라 마케팅 프로그램의 반응 빈도가 달라지는가? 코로나 백신 접종자와 미접종자에 따라 코로나 감염 빈도에 차이가 있는가? 다른 한 범주형 변수에 의해 다른 범주형 변수의 발생 빈도가 달라진다면 그 차이는 어느 정도인가? 기술통계 분석에서 두 범주형 변수의 상관성이 관측되었다면 추론통계 분석을 통해 이러한 상관성이 통계적으로 유의미한지 가설검정해 보거나, 이 관계를 이용하여 한 범주형 변수의 값이 알려져 있을 때 다른 범주형 변수의 값을 예측하는 모형을 개발할 수 있다. 7.2.1 범주형 변수의 상관성을 수치로 요약하기 - 교차표 만들기 7.2.1.1 절대 빈도로 교차표 만들기 앞에서 course 데이터에서 성별, 학년별로, 각각 하나의 범주형 변수에 대한여 빈도표를 만들어 보았다. 만약 성별에 따른 학년별 분포가 차이가 있는지, 반대로 학년별로 성별 분포의 차이가 있는지를 파악해 보고자 한다면, 남자-1학년, 여자-1학년 등등 성별-학년의 모든 가능한 값의 조합에 대해 발생 빈도를 확인해 보아야 한다. 이렇게 두 개의 범주형 변수 간의 상관성을 파악하기 위해 한 변수의 범주를 행으로, 다른 한 변수의 범주를 열로 하여, 두 변수의 범주가 교차하는 칸마다 관측 빈도를 행렬 형태로 요약한 표를 교차표(cross tables) 또는 분할표(contingency tables)라고 한다. 표 7.3은 course 데이터에서 성별을 행으로, 학년을 열로 한 교차표를 보여준다. Table 7.3: 성별-학년 교차표 1 2 3 4 F 0 14 3 1 M 1 18 6 2 빈도표와 마찬가지로 R에서 교차표를 만드는 방법은 다음 네 가지 방법이 있다. 기본 base 패키지의 table() 함수 (별도의 패키지 적재 불필요 없음) 기본 stat 패키지의 xtabs() 함수 (별도의 패키지 적재 불필요 없음) reshape2 패키지의 acast() 또는 dcast() 함수 (reshape2 패키지 적재 필요) dplyr 패키지의 count() 함수 (dplyr 패키지 적재 필요) 이 책에서는 R의 기본 기능으로 제공하는 table()과 xtabs() 함수를 이용하여 교차표를 만드는 방법을 설명한다. table() 함수로 교차표 만들기 table() 함수를 사용하면 빈도표와 동일한 문법으로 두 개 이상의 범주형 변수에 대한 교차표를 구할 수 있다. 다만 인수가 하나가 아니라 두 개 또는 여러 개의 범주형 변수를 인수로 나열해 주면 된다. table(벡터1. 벡터2, ...) table(데이터프레임$열이름1, 데이터프레임$열이름2, ...) 다음은 course 데이터에서 성별과 학년의 교차표를 table() 함수로 구한 예이다. 첫째 인수로 기술된 변수의 범주가 행으로, 둘째 인수로 기술된 변수의 범주가 열로 표현되어 교차표가 구해지는 것을 볼 수 있다. &gt; table(course$gender, course$year) 1 2 3 4 F 0 14 3 1 M 1 18 6 2 만약 학년을 행으로, 성별을 열로 하여 교차표를 구하고 싶다면 다음처럼 두 인수의 위치를 바꾸어 주면 된다. &gt; table(course$year, course$gender) F M 1 0 1 2 14 18 3 3 6 4 1 2 만약 세 범주형 변수의 교차표를 구하려면, 세 변수를 차례로 기술한다. 그러면 첫 번째, 두 번째, 세 번째로 기술된 변수가 각각 교차표의 행, 열, 층(layer)이 되어 3차원의 교차표가 만들어 진다. 다음은 성별을 행으로, 학년을 열로, 분반을 층으로 하여 교차표를 구한 예이다. 2차원인 컴퓨터 화면 상에서 3차원 데이터를 표현할 수 없으므로 층 별로 나누어 교차표가 나타났다. 첫 번째 행렬이 1분반의 성별-학년 교차표이고, 두 번째 행렬이 2분반의 성별-학년 교차표이다. &gt; table(course$gender, course$year, course$class) , , = 1 1 2 3 4 F 0 8 2 0 M 0 10 1 1 , , = 2 1 2 3 4 F 0 6 1 1 M 1 8 5 1 xtabs() 함수로 교차표 만들기 빈도표와 마찬가지로 xtabs() 함수를 사용하면 data 인수에 데이터 프레임의 열을 $ 연산자로 사용하지 않고도 지정할 수 있기 때문에 데이터에서 여러 개의 열을 지정해야 하는 교차표를 만들 때 xtabs()는 매우 편리하다. 범주형 변수가 하나일 때와 달라진 점은 수식의 우변에 교차표에 사용될 범주형 변수를 +로 연결하여 표현한다는 것이다. xtabs(~ 열이름1 + 열이름2 + ..., data = 데이터프레임) 수식의 우변에 첫 번째 기술되는 변수가 행, 두 번째 기술되는 변수가 열, 세 번째 기술되는 변수가 층이 되어 교차표가 만들어 진다. 두 변수만 기술되면 행렬 형식의 교차표가 만들어 진다. 다음은 course 데이터에서 성별-학년 2차원 교차표, 성별-분반 2차원 교차표, 그리고 성별-학년-분반의 3차원 교차표를 xtabs() 함수로 구한 예이다. &gt; freqGenderYear &lt;- xtabs(~ gender + year, data=course); freqGenderYear year gender 1 2 3 4 F 0 14 3 1 M 1 18 6 2 &gt; freqGenderClass &lt;- xtabs(~ gender + class, data=course); freqGenderClass class gender 1 2 F 10 8 M 12 15 &gt; freqGenderYearClass &lt;- xtabs(~ gender + year + class, data=course); freqGenderYearClass , , class = 1 year gender 1 2 3 4 F 0 8 2 0 M 0 10 1 1 , , class = 2 year gender 1 2 3 4 F 0 6 1 1 M 1 8 5 1 한 범주형 변수의 빈도표를 만들 때 설명한 것처럼 xtabs() 함수의 장점은 열 이름을 table() 함수보다 편리하게 지정할 수 있다는 점뿐만 아니라, 특정 조건의 데이터만 선택하여 교차표를 만들 수 있다는 점이다. 만약 총점(score)가 80점 이상인 학생과 미만인 학생의 성별-학년별 상관성을 나누어 분석한다고 하자. 다음처럼 subset 인수에 해당 조건인 관측만 TRUE가 되도록 논리값 벡터를 지정해 주면 해당 조건의 관측만으로 교차표를 생성한다. &gt; xtabs(~ gender + year, data=course, subset = score &gt;= 80) year gender 1 2 3 4 F 0 4 1 1 M 0 3 3 1 &gt; xtabs(~ gender + year, data=course, subset = score &lt; 80) year gender 1 2 3 4 F 0 10 2 0 M 1 15 3 1 교차표에서 빈도표 구하기 원 데이터에서 빈도표를 직접 구할 수도 있지만, 교차표에서 각 범주형 변수의 빈도표를 구할 수도 있다. 표 7.3처럼 course 데이터에서 성별을 행으로, 학년을 열로 한 교차표가 있으면, 행으로 교차표의 빈도를 합산하면 성별 빈도표가 만들어지고, 열로 교차표의 빈도를 합산하면 학년 빈도표가 만들어지는 것을 알 수 있다. marginSums() 또는 margin.table() 함수를 이용하면 교차표를 행별 또는 열별로 합산하면 빈도표를 구할 수 있다. margin은 교차표를 어느 방향으로 합산하여 빈도표를 만들지를 지정한다. 1이면 행으로, 2이면 열로 합산을 한다. margin 인수에 값을 주지 않으면 교차표의 모든 빈도를 합하여 총 빈도를 구한다. marginSums(교차표) # 총 빈도 합산 marginSums(교차표, margin = 1) # 행으로 빈도 합산 marginSums(교차표, margin = 2) # 열로 빈도 합산 다음은 성별-학년 2차원 교차표에서 전체, 성별, 학년별 관측빈도의 합을 구한 예이다. marginSums() 함수 호출 시 margin 인수를 기술하지 않으면 교차표의 총 빈도가, margin 인수가 1이면 교차표의 행별 합이, margin 인수가 2이면 교차표의 열별 합이 결과로 주어진다. &gt; marginSums(freqGenderYear) [1] 45 &gt; marginSums(freqGenderYear, margin=1) gender F M 18 27 &gt; marginSums(freqGenderYear, margin=2) year 1 2 3 4 1 32 9 3 만약 교차표에 행별, 열별 합을 포함하여 출력하고 싶으면 addmargins() 함수를 이용한다. &gt; addmargins(freqGenderYear) year gender 1 2 3 4 Sum F 0 14 3 1 18 M 1 18 6 2 27 Sum 1 32 9 3 45 3차원 교차표에서도 marginSums()를 이용하여 빈도표를 만들 수 있다. 3차원 교차표에서는 margin 인수에 3을 부여하면 층별로 합산이 이루어 진다. 다음은 성별-학년-분반 교차표에서 전체 총 빈도, 성별 빈도, 학년 빈도, 분반별 빈도를 구한 예이다. &gt; marginSums(freqGenderYearClass) [1] 45 &gt; marginSums(freqGenderYearClass, margin=1) gender F M 18 27 &gt; marginSums(freqGenderYearClass, margin=2) year 1 2 3 4 1 32 9 3 &gt; marginSums(freqGenderYearClass, margin=3) class 1 2 22 23 3차원 교차표에서는 marginSums()를 이용하여 2차원 교차표도 만들 수 있다. 예를 들어 성별-학년-분반 교차표에서 행과 열을 기준으로 합산을 하면 층은 사라지고 성별-학년 교차표가 된다. 또는 행과 층을 기준으로 합산하면 성별-분반 교차표가 된다. &gt; marginSums(freqGenderYearClass, margin=c(1, 2)) year gender 1 2 3 4 F 0 14 3 1 M 1 18 6 2 &gt; marginSums(freqGenderYearClass, margin=c(1, 3)) class gender 1 2 F 10 8 M 12 15 7.2.1.2 상대 빈도로 교차표 구하기 절대 빈도로 표시된 성별-학년 교차표는 각 범주 조합이 몇 번 관측되었는지를 파악할 수 있으나, 전체 관측에서 차지하는 비중이 얼마인지 파악하기 힘들다. 예를 들어 남자와 여자의 학년별 비율이 차이가 있는지를 살펴보려면 상대 빈도로 교차표를 이용하는 것이 좋다. 상대 빈도로 빈도표를 만들 때와 마찬가지로 proportions()나 prop.table() 함수를 이용하면 절대 빈도 교차표에서 상대 빈도 교차표를 구할 수 있다. 2차원 절대 빈도 교차표에서 상대 빈도 교차표를 만드는 방법은 다음 세 가지 방법이 있다. 전체 관측 도수를 1로 하여 각 범주 조합의 상대적 비율을 나타낸다. 절대 빈도 교차표의 각 행의 빈도 합을 1로 하여 행별로 상대적 비율을 나타낸다. 절대 빈도 교차표의 각 열의 빈도 합을 1로 하여 열별로 상대적 비율을 나타낸다. propotions() 함수의 문법은 다음과 같다. propotions(절대빈도교차표) # 총 관측 도수 대비 상대 빈도 propotions(절대빈도교차표, margin = 1) # 행별 상대 빈도 propotions(절대빈도교차표, margin = 2) # 열별 상대 빈도 다음은 성별-학년 절대빈도 교차표에서 전체 관측 도수를 1로 하여 상대 빈도를 구한 예이다. 전체 45명 학생에 대한 관측 중 남자이면서 2학년인 학생이 40%를 차지함을 볼 수 있다. 전체 합이 1이 되는 것을 확인하라. &gt; proportions(freqGenderYear) year gender 1 2 3 4 F 0.00000000 0.31111111 0.06666667 0.02222222 M 0.02222222 0.40000000 0.13333333 0.04444444 전체 관측도수 대비 상대적 빈도뿐 아니라 교차표의 행별, 열별 상대 빈도를 구할 수도 있다. 다음 중 첫 번째 예는 행별 상대 빈도, 즉 성별로 학년 비율을 구한 것이다. 여자 학생 중 2학년 학생은 77.8%를 차지하고 있다. 행의 합은 1이 되는 것을 확인하라. 두 번재 예는 열별 상대 빈도, 즉 학년별로 성별 비율을 구한 것이다. 3학년 학생 중 여학생은 33.3%임을 알 수 있다. 열의 합이 1이 되는 것을 확인하라. 이렇듯 어떤 범주형 변수의 값에 따라(조건) 나머지 범주형 변수의 비율(상대 빈도)을 확인하고 싶으면, 조건이 되는 범주형 변수의 값에 따라 상대 빈도를 구하여 주면 된다. &gt; proportions(freqGenderYear, 1) year gender 1 2 3 4 F 0.00000000 0.77777778 0.16666667 0.05555556 M 0.03703704 0.66666667 0.22222222 0.07407407 &gt; proportions(freqGenderYear, 2) year gender 1 2 3 4 F 0.0000000 0.4375000 0.3333333 0.3333333 M 1.0000000 0.5625000 0.6666667 0.6666667 3차원 이상의 절대빈도 교차표에 대해서도 proportions() 함수를 이용하면 상대 빈도표를 구할 수 있다. proportions()의 margin 인수를 설정하는 방식은 marginSums() 함수를 3차원 교차표에 적용할 때와 동일한 방식으로 하면 된다. margin은 1, 2, 3으로 주면 행, 열, 층별 합이 1이 되도록 상대 빈도표를 구한다. 두 개 이상의 차원을 margin에 지정하면 두 차원이 교차되는 셀들의 합이 1이 되도록 상대 빈도표를 구한다. 다음은 성별-학년-분반 교차표에서 행, 열, 층별 상대 빈도와, 행-열 조합을 1로 하였을 때의 상대 빈도표를 구한 예이다. &gt; proportions(freqGenderYearClass, margin = 1) # 두 층으로 이루어진 한 행의 합은 1 , , class = 1 year gender 1 2 3 4 F 0.00000000 0.44444444 0.11111111 0.00000000 M 0.00000000 0.37037037 0.03703704 0.03703704 , , class = 2 year gender 1 2 3 4 F 0.00000000 0.33333333 0.05555556 0.05555556 M 0.03703704 0.29629630 0.18518519 0.03703704 &gt; proportions(freqGenderYearClass, margin = 2) # 두 층으로 이루어진 한 열의 합은 1 , , class = 1 year gender 1 2 3 4 F 0.0000000 0.2500000 0.2222222 0.0000000 M 0.0000000 0.3125000 0.1111111 0.3333333 , , class = 2 year gender 1 2 3 4 F 0.0000000 0.1875000 0.1111111 0.3333333 M 1.0000000 0.2500000 0.5555556 0.3333333 &gt; proportions(freqGenderYearClass, margin = 3) # 한 층의 합은 1 , , class = 1 year gender 1 2 3 4 F 0.00000000 0.36363636 0.09090909 0.00000000 M 0.00000000 0.45454545 0.04545455 0.04545455 , , class = 2 year gender 1 2 3 4 F 0.00000000 0.26086957 0.04347826 0.04347826 M 0.04347826 0.34782609 0.21739130 0.04347826 &gt; proportions(freqGenderYearClass, margin = c(1, 2)) # 같은 행-열에 위치한 셀의 합은 1 , , class = 1 year gender 1 2 3 4 F 0.5714286 0.6666667 0.0000000 M 0.0000000 0.5555556 0.1666667 0.5000000 , , class = 2 year gender 1 2 3 4 F 0.4285714 0.3333333 1.0000000 M 1.0000000 0.4444444 0.8333333 0.5000000 7.2.2 범주형 변수의 상관성을 그래프로 요약하기 교차표를 가지고 두 범주형 변수의 관계를 확인할 수 있지만, 그래프로 표현하는 것이 한 눈에 파악하기 좋다. 두 범주형 변수의 상관성을 나타내는 방법으로는 주로 막대 그래프와 모자이크 그래프가 자주 사용된다. 7.2.2.1 두 범주형 변수의 막대 그래프 그리기 쌓은 막대 그래프 그리기 두 범주형 변수의 관계를 막대 그래프로 나타내는 방법은, 두 범주형 변수 중 한 변수를 가로축(x)으로, 다른 범주형 변수를 막대의 채우기 색상(fill)으로 달리 표시하여 관측 도수를 표현한다. 다음은 ggplot2 패키지에서는 geom_bar() 함수를 이용하여 두 범주형 변수의 막대 그래프를 그리는 문법이다. ggplot(데이터, aes(x = 범주형변수1, fill = 범주형변수2)) + geom_bar() 다음은 geom_bar() 함수를 이용하여 학년-성별 분포를 막대 그래프로 표현한 것이다. 학년을 가로축에, 성별에 따라 막대의 채우기 색상이 달라지도록 매핑하였다. &gt; ggplot(course, aes(x = year, fill = gender)) + geom_bar() 위의 그래프처럼 한 범주를 기준으로 막대를 쌓아서 그리는 그래프를 쌓은 막대 그래프라고 한다. 쌓은 막대 그래프는 중심이 되는 변수-여기서는 학년-에 대한 분포가 막대의 크기로 표현되어 있어서 중심이 되는 범주형 변수의 분포를 확인할 수 있는 동시에, 중심이 되는 변수의 값이 정해져 있을 때 나머지 변수의 분포의 차이를 비교하기 좋다. 위의 쌓은 막대 그래프에서 2학년이 가장 빈도가 많으며, 2 학년이 남/녀 성별 비율이 가장 균형을 이루고 있다는 것을 확인할 수 있다. 나란한 막대 그래프 그리기 쌓은 막대 그래프는 중심이 되는 변수-가로축에 매핑되는 변수-의 절대 빈도를 파악하기 쉬운 장점이 있으나, 두 범주형 변수의 범주 값의 조합 중 가장 빈도가 높은 조합이 무엇인지 한 눈에 파악하기 어렵다. 그리고 한 범주형 변수의 값이 정해져 있을 때 다른 범주형 변수의 분포의 차이를 파악하기도 어렵다. 나란한 막대 그래프는 채우기 색상(fill)에 매핑된 범주형 변수의 값에 따라 나타나는 막대를 쌓아 표현하는 것이 아니라 나란히 표시하여 각 범주 조합의 절대 빈도를 파악할 수 있다. 다음은 geom_bar() 함수를 이용하여 나란한 막대 그래프를 그리는 문법이다. 쌓은 막대 그래프의 문법과 동일한데, 다만 geom_bar() 함수의 position 인수를 \"dodge\"로 설정하는 것만 다르다.(따옴표가 있다는 것에 주의.) ggplot2 패키지에서 position 문법의 의미를 자세히 알고자 하는 독자는 R 프로그래밍의 ggplot2의 위치 조정 절을 참조하기 바란다. ggplot(데이터, aes(x = 변수1, fill = 변수2)) + geom_bar(position = &quot;dodge&quot;) 다음은 앞에서 그린 학년과 성별 변수에 대하여 쌓은 막대 그래프를 나란한 막대 그래프를 그린 것이다. 절대 빈도가 가장 큰 조합은 2학년-남(M)학생 조합임을 알 수 있다. 학년 별로 성별 분포를 확인할 수 있는데, 다른 색상으로 표현된 막대의 크기에서 모두 학년에서 남자가 많았음을 확인할 수 있다. 1학년은 남학생밖에 없기 때문에 하나의 막대만 표시되었다. &gt; ggplot(course, aes(x = year, fill = gender)) + geom_bar(position = &quot;dodge&quot;) x와 fill의 매핑을 서로 바꾸면, 성별로 학년 분포(절대 빈도)를 확인할 수 있다. 남, 녀 모두 2학년이 가장 많았고, 그 다음 3학년, 4학년 순으로 수강하고 있음을 볼 수 있다. &gt; ggplot(course, aes(x = gender, fill = year)) + geom_bar(position = &quot;dodge&quot;) 상대 빈도로 막대 그래프 그리기 그런데 학년별로 성별 비율의 상대적 차이를 분석하고자 한다면, 절대 빈도로 그래프를 그려주는 쌓은 막대 그리프나, 나란한 막대 그래프보다는 상대 빈도로 막대 그래프를 그리는 것이 좋다. 상대 빈도로 그리는 막대 그래프는 가로축의 범주별 관측 도수를 1이라고 할 때 색상으로 매핑된 범주의 상대 빈도를 막대의 크기로 표현한다. 다음은 geom_bar() 함수를 이용하여 상대 빈도로 막대 그래프를 그리는 문법이다. 나란한 막대 그래프의 문법과 동일한데, 다만 geom_bar() 함수의 position 인수를 \"fill\"로 설정하는 것만 다르다.(따옴표가 있으며, 막대의 채우기 색상을 매핑할 때 사용하는 fill과는 다른 의미이다. 막대의 크기를 모두 1로 채운다는 의미로 이해하면 된다.) ggplot(데이터, aes(x = 변수1, fill = 변수2)) + geom_bar(position = &quot;fill&quot;) 다음은 각 학년의 데이터를 100%로 하여 성별로 상대 빈도를 막대 그래프로 그려본 것이다. 이 과목의 경우 2학년보다는 3, 4학년에서 남자 학생의 비율이 더 많았음을 볼 수 있다. 이러한 차이가 우연히 발생한 것인지 통계적으로 유의미한 차이인지는 가설검정을 해보아야 알 수 있을 것이다. &gt; ggplot(course, aes(x = year, fill = gender)) + geom_bar(position = &quot;fill&quot;) 7.2.2.2 범주형 변수의 상관성을 모자이크 그래프로 그리기 앞서 살펴본 상대 빈도로 막대 그래프를 그리는 방법은 한 변수의 값에 따라 다른 범주형 변수의 상대적 비율을 파악하기 쉬운 장점이 있으나, 전체 데이터에서 각 범주 조합의 비중을 파악할 수는 없어서 보는 사람들에게 왜곡된 정보를 줄 수도 있다. 반면 쌓은 막대 그래프나 나란한 막대 그래프는 절대 빈도로 막대를 그리므로 이러한 왜곡을 막을 수 있으나 상대 빈도를 비교하기 어렵다. 예를 들어 앞의 상대 빈도로 그린 막대 그래프에서 1학년 학생은 100%가 남자인 것을 볼 수 있다. 만약 이 그래프만 보고 판단하면 1학년에서 남자 학생의 비율이 매우 큰 것이 의아하게 생각될 수 있다. 그러나 사실 1학년 학생은 전체 학생 중 한 명밖에 없었고, 그 한 명이 남자였기 때문에 1학년의 성별 비율이 100% 남자로 표시된 것이다. 이 경우 1 학년 학생의 데이터가 매우 적다는 것을 표현하면 좋다. 모자이크 그래프는 한 범주형 변수의 값에 따라 다른 범주형 변수의 상대 빈도를 비교하기 좋게 표시하면서도 각 범주 조합의 비중의 크기를 파악할 수 있게 해준다. 모자이크 그래프는 가로축에 매핑되는 범주형 변수의 값의 빈도에 따라 막대의 폭을 다르게 표시한다. 모자이크 그래프는 ggplot2를 기반으로 하는 ggmosiac 패키지로 모자이크 그래프를 그릴 수 있지만, 여기서는 vcd 패키지의 mosaic() 함수를 사용하면 모자이크 그래프를 그리도록 한다. vcd 패키지가 설치되어 있지 않으면 다음 명령이나 RStudio의 [Packages] 탭을 사용하여 설치를 하도록 한다. &gt; install.packages(&quot;vcd&quot;) mosaic() 함수의 문법은 다음과 같다. mosaic(범주형변수2 ~ 범주형변수1, data = 데이터, direction = &quot;v) 다음은 학년-성별 모자이크 그래프를 그린 예이다. 각 학년의 성별 비율을 파악할 수 있을뿐 아니라 2학년, 3학년, 4학년 순으로 빈도가 높음을 확인할 수 있으며, 1학년은 매우 데이터가 적다는 것을 파악할 수 있다. &gt; library(vcd) # vcd 패키지를 먼저 적재한다. &gt; mosaic(gender ~ year, data = course, direction = &quot;v&quot;) 7.3 범주형 변수의 분석 사례 7.3.1 관절염 치료 임상시험 데이터 분석 지금까지 범주형 변수의 분석과 관련하여 배운 내용을 이용하여 관절염 치료법에 대한 임상시험 데이터를 분석해 보자. 이 데이터는 Koch and Edwards(1988)가 새로운 관절염 치료법의 효과를 측정한 데이터이다. 이 데이터는 vcd라는 패키지에 Arthritis라는 이름으로 포함되어 있고 여기서는 교육의 목적으로 bizstatp 패키지에 같은 이름으로 재수록 하였다. bizstatp 패키지가 적재되어 있지 않으면 먼저 적재한 후 다음 명령으로 Arthritis 데이터를 살펴보자. &gt; library(bizstatp) # bizstatp 패키지를 적재한다. &gt; Arthritis ID Treatment Sex Age Improved 1 57 Treated Male 27 Some 2 46 Treated Male 29 None 3 77 Treated Male 30 None 4 17 Treated Male 32 Marked 5 36 Treated Male 46 Marked 6 23 Treated Male 58 Marked 7 75 Treated Male 59 None 8 39 Treated Male 59 Marked 9 33 Treated Male 63 None ...... 이 데이터를 분석하여 다음과 같은 질문에 답을 해보자. 새로운 치료법은 아무 치료도 하지 않는 것보다 효과가 있는가? 새로운 치료법의 효과는 성별로 차이가 있는가? 본격적으로 질문에 답하기에 전에 summary() 함수로 전체 데이터에 대한 통계 요약을 해보자. 아래 결과를 보면, 이 임상시험에서 새로운 치료법을 받은(Treated) 환자와 플라시보(Placebo) 치료를 받은 환자의 수가 거의 비슷하였다. 또한 여자 환자의 수가 남자 환자의 수보다 2배 이상 많았고, 환자의 연령대는 23세부터 74세까지 있었다. 치료(플라시보 치료 포함) 후에 차도가 거의 없었던(None) 환자의 수와 약간(Some) 또는 확실히(Marked) 효과가 있었던 환자를 합친 수가 같았다. &gt; summary(Arthritis) ID Treatment Sex Age Improved Min. : 1.00 Placebo:43 Female:59 Min. :23.00 None :42 1st Qu.:21.75 Treated:41 Male :25 1st Qu.:46.00 Some :14 Median :42.50 Median :57.00 Marked:28 Mean :42.50 Mean :53.36 3rd Qu.:63.25 3rd Qu.:63.00 Max. :84.00 Max. :74.00 그럼 이런 기본 정보를 바탕으로 새로운 치료법이 증상의 개선에 뚜렷이 도움이 되었는지 확인해 보자. 치료법(Treatment)과 증상 개선 여부(Improved)에 대한 교차표를 구해보니 뚜렷한 증상 개선(Marked)이 된 환자 중에는 새로운 치료법을 받은 환자(Treated)가 많았다. &gt; tti &lt;- xtabs(~ Treatment + Improved, data = Arthritis) &gt; tti Improved Treatment None Some Marked Placebo 29 7 7 Treated 13 7 21 이를 좀더 정확히 살펴보기 위해 치료법에 따른 증상 개선의 상대적 비율(%)을 구해보자. 결과에서 플라시보 치료를 받은 환자의 67%가 증상의 개선이 없었는데, 새로운 치료법을 받은 환자는 31%만 개선이 없었고, 51%의 환자는 확실한 증상 개선이 있었다. &gt; round(prop.table(tti, margin = 1) * 100, digits=2) Improved Treatment None Some Marked Placebo 67.44 16.28 16.28 Treated 31.71 17.07 51.22 물론 이러한 차이가 통계적으로 유의미한지는 다시 가설검정을 해보아야 한다. 가설검정 방법에 대해서는 뒤에 자세히 살펴보도록 하고, 가설검정 결과만 살펴보면 치료법에 따른 증상 개선 효과의 차이는 없다는 귀무가설에 대한 검정에서 p-값이 매우 작게 나와서 치료법에 따라 증상 개선 효과가 차이가 있었다는 대립가설을 채택하게 해 준다. &gt; chisq.test(tti) Pearson&#39;s Chi-squared test data: tti X-squared = 13.055, df = 2, p-value = 0.001463 지금까지 분석한 내용을 다른 사람들에게 전달하기 좋도록 그래프로 나타내 보자. &gt; ggplot(Arthritis, aes(x = Treatment, fill = Improved)) + geom_bar(position = &quot;dodge&quot;) &gt; ggplot(Arthritis, aes(x = Treatment, fill = Improved)) + geom_bar(position = &quot;fill&quot;) 그러면 증상 개선 효과(Improved)의 성별(gender) 차이가 있었는지를 어떻게 분석할 수 있을까? 먼저 플라시보 치료를 받은 환자에 대하여 증상 개선 효과와 환자 성별로 교차표를 구해보자. 남자에 비해 여성 환자의 확실한(Marked) 증상 개선 사례가 많아 보인다. &gt; tsi_placebo &lt;- xtabs(~ Sex + Improved, data = Arthritis, subset = Treatment == &quot;Placebo&quot;) &gt; tsi_placebo Improved Sex None Some Marked Female 19 7 6 Male 10 0 1 플라시보 치료를 받은 환자에 대하여 실제 성별로 증상 개선 효과의 상대적 비율이 다른지 확인해 보자. 플라시보 치료의 경우 남자 환자의 90%가 증상 개선이 없었던 반면, 여성 환자의 40% 가량은 증상의 개선이 조금 또는 확연히 있었다. &gt; proportions(tsi_placebo, margin = 1) Improved Sex None Some Marked Female 0.59375000 0.21875000 0.18750000 Male 0.90909091 0.00000000 0.09090909 물론 이러한 수치가 관측 도수가 작아서 우연히 발생한 것일 수 있다. 그러므로 플라시보 치료자의 증상 개선 효과에 대한 성별 차이가 있었는지에 대하여 가설검정을 해보자. 관측 도수가 매우 낮은 셀이 있어서 Fisher 정확 검증으로 가설검정을 수행하였다. 결과에서 p-값이 크게 나왔으므로 성별 차이는 우연히 발생한 것이라는 귀무가설을 기각하지 못한다. &gt; fisher.test(tsi_placebo) Fisher&#39;s Exact Test for Count Data data: tsi_placebo p-value = 0.1706 alternative hypothesis: two.sided 그러면 새로운 치료법에서는 성별로 증상 개선 효과의 차이가 있었을까? 새로운 치료법을 받은 환자에 대해 성별-증상 개선 효과의 교차표를 구하여, 성별로 증상 개선의 상대적 비율을 구해보았다. 이 경우에도 여성의 증상 개선 효과가 남자보다 크게 나타난 것으로 확인할 수 있다. 그러나 플라시보 치료자와 마찬가지로 이 차이가 통계적으로 유의미한 차이라고 보기는 어렵다. &gt; tsi_treated &lt;- xtabs(~ Sex + Improved, data = Arthritis, subset = Treatment == &quot;Treated&quot;) &gt; prop.table(tsi_treated, margin = 1) Improved Sex None Some Marked Female 0.2222222 0.1851852 0.5925926 Male 0.5000000 0.1428571 0.3571429 &gt; fisher.test(tsi_treated) Fisher&#39;s Exact Test for Count Data data: tsi_treated p-value = 0.2204 alternative hypothesis: two.sided 지금까지 분석한 내용을 다른 사람들에게 전달하기 좋도록 그래프로 나타내 보자. 성별 변수로 측면으로 나누어 막대 그래프를 그리기 위해 facet_wrap() 함수를 이용하여 성별로 측면 그래프를 그렸다. &gt; ggplot(Arthritis, aes(x = Treatment, fill = Improved)) + + geom_bar(position = &quot;dodge&quot;) + + facet_wrap(~ Sex) &gt; ggplot(Arthritis, aes(x = Treatment, fill = Improved)) + + geom_bar(position = &quot;fill&quot;)+ + facet_wrap(~ Sex) 막대 그래프에서 새로운 치료법을 적용하든 플라시보 치료법이든 여성이 남성에 비해 관절염의 증상 개선 효과가 더 좋은 경향을 보인다는 것을 볼 수 있다. 그러나 이 차이는 통계적으로 유의미한 확실한 차이는 아니었다. 7.3.2 이혼에 대한 사회조사 데이터 분석 bizstatp 패키지의 BrokenMarriage 데이터는 덴마크 사회 조사국에서 수행한 성별 및 사회적 계급에 따른 이혼 또는 영구적 남녀 관계가 깨진 빈도를 측정한 데이터이다. 이 데이터는 vcd라는 패키지에 BrokenMarriage라는 이름으로 포함되어 있고 여기서는 교육의 목적으로 같은 이름으로 재수록 하였다. bizstatp 패키지를 메모리에 적재하였다면 다음 명령으로 데이터를 확인할 수 있다. &gt; BrokenMarriage Freq gender rank broken 1 14 male I yes 2 102 male I no 3 39 male II yes 4 151 male II no 5 42 male III yes 6 292 male III no 7 79 male IV yes 8 293 male IV no 9 66 male V yes 10 261 male V no 11 12 female I yes 12 25 female I no 13 23 female II yes 14 79 female II no 15 37 female III yes 16 151 female III no 17 102 female IV yes 18 557 female IV no 19 58 female V yes 20 321 female V no 이 데이터의 특징은 조사된 원 데이터-조사된 사람 한 명에 대한 관측이 행을 이루는 원래 데이터-가 아니라 이미 그룹별로 빈도가 요약된 데이터라는 것이다. 첫 번째 행은 남성이면서 1-계급에 속하는 사람이 이혼 또는 영구적 남녀 관계가 깨졌는지에 대한 물음에 그렇다고 응답(yes)한 빈도수(Freq)를 보여준다. 이렇게 이미 그룹으로 요약된 데이터를 다룰 때는 이미 요약된 빈도수가 후속 분석에서 제대로 반영되도록 주의해야 한다. 예를 들어 성별로 이혼 빈도에 대한 교차표를 구할 때, 원 데이터를 가지고 있을 때와 마찬가지로 행 하나를 관측으로 간주하여 빈도를 세면 정확한 결과를 얻을 수 없다. &gt; xtabs(~ gender + broken, data = BrokenMarriage) broken gender yes no male 5 5 female 5 5 BrokenMarriage 데이터처럼 이미 빈도로 요약된 데이터를 가지고 xtabs() 함수로 빈도표나 교차표를 만드려면 다음처럼 수식의 좌변에 이미 요약된 빈도를 가진 열을 기술해야 한다. xtabs(빈도변수 ~ 범주형변수1 + ..., data = 데이터) 다음은 성별-이혼 여부 변수에 대한 교차표를 구한 예이다. 수식의 좌변에 빈도수를 가지고 있는 열 Freq을 지정해 주어야 단순히 행의 개수를 세는 것이 아니라 빈도수 더하여 교차표를 만들어 준다. &gt; tgb &lt;- xtabs(Freq ~ gender + broken, data = BrokenMarriage) &gt; tgb broken gender yes no male 240 1099 female 232 1133 성별로 이혼률에 차이가 있는지 확인해 보자. 상대 빈도도 거의 차이가 나지 않고, 그 차이도 통계적으로 유의미하지 않음을 볼 수 있다. &gt; proportions(tgb, 1) broken gender yes no male 0.1792382 0.8207618 female 0.1699634 0.8300366 &gt; chisq.test(tgb) Pearson&#39;s Chi-squared test with Yates&#39; continuity correction data: tgb X-squared = 0.34175, df = 1, p-value = 0.5588 그러면 사회 계급별로 이혼률에 차이가 있는지 확인해 보자. 사회 계급별로도 유의미한 차이를 보이지 않았다. &gt; trb &lt;- xtabs(Freq ~ broken + rank, data = BrokenMarriage) &gt; proportions(trb, margin = 2) rank broken I II III IV V yes 0.1699346 0.2123288 0.1513410 0.1755577 0.1756374 no 0.8300654 0.7876712 0.8486590 0.8244423 0.8243626 &gt; chisq.test(trb) Pearson&#39;s Chi-squared test data: trb X-squared = 4.8795, df = 4, p-value = 0.2999 성별로 사회계급에 따른 이혼률의 차이가 있는지를 살펴보기 위해서 성별로 측면으로 나누어 막대 그래프를 그려보자. 이미 빈도로 요약된 데이터에 대한 막대 그래프는 geom_bar()가 아니라 geom_col() 함수로 막대 그래프를 그린다. 두 함수에 대한 자세한 차이는 R 프로그래밍의 ggplot2 범주형 변수의 통계 요약 절을 참조 바란다. geom_col()으로 이미 빈도로 요약된 데이터에서 막대 그래프를 그리는 문법은 다음과 같다. x뿐 아니라 y에 빈도를 가진 영를 매핑하여 막대 그래프를 그린다. ggplot(데이터, aes(x = 범주형변수, y = 빈도변수)) + geom_col() ggplot(데이터, aes(x = 범주형변수1, y = 빈도변수, fill = 범주형변수2)) + geom_col() ggplot(데이터, aes(x = 범주형변수1, y = 빈도변수, fill = 범주형변수2)) + geom_col(position = &quot;dodge&quot; or &quot;fill&quot;) 성별로 사회 계급에 따른 이혼 빈도를 절대 빈도와 상대 빈도로 막대 그래프를 그려보면 다음과 같다. &gt; ggplot(BrokenMarriage, aes(x = rank, y = Freq, fill = broken)) + + geom_col() + facet_wrap(~ gender) &gt; ggplot(BrokenMarriage, aes(x = rank, y = Freq, fill = broken)) + + geom_col(position = &quot;fill&quot;) + facet_wrap(~ gender) 절대 빈도를 보여주는 그래프에서 남성에 비해 여성의 계급이 4등급에 집중되어 있다는 것을 볼 수 있다. 그리고 상대 빈도를 보여주는 그래프에서 남성에 비해 여성이 사회적 등급이 높아질수록 이혼률이 약간은 증가하는 경향을 볼 수 있다. 남성과 여성으로 나누어 보았을 때 사회계급의 차이가 이혼률에 영향을 미치는지를 살펴보기 위해 성별로 이혼 여부-사회계급의 교차표를 계산해 보자. 그리고 성별로 사회계급에 따라 이혼률이 달라지는지 확인해 보자. 다음 결과에서 남자의 이혼율은 2, 4, 5 등급에서 20% 정도이고, 1, 3 등급에서 12% 정도였는데, 이러한 차이는 통계적으로 유의미한 차이로 분석되었다. &gt; tbr_male &lt;- xtabs(Freq ~ broken + rank, data = BrokenMarriage, subset = gender == &quot;male&quot;) &gt; prop.table(tbr_male, margin = 2) rank broken I II III IV V yes 0.1206897 0.2052632 0.1257485 0.2123656 0.2018349 no 0.8793103 0.7947368 0.8742515 0.7876344 0.7981651 &gt; chisq.test(tbr_male) Pearson&#39;s Chi-squared test data: tbr_male X-squared = 13.984, df = 4, p-value = 0.007347 다음 결과에서 여자의 이혼율은 사회 등급이 높아질수록 이혼률이 증가하는 경향을 보였는데, 이러한 차이도 통계적으로 유의미한 차이로 분석되었다. &gt; tbr_female &lt;- xtabs(Freq ~ broken + rank, data = BrokenMarriage, subset = gender == &quot;female&quot;) &gt; prop.table(tbr_female, margin = 2) rank broken I II III IV V yes 0.3243243 0.2254902 0.1968085 0.1547800 0.1530343 no 0.6756757 0.7745098 0.8031915 0.8452200 0.8469657 &gt; chisq.test(tbr_female) Pearson&#39;s Chi-squared test data: tbr_female X-squared = 11.286, df = 4, p-value = 0.02353 남녀 합쳐서 분석할 때는 사회계급에 따른 이혼률의 차이가 유의미 하지 않았지만, 성별로 나누어 분석해 보면 남성과 여성 모두에서 사회계급과 이혼 여부가 통계적으로 유의미한 상관성을 확인할 수 있다. 이는 남성일수록 상위 계급(1, 3 등급)의 이혼률이 낮아지는데, 여성일수록 상위 계급(1, 2)의 이혼률이 높아져서, 합쳐진 데이터에서는 이러한 경향이 중화되어 나타나지 않았음을 볼 수 있다. 이 에에서 보듯이 한 변수가 다른 변수에 미치는 영향은 두 변수만 한정하여 살펴보는 것뿐만 아니라, 제 삼의 변수의 조건에 따라 두 변수의 상관성이 영향을 받는지 살펴볼 필요가 있다. 이러한 것을 살펴보기 위해서는 여러 측면으로 나누어 기술통계 분석을 실시해 보아야 하고, 분석하는 문제에 대한 충분한 배경 지식을 갖고 있어야 한다. group 속성에는 상수 값이면 아무 값이나 매핑해도 된다. 여기서는 편의상 1을 매핑하였다.↩︎ "],["ch-numericDescStat.html", "Chapter 8 수치형 변수에 대한 R 기술통계 8.1 한 수치형 변수에 대한 분포 분석 8.2 둘 이상의 수치형 변수의 상관성 분석", " Chapter 8 수치형 변수에 대한 R 기술통계 수치형 변수에 대한 기술통계 분석도 범주형 변수와 마찬가지로 한 변수의 분포를 파악하는 방법과 여러 개의 수치형 변수 사이의 상관성을 파악하는 방법으로 나누어 살펴보도록 한다. 8.1 한 수치형 변수에 대한 분포 분석 bizstatp의 course 데이터의 총점(score) 같은 수치형 변수가 있을 때 우리는 분포에 대해 다음과 같은 질문을 해볼 수 있다. 수치형 변수의 중심점은 어디인가? 그리고 가장 빈번하게 발생하는 수치는 어디인가? 수치형 변수의 값은 얼마니 넓게 분포하는? 특정 값 중심으로 몰려 있는가, 아니면 매우 넓게 퍼져 있는가? 수치형 변수의 분포는 대칭적인가, 한쪽으로 치우쳐 있는가? 다른 수치 값과 동떨어져 있는 이상치(outliers)가 있는가? 이러한 질문에 답하기 위해서, 범주형 변수와 마찬가지로 수치로 요약해 볼 수도 있고 그래프로 요약해 볼 수 있다. 8.1.1 수치형 변수 분포를 수치로 요약하기 수치형 변수의 특성을 파악하기 위해 분포의 특성을 대표할 수 있는 몇 개의 의미있는 통계량(통계치)으로 요약하는 것이 자주 사용된다. 왜냐하면 앞서 1 장에서도 설명하였듯이 데이터를 나열하는 것만으로는 데이터의 특성을 파악하기 힘들기 때문이다. 주로 사용되는 수치형 변수의 통계량은 다음과 같다. 분포의 중심 경향을 보여주는 통계량: 평균(mean), 중위수(meidan) 분포의 펴진 정도를 보여주는 통계량: 분산(variance), 표준 편차(standard deviation), 범위(range), 분위수(quantile)와 IQR(inter-quartile range) 분포의 치우친 정도(비대칭성)를 보여주는 통계량: 왜도(skewness), 분위수(quantile) 분파의 중앙 집중도를 보여주는 통계량: 첨도(kurtosis) 8.1.1.1 중심 경향을 보여주는 통계량 표 8.1는 course 데이터의 총점(score)에 대해 학년별 평균을 구한 예이다. 결과에서 보듯이 학년이 올라갈수록 평균 점수가 올라가는 경향이 있음을 쉽게 파악할 수 있다. 이렇듯 여러 집단을 비교할 때 평균처럼 중심값을 구하여 비교하는 것이 전체적인 경향을 파악하기 쉽다. Table 8.1: course 데이터의 총점의 학년별 평균 year mean_score 1 10.00000 2 71.44781 3 75.40667 4 80.25000 평균 수치형 변수 \\(x\\)의 평균을 \\(\\bar{x}\\)라 하면 평균은 다음처럼 계산된다. \\[ \\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}. \\] 단, \\(x_i\\)는 \\(i\\)-번째 관측의 \\(x\\) 변수의 값이고, \\(n\\)은 관측 개수. 그런데 평균은 다음과 같은 단점과 장점이 있다. 관측된 값을 모두 더하여 관측 개수로 나누다 보니, 예외적으로 크고 작은 수치에 의해 영향을 크게 받는다. 여러 집단으로 나누어 평균을 구한 후, 집단의 평균을 집단의 관측 개수로 가중 평균을 하면 전체 집단의 평균을 구할 수 있다. R은 평균은 mean() 함수로 구한다. mean(수치벡터) mean(데이터프레임$수치형변수) 다음 예에서 예외적인 수치가 들어감에 따라 평균이 크게 바뀌는 것을 관찰할 수 있다. &gt; x &lt;- 46:55 ; y &lt;- c(x, 1000) ; z &lt;- c(x, -1000) &gt; x; mean(x) [1] 46 47 48 49 50 51 52 53 54 55 [1] 50.5 &gt; y; mean(y) [1] 46 47 48 49 50 51 52 53 54 55 1000 [1] 136.8182 &gt; z; mean(z) [1] 46 47 48 49 50 51 52 53 54 55 -1000 [1] -45 다음은 course 데이터에서 총점의 평균을 구한 결과이다. &gt; library(bizstatp) &gt; mean(course$score) [1] 71.46089 그런데 중간고사에 대한 평균을 구해보면 다음과 같은 결과를 볼 수 있다. &gt; mean(course$mid) [1] NA 이러한 결과가 나온 이유는 한 학생이 중간고사에 불참하여 이 학생의 중간고사 점수가 결측(NA)되었기 때문에 평균을 계산할 수 없다는 뜻에서 NA가 나온 것이다. 평균을 계산할 때 결측치를 제외하고 평균을 구하려면 다음처럼 na.rm 인수를 TRUE로 설정하여 구한다. 앞으로 볼 많은 R 통계 함수들도 결측치를 제외하고 계산할 때 동일한 인수를 사용하는 경우가 많다. &gt; mean(course$mid, na.rm = TRUE) [1] 61.61364 중위수(중앙값) 중위수는 관측값을 크기 순으로 나열하였을 때 가운데 중앙에 위치하는 값을 의미한다. 관측값의 개수 n이 홀수이면 (n+1)/2 번째 값이 중위수이고 n이 짝수이면 n/2 번째 값과 n/2 + 1번째 값의 평균이 중위수가 된다. 따라서 중위수보다 작은 값의 수와 중위수보다 큰 값의 수가 같아진다. 평균은 매우 큰 이상치에 영향을 많이 받는 반면, 중위수는 한 두 개의 매우 큰 값이나 작은 값에 영향을 크게 받지 않는 장점이 있다. 그러나 평균처럼 전체 관측이 여러 집단으로 나뉘어져 있을 때 각 집단의 중위수로 전체 관측의 중위수를 구할 수 있는 방법은 없다. R에서 중위수는 median() 함수로 구한다. median(수치벡터) median(데이터프레임$수치변수) 다음 예에서 예외적인 수치가 있어도 중위수는 크게 변화하지 않음을 볼 수 있다. &gt; x; median(x) [1] 46 47 48 49 50 51 52 53 54 55 [1] 50.5 &gt; y; median(y) [1] 46 47 48 49 50 51 52 53 54 55 1000 [1] 51 &gt; z; median(z) [1] 46 47 48 49 50 51 52 53 54 55 -1000 [1] 50 다음은 course` 데이터에서 총점의 중위수를 구한 결과이다. &gt; median(course$score) [1] 72.6 평균과 마찬자지로 결측치가 있는 관측을 제외하고 중위수를 구하려면 na.rm 인수를 사용한다. &gt; median(course$mid) [1] NA &gt; median(course$mid, na.rm = TRUE) [1] 59 8.1.1.2 퍼진 경향을 보여주는 통계량 수치형 변수를 파악할 때 중심경향을 파악하는 것만으로는 변수의 특성을 충분히 파악하기 힘들다. 수치 변수의 값이 중심으로부터 어느 정도 퍼져 있는지를 알 수 없기 때문이다. 수치형 분포의 퍼진 정도를 파악하는 통계량으로 분산, 표준편차, 분위수 등이 있다. 분산과 표준편차 분산(variance)과 표준편차(standard deviation)는 관측값들이 평균으로부터 얼마나 떨어져 있는지를 측정하는 통계량으로 다음과 같이 계산된다. 변수 \\(x\\)에 대한 분산을 \\(s^2_x\\)이라고 하면 \\(s^2_x\\)은 다음처럼 계산된다. \\[ s^2_x = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\] 표준편차는 분산에 제곱근을 씌운 것으로 관측값과 분산을 평균과 동일한 축적으로 변환시킨다. 따라서 개략적으로 표현하자면 표준편차는 관측값이 평균에서 평균적으로 얼마나 떨어져 있는지를 나타낸다고 할 수 있다. 변수 \\(x\\)에 대한 표준편차를 \\(s_x\\)라고 하면 \\(s_x\\)는 다음처럼 계산된다. \\[ s_x = \\sqrt{s_x^2} = \\sqrt{ \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 }. \\] R에서 분산과 표준편차는 var()와 sd() 함수로 구한다. &gt; var(course$score) [1] 220.4966 &gt; sd(course$score) [1] 14.84913 분산과 표준편차는 평균과 비슷한 성질을 가지고 있다. 관측치가 여러 집단으로 나누어져 있으면 각 집단의 분산을 가중 평균하여 전체의 분산을 계산할 수 있다. 그러나 평균과 마찬가지로 분산과 표준편차는 예외적인 값에 크게 영향을 받는다. &gt; x; sd(x) [1] 46 47 48 49 50 51 52 53 54 55 [1] 3.02765 &gt; y; sd(y) [1] 46 47 48 49 50 51 52 53 54 55 1000 [1] 286.2994 &gt; z; sd(z) [1] 46 47 48 49 50 51 52 53 54 55 -1000 [1] 316.7507 표준편차는 관측치의 측정단위로 관측치가 평균에서 평균적으로 얼마나 퍼져 있는가를 측정한다. 그렇기 때문에 측정단위가 다른 데이터의 퍼짐경향을 서로 비교하기가 어렵다. 이를 보완하여 측정단위와 무관하게 퍼진 정도를 비교하는 방법이 변동계수(coefficient of variance)를 사용하는 것이다. 변동계수 \\(c_{x}\\)는 다음처럼 표준편차를 평균으로 나누어 구한다. 그러므로 분자와 분모의 측정단위가 상쇄되어서, 변동계수를 사용하면 평균 대비 표준편차의 상대적 크기를 서로 비교할 수 있다. \\[ c_x = s_x / \\bar{x}. \\] 다음은 course 데이터에서 중간고사, 기말고사, 최종평가 점수의 변동계수를 구해본 예이다. 다음 결과에서 중간고사, 기말고사, 최종평가 점수 순으로 퍼짐경향이 줄어들었음을 볼 수 있다. 중간 및 기말고사에 결측치 NA가 있기 때문에 이를 제외하고 표준편차와 평균을 구할 때 na.rm = TRUE 인수를 사용하였다. &gt; sd(course$mid, na.rm=T) / mean(course$mid, na.rm=T) # 중간고사의 변동계수 [1] 0.3324946 &gt; sd(course$final, na.rm=T) / mean(course$final, na.rm=T) # 기말고사의 변동계수 [1] 0.2891162 &gt; sd(course$score) / mean(course$score) # 총점의 변동계수 [1] 0.2077938 분위수(quantile)와 IQR 평균과 마찬가지로 분산과 표준편차는 극단적인 한 두 값에 의해 영향을 많이 받는다. 사분위수(quartiles) 같은 분위수(quantile)를 사용하여 수치 분포의 퍼진 정도를 파악하면 중위수와 마찬가지로 극단적 이상치의 영향을 덜 받는다. 분위수는 관측값을 크기 순으로 오름차순으로 나열한 후 \\(q\\) 등분할 때, 이 등분의 경계가 되는 \\(q-1\\) 개의 수를 q분위수라고 한다. 예를 들어, 사분위수는 관측값을 크기 순으로 나열한 후 4 등분하는 그 경계가 되는 3 개의 수를 말한다. 마찬가지로 십분위수는 관측값을 10 등분하는 그 경계가 되는 9 개의 수를 말한다. q분위수 중 가장 작은 수부터, 1-q분위수, 2-q분위수, …, (q-1)-q분위수라고 한다. 따라서 1-사분위수(1Q)는 관측치를 하위 25%와 상위 75%를 나누는 수이며, 2-사분위수(2Q)는 중위수를 의미하며, 3-사분위수(3Q)는 하위 75%와 상위 25%를 나누는 수이다. R에서는 quantile() 함수를 사용하여 분위수를 구한다. 다음과 같이 quantile() 함수에 수치형 변수만 전달하면, 수치형 변수의 사분위수와 함께, 최소(0%), 최대 값(100%)을 출력한다. quantile(수치형벡터) quantile(데이터프레임$수치형변수) 다음 예에서 최소, 최대값을 제외하고 사분위수는 극단적 이상치에 영향을 덜 받는 것을 확인할 수 있다. &gt; x; quantile(x) [1] 46 47 48 49 50 51 52 53 54 55 0% 25% 50% 75% 100% 46.00 48.25 50.50 52.75 55.00 &gt; y; quantile(y) [1] 46 47 48 49 50 51 52 53 54 55 1000 0% 25% 50% 75% 100% 46.0 48.5 51.0 53.5 1000.0 &gt; z; quantile(z) [1] 46 47 48 49 50 51 52 53 54 55 -1000 0% 25% 50% 75% 100% -1000.0 47.5 50.0 52.5 55.0 다음은 course 데이터의 총점과 중간고사 변수에 대한 사분위수를 구한 예이다. 중간고사는 결측치가 있으므로 na.rm 인수로 결측치를 제외하고 사분위수를 구하였다. 사분위수를 확인해보면 분포의 중심이 되는 50% 데이터가 어느 구간에 퍼져 있고, 대칭적인지 비대칭적인지도 파악할 수 있다. 중간고사 데이터를 보면 1사분위수와 3사분위수 사이의 50% 데이터가 약 45점에서 80점 사이에 분포되어 있고, 중위수가 약 60점인 것으로 볼 때 상위 점위의 꼬리가 긴 분포 형태임을 짐작할 수 있다. &gt; quantile(course$score) 0% 25% 50% 75% 100% 10.00 61.50 72.60 80.49 95.00 &gt; quantile(course$mid, na.rm = TRUE) 0% 25% 50% 75% 100% 27.00 45.50 59.00 79.75 97.00 quantile() 함수의 probs 인수에 [0, 1] 사이의 값을 전달하면, 관측치를 순서로 나열했을 때 해당 순위의 값을 출력한다. 예를 들어 다음처럼 0.5를 전달하면 작은 값부터 시작하여 순위가 50%인 값이, 0.25를 전달하면 순위가 25%인 값이 출력된다. &gt; quantile(course$score, probs = 0.5) # 중위수 50% 72.6 &gt; quantile(course$score, probs = 0.25) # 1-사분위수 25% 61.5 probs에 다음처럼 여러 값을 입력할 수 있다. 다음은 5분위수와 10분위수를 구한 예이다. &gt; quantile(course$score, probs = seq(from = 0, to = 1, by = 0.2)) 0% 20% 40% 60% 80% 100% 10.000 60.330 66.942 74.526 83.166 95.000 &gt; quantile(course$score, probs = seq(from = 0, to = 1, by = 0.1)) 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 10.000 58.498 60.330 64.412 66.942 72.600 74.526 79.920 83.166 88.984 95.000 사분위수를 가지고 관측값의 퍼진경향을 측정하는 통계량이 IQR(interquartile range)이다. IQR은 3사분위수와 1사분위수의 차이로 계산된다. 즉, 중심에 있는 50% 데이터가 서로 얼마나 멀리 퍼져 있는지를 측정한다. 중심에 있는 50% 데이터로 퍼진 정도를 측정하므로, 예외적으로 큰 값이나 작은 값은 IQR에 영향을 크게 주지 못한다. R에서 IQR은 IQR() 함수로 구한다. 다음 예에서 예외적인 값이 IQR에 크게 영향을 주지 않는다는 것을 확인할 수 있다. &gt; x; IQR(x) [1] 46 47 48 49 50 51 52 53 54 55 [1] 4.5 &gt; y; IQR(y) [1] 46 47 48 49 50 51 52 53 54 55 1000 [1] 5 &gt; z; IQR(z) [1] 46 47 48 49 50 51 52 53 54 55 -1000 [1] 5 course 데이터의 중간, 기말, 총점의 IQR을 구해본 결과 변동계수와 마찬가지로 중간, 기말, 총점 순으로 퍼짐경향이 줄어드는 것을 볼 수 있다. &gt; IQR(course$mid, na.rm=T); IQR(course$final, na.rm=T); IQR(course$score) [1] 34.25 [1] 29.5 [1] 18.99 중앙값 절대 편차 중앙값 절대 편차(Median Absolute Deviaton)는 IQR보다 더 안정적으로 데이터의 퍼진 정도를 측정하는 통계량이다. 중앙값 절대 편차는 다음 방법으로 계산된다. 절대 편차 계산: 관측값이 중위수에서 얼마나 멀리 떨어져 있는지 편차를 계산한 후 절대값을 취한다. 절대 편차의 중위수(중앙값)를 계산한다. 분포가 정규분포를 따를 때의 표준편차의 추정치로 사용할 수 있도록 절대 편차의 중위수에 1.4826이라는 상수를 곱 한다. 다음은 앞의 설명대로 중앙값 절대 편차를 계산한 예이다. &gt; x - median(x) [1] -4.5 -3.5 -2.5 -1.5 -0.5 0.5 1.5 2.5 3.5 4.5 &gt; abs(x - median(x)) [1] 4.5 3.5 2.5 1.5 0.5 0.5 1.5 2.5 3.5 4.5 &gt; 1.4826 * median(abs(x - median(x))) [1] 3.7065 R은 이러한 계산을 해서 중앙값 절대 편차를 구해주는 mad()라는 함수를 가지고 있다. &gt; mad(x) [1] 3.7065 다음은 course 데이터의 중간, 기말, 총점의 중위수 절대 편차를 구한 결과이다. &gt; mad(course$mid, na.rm=T); mad(course$final, na.rm=T); mad(course$score) [1] 25.2042 [1] 22.9803 [1] 13.06171 범위(range) 수치형 변수의 퍼진 정도를 파악할 때 최소값과 최대값을 사용하여 수치형 변수의 범위를 파악하는 방법을 사용하기도 한다. R에서는 range() 함수를 사용하여 최소값과 최대값을 구할 수 있다. min()과 max() 함수를 사용하면 최소값과 최대값만 각각 구할 수도 있다. &gt; range(course$score) [1] 10 95 &gt; max(course$score) [1] 95 &gt; min(course$score) [1] 10 범위는 매우 직관적이고 간편하게 계산할 수 있으나 다음 예처럼 한 두 개의 예외적 데이터가 있으면 크게 그 값이 변하는 약점이 있다. &gt; range(x) [1] 46 55 &gt; range(y) [1] 46 1000 &gt; range(z) [1] -1000 55 지금까지 배운 중심 경향과 퍼진 정도를 보여주는 통계량을 course 데이터의 score 변수에 적용하여 비교한 결과이다. mean median sd IQR mad range 71.46089 72.6 14.84913 18.99 13.06171 85 8.1.1.3 분포의 치우친 정도를 보여주는 통계량 왜도(skewness)는 수치형 변수의 분포가 치우친 정도를 측정하는 통계량이다. 왜도는 다음 식으로 계산된다.6 \\[ Skewness = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{s} \\right)^3 \\] 왜도를 사용하면 분포의 대칭성과 비대칭성을 확인할 수 있다. 좌우 대칭인 분포에서는 왜도는 0이 된다. 분포가 왼쪽으로 치우쳐 있으면(오른쪽으로 긴 꼬리를 가지면) 왜도는 양의 값이 된다. 분포가 오른쪽으로 치우쳐 있으면(왼쪽으로 긴 꼬리를 가지면) 왜도는 음의 값이 된다. R의 기본 기능에는 왜도를 계산하는 함수가 없다. 왜도를 계산해 주는 함수를 가진 패키지로는 moments, fBasics, psych 등이 있다. 이 책에서는 psych 패키지를 사용한다. 먼저 psych 패키지는 bizstatp 패키지를 설치하였다면 설치가 이미 되었을 것이다. psych는 ggplot2 패키지와 충돌하는 이름들이 있어서 library() 함수로 psych 패키지를 메모리에 적재하지 않고 다음처럼 :: 연산자로 바로 psych 패키지의 skew() 함수를 사용하도록 한다. 다음 예는 대칭인 경우 오른쪽에 긴 꼬리가 있는 경우, 왼쪽으로 긴 꼬리가 있는 경우의 왜도가 어떻게 계산되는지를 보여준다. &gt; x; psych::skew(x) [1] 46 47 48 49 50 51 52 53 54 55 [1] 0 &gt; y; psych::skew(y) [1] 46 47 48 49 50 51 52 53 54 55 1000 [1] 2.466456 &gt; z; psych::skew(z) [1] 46 47 48 49 50 51 52 53 54 55 -1000 [1] -2.466539 다음은 course 데이터의 총점, 중간고사, 기말고사의 왜도를 계산한 결과이다. 주의할 점은 psych 패키지의 skew() 함수는 지금까지 본 R의 기본 함수와는 달리 결측치가 있을 때 na.rm 인수를 지정하지 않아도 자동으로 결측치를 제외하고 왜도를 계산한다는 점이다. &gt; psych::skew(course$score) [1] -1.296142 &gt; psych::skew(course$mid) [1] 0.2409169 &gt; psych::skew(course$final) [1] -0.02417389 총점은 왼쪽으로 꼬리가 긴 분포이고, 중간과 기말은 비교적 대칭인 분포임을 알 수 있다. 중간과 기말은 시험을 안 본 학생은 제외하고 계산이 되어 비교적 대칭인 분포였고, 총점은 시험을 안 본 학생이 총점에 포함되어 있어서 이 학생에 의해 왼쪽으로 꼬리가 긴 비대칭적인 분포처럼 왜도가 계산 되었다. 뒤에서 그래프를 통해서 이 사실을 다시 확인할 수 있을 것이다. 이처럼 왜도도 평균과 분산처럼 예외적인 값에 영향을 크게 받는 단점이 있다. 그러므로 왜도는 값만으로 변수의 분포를 단정지으면 안되고, 그래프를 사용하여 분포의 모양도 함께 확인해 보아야 한다. 다음처럼 na.omit() 함수로 결측치가 있는 행은 제외하고 다시 총점의 왜도를 계산해 보면 분포가 크게 비대칭적이지는 않음을 확인할 수 있다. &gt; course_omitted &lt;- na.omit(course) &gt; psych::skew(course_omitted$score) [1] 0.2385544 8.1.1.4 분포의 뾰족함을 보여주는 통계량 첨도(kurtosis)는 분포가 얼마나 뾰족한지를 나타낸다. 첨도는 다음 식으로 계산된다.7 \\[ kurtosis = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{s} \\right)^4 - 3 \\] 첨도를 사용하면 분포의 뾰족한 정도를 확인할 수 있다. 정규분포에서는 첨도는 0이 된다. 분포가 정규분포보다 더 뾰족하면 첨도는 양의 값이 된다. 분포가 정규분포보다 덜 뾰족하면(더 평평하면) 첨도는 음의 값이 된다. R의 기본 기능에는 첨도를 계산하는 함수가 없다. 따라서 첨도의 계산에는 psych 패키지의 kurtosi() 함수를 사용하도록 한다. 다음은 course 데이터의 총점, 중간고사, 기말고사의 첨도를 계산한 결과이다. 왜도를 계산하는 skew()와 마찬가지로 결측치를 자동으로 제외하고 첨도를 계산하는 것을 확인할 수 있다. &gt; psych::kurtosi(course$score) [1] 4.29198 &gt; psych::kurtosi(course$mid) [1] -1.313393 &gt; psych::kurtosi(course$final) [1] -0.957484 중간고사와 기말고사의 분포는 정규분포보다 더 평평한 분포이지만, 총점은 더 뾰족한 분포로 계산되었다. 총점이 매우 뾰족한 분포로 나온 이유는 시험을 안 본 예외적인 학생 때문이다. 이처럼 첨도도 평균, 분산, 왜도처럼 이상치의 영향을 크게 받는다. 시험을 안 본 학생을 제외하고 다시 총점의 첨도를 계산해 보면 정규분포보다 뾰족한 분포가 아니라 평평한 분포를 가지고 있음을 알 수 있다. &gt; psych::kurtosi(course_omitted$score) [1] -1.122113 8.1.1.5 수치 변수의 기술통계량을 한 번에 파악하기 psych 패키지의 describe() 함수는 수치 변수에 대한 다양한 기술통계량을 제공한다. 다음은 course의 다섯 번째에서 여덟 번째 열에 대하여 psych 패키지의 describe() 함수를 이용하여 다양한 기술통계량을 계산한 예이다. skew()나 kurtosi() 등의 다른 psych 패키지의 함수처럼 결측치는 자동으로 제외하고 통계량을 계산해 준다. &gt; psych::describe(course[5:8]) vars n mean sd median trimmed mad min max range skew kurtosis mid 1 44 61.61 20.49 59.0 61.03 25.20 27 97.00 70.00 0.24 -1.31 final 2 44 63.16 18.26 65.5 63.06 22.98 23 95.00 72.00 -0.02 -0.96 hw 3 45 83.37 13.36 84.3 85.41 4.45 0 91.33 91.33 -5.38 30.76 score 4 45 71.46 14.85 72.6 72.09 13.06 10 95.00 85.00 -1.30 4.29 se mid 3.09 final 2.75 hw 1.99 score 2.21 네 개의 수치형 변수에 대한 통계량이 행별로 제시되어 있다. 평균(mean), 표준편차(sd), 중위수(median), 중앙값 절대 편차(mad), 최소값(min), 최대값(max), 범위(range), 왜도(skew), 첨도(kurtosis)는 이미 설명을 하였다. 결과에서 n 열은 결측치를 제외한 관측치 수를, trimmed 열은 양 극단의 수치를 일부 잘라내고 계산한 평균을, se 열은 평균의 표준 오차(standard error)를 의미한다. 표준오차는 \\(se = sd / \\sqrt{n}\\)으로 계산된다. 8.1.1.6 도수분포표 한두 개의 통계량으로 수치형 변수의 특성을 파악하는 방법 외에도 수치형 변수의 전체적인 분포의 윤곽을 파악하려면 도수분포표를 사용하는 것이 좋다. 도수분포표는 수치를 계급이라 불리는 몇 개의 구간으로 나누어 구간 별로 관측 도수를 집계한 표를 의미한다. 히스토그램은 도수분포표를 시각적으로 표현한 것이다. R에서 연속적인 수치형 변수에서 도수분포표를 만드는 방법은 cut() 함수로 수치형 변수를 구간으로 나눈 범주형 변수로 변환한 후, 변주형 변수의 빈도표를 만들 때 사용한 table()이나 xtabs() 함수를 이용하는 것이다. cut() 함수의 기본 문법은 다음과 같다. cut(수치 벡터, breaks = 구간을 나누는 점) 다음은 course 데이터의 총점(score) 열을 cut() 함수를 이용하여 10점 단위의 구간으로 나누어 범주형 변수로 변환한 결과이다. &gt; course$score [1] 73.47 61.50 89.18 78.47 93.88 64.39 72.60 55.54 59.89 66.00 79.99 70.10 [13] 56.53 53.74 59.89 63.79 71.14 64.99 88.69 70.59 83.79 60.39 88.31 80.00 [25] 81.10 87.28 93.09 90.58 60.09 66.87 64.50 75.09 66.99 79.64 57.77 95.00 [37] 73.37 10.00 74.88 61.06 80.49 74.29 59.59 83.01 74.19 &gt; grade &lt;- cut(course$score, breaks = seq(from = 0, to = 100, by = 10)) &gt; grade [1] (70,80] (60,70] (80,90] (70,80] (90,100] (60,70] (70,80] (50,60] [9] (50,60] (60,70] (70,80] (70,80] (50,60] (50,60] (50,60] (60,70] [17] (70,80] (60,70] (80,90] (70,80] (80,90] (60,70] (80,90] (70,80] [25] (80,90] (80,90] (90,100] (90,100] (60,70] (60,70] (60,70] (70,80] [33] (60,70] (70,80] (50,60] (90,100] (70,80] (0,10] (70,80] (60,70] [41] (80,90] (70,80] (50,60] (80,90] (70,80] 10 Levels: (0,10] (10,20] (20,30] (30,40] (40,50] (50,60] (60,70] ... (90,100] 위 결과에서 볼 수 있듯이 cut() 함수는 첫째 인수로 숫자 벡터를 받고, breaks 인수로 관측값을 나눌 계급을 지정한다. 여기서는 0, 10, …, 90, 100으로 구성된 숫자 벡터를 지정하였으므로, (0,10], (10,20], (20,30], (30,40], (40,50], (50,60], (60,70], (70,80], (80,90], (90,100] 등 10 개의 계급이 만들어진다. 그러므로 73.47, 61.5 같은 수치값이 (70,80], (60,70] 같은 구간을 나타내는 범주로 변환된 것을 볼 수 있다. 범주형 변수로 변형되었으니 cut() 함수의 결과를 table() 함수에 전달하면 도수분포표를 구할 수 있다. &gt; table(grade) grade (0,10] (10,20] (20,30] (30,40] (40,50] (50,60] (60,70] (70,80] 1 0 0 0 0 7 11 14 (80,90] (90,100] 8 4 그런데 계급을 나누는 표시를 보면 (0,10]처럼 왼쪽은 괄호(()로, 오른쪽은 대괄호(])로 구간의 경계가 표시한 것을 볼 수 있다. 괄호는 개구간의 경계를 의미하여 해당 경계가 구간에 포함되지 않음을 의미하며, 대괄호는 폐구간의 경계를 의미하여 해당 경계가 구간에 포함된다는 것을 의미한다. 따라서 0 점은 (0,10] 구간에 포함되지 않지만, 10 점은 (0,10] 구간에 포함된다. 이는 경계가 어는 한 구간에만 포함되도록 하기 위한 것이다. cut()은 기본적으로 구간의 오른쪽 경계를 포함하고 왼쪽 경계를 포함하지 않도록 한다. 그런데 이렇게 하면 0점을 받은 데이터는 어느 구간에도 포함되지 않는 문제가 발생한다. 만약 breaks로 주어진 첫 번째 경계도 구간에 모두 포함시키려면 다음처럼 include.lowest=TRUE로 설정한다. 첫 번째 구간의 왼쪽 경계가 구간에 포함된 것을 볼 수 있다. &gt; grade &lt;- cut(course$score, breaks=seq(from=0, to=100, by=10), include.lowest = TRUE) &gt; table(grade) grade [0,10] (10,20] (20,30] (30,40] (40,50] (50,60] (60,70] (70,80] 1 0 0 0 0 7 11 14 (80,90] (90,100] 8 4 그런데 앞의 예에서 (80, 90], (90, 100] 등의 구간은 80점과 90점은 포함되지 않는다. 만약 구간의 왼쪽 경계를 포함하고 오른쪽 경계를 포함하지 않도록 하려면 right=FALSE로 설정한다. &gt; grade &lt;- cut(course$score, breaks=seq(from=0, to=100, by=10), + include.lowest = TRUE, right=FALSE) &gt; table(grade) grade [0,10) [10,20) [20,30) [30,40) [40,50) [50,60) [60,70) [70,80) 0 1 0 0 0 7 11 13 [80,90) [90,100] 9 4 다음은 course 데이터의 중간고사 점수를 20 점 간격으로 나누어 도수분포표를 만들어 본 결과이다. &gt; table(cut(course$mid, + breaks = seq(from = 0, to = 100, by = 20), + include.lowest = T)) [0,20] (20,40] (40,60] (60,80] (80,100] 0 7 15 11 11 R에서 수치형 변수를 범주형 변수로 변환할 때, R의 기본 기능이 제공하는 cut() 함수 외에도 ggplot2() 패키지가 제공하는 다음 함수도 사용할 수 있다. 관심 있는 독자는 R 도움말 등을 참조하기 바란다. cut_width(): 구간의 폭(width)을 지정하면 수치형 변수를 동일한 폭으로 구간을 나눈다. cut_interval(): 구간의 수(n)를 지정하면 수치형 변수를 동일한 폭으로 구간을 나눈다. cut_number(): 구간의 수(n)를 지정하면 수치형 변수를 구간에 동일한 수의 관측값이 들어가도록 구간을 나눈다. 8.1.2 수치형 변수 분포를 그래프로 요약하기 수치형 변수를 수치로 요약하는 하는 방식은 분포의 중심, 퍼진 정도, 치우침 등을 대략적으로 파악할 수 있고 서로 다른 분포를 수치로 비교할 수 있는 장점이 있다. 그러나 분포의 세부적인 모양은 알 수 없다. 평균이 같은 분포이어도 서로 매우 다른 모양의 분포일 수 있다. 다음은 평균이 모두 2인 세 분포를 보여주고 있다. 평균이 동일하더라도 분포의 세부 모습은 크게 다를 수 있다. 그러므로 수치로 요약하는 것뿐 아니라 그래프를 사용하여 수치형 분포의 세부적인 모양을 파악할 필요가 있다. 수치형 변수의 그래프를 살펴볼 때는 다음 사항을 주의깊게 살펴보아야 한다. 분포는 어느 정도 대칭적인 모양을 가지고 있는가? 비대칭적인 모양이라면 변환을 사용하여 대칭적인 분포로 변환할 수 있는가? 분포는 대체적으로 하나의 봉우리를 가지고 있는가? 아니면 두 개 이상의 봉우리를 가지고 있는가? 분포는 정규분포와 비슷한 모양을 가지고 있는가, 아니면 전혀 다른 모양의 분포를 가지고 있는가? 분포에 다른 데이터와 동떨어져 있는 이상치는 없는가? 8.1.2.1 히스토그램 수치형 변수의 도수분포표에 따라 막대 그래프를 그린 것이 히스토그램이다. 히스토그램은 수치형 분포의 전체적인 윤관을 파악할 때 가장 많이 사용되는 그래프이다. ggplot2 패키지는 수치형 변수에 대한 히스토그램을 그려주는 geom_histogram() 함수를 제공한다. geom_histogram()의 기본적인 문법은 다음과 같다. ggplot(데이터, aes(x = 수치형변수)) + geom_histogram() 다음은 course 데이터의 총점 변수에 대한 히스토그램을 그린 예이다. &gt; library(ggplot2) &gt; ggplot(course, aes(x = score)) + geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 출력된 메시지에서 확인할 수 있듯이 기본적으로 수치 변수를 30 개의 구간으로 나누어 히스토그램을 그린다. 그러나 자동으로 부여된 구간 수가 수치형 변수를 표현하는 가장 좋은 방식이 아닐 수 있다. 위의 예에서는 45 개의 데이터밖에 없는데 구간이 30 개나 되어 한 구간에 매우 적은 관측 도수밖에 없어서 우연적인 경향이 그래프로 나타날 수 있다. 그러므로 주어진 수치형 변수의 분포를 가장 잘 표현할 수 있도록 구간의 수를 조정해 볼 필요가 있다. geom_histogram() 함수는 bins 인수로 사용자가 원하는 구간의 수를 입력 받는다. 또는 다은은 15 개와 10개의 구간으로 히스토그램을 그린 예이다. 구간의 수를 조정함에 따라 히스토그램의 모습이 크게 바뀌는 것을 볼 수 있다. 그러므로 히스토그램을 그릴 때는 분포의 모양을 잘 표현할 수 있도록 구간의 수를 잘 조정해야 한다. &gt; ggplot(course, aes(x = score)) + geom_histogram(bins = 15) &gt; ggplot(course, aes(x = score)) + geom_histogram(bins = 10) geom_histogram() 함수는 bins 인수로 구간의 수를 지정할 수 있을 뿐 아니라, binwidth 인수를 이용하여 구간의 폭을 지정할 수도 있다. 다음은 구간의 폭이 10이 되돍 하여 총점의 히스토그램을 그린 예이다. &gt; ggplot(course, aes(x = score)) + geom_histogram(binwidth = 10) 그런데 보통 구간의 크기를 지정하면 최소값과 최대값을 기준으로 binwidth의 길이로 구간을 나누므로, 나누어진 경계가 원하는 수치가 아닐 수 있다. 총점처럼 점수의 경우는 정확히 10, 20, …, 90, 100 등이 구간의 경계가 되는 것이 좋을 수 있다. 이처럼 원하는 경계에 따라 구간을 나누어 히스토그램을 그리려면, cut() 함수와 마찬가지로 breaks 인수를 이용하여 구간을 나누는 지점을 지정할 수 있다. cut() 함수와 다른 점은 right가 아니라 closed 인수를 사용하여 구간에 왼쪽 경계를 포함할지 오른쪽 경계를 포함할지를 지정하는 점이 다르다. (막대의 구간을 정확히 확인할 수 있도록 scale_x_continous() 함수로 가로축의 눈금을 조정하였다. 이 함수의 사용법은 R 프로그래밍의 그래프의 좌표축 조정 절을 참조. ) &gt; ggplot(course, aes(x = score)) + + geom_histogram(breaks = seq(from=0, to=100, by=10), closed=&quot;left&quot;) + + scale_x_continuous(breaks = seq(from=0, to=100, by=20)) 8.1.2.2 확률 밀도 그래프 수치형 변수는 통계에서 자주 정규분포를 따른다고 가정된다. 정규분포를 정확히 따르지 않더라도 정규분포처럼 대칭적인 분포로 가정되는 경우가 많다. 따라서 히스토그램 등으로 수치형 변수의 분포를 살펴볼 때 다음 두 가지 사항을 확인해 보아야 한다. 수치형 변수의 분포가 한 쪽으로 치우친 분포는 아닌가? 특히 소득분포처럼 한 쪽으로 크게 치우친 분포의 경우는 분석을 수행할 때 로그 함수로 값을 변환하여 분석하는 게 좋을 때가 많다. 수치형 변수의 분포가 여러 봉우리는 가지고 있지는 않은가? 수치형 변수의 분포가 두 개 이상의 봉우리를 가지게 되면 수치형 변수의 값에 영향을 미치는 두 개 이상의 이질적인 집단이 있을 수 있다. 이러한 경우 하나의 집단으로 묶어서 분석을 할 때 좋은 결과를 얻기 힘든 경우가 많다. 따라서 분포에서 여러 봉우리를 만드는 원인이 무엇인지를 추적해 볼 필요가 있다. 그런데 히스토그램은 막대의 간격에 따라 여러 다른 모습의 분포를 보여주므로 분포의 봉우리를 파악하기 어렵다. 이런 경우에는 수치형 변수의 분포에 대한 확률밀도를 추정하여 그래프로 그려보면 분포의 추세를 파악하기 쉽다. ggplot2 패키지의 geom_density() 함수는 수치형 변수에 대해 (추정된) 확률 밀도 그래프를 그려준다. ggplot(데이터, aes(x = 수치형변수)) + geom_density() 다은은 course 데이터의 총점 열의 확률 밀도 그래프를 그린 예이다. &gt; ggplot(course, aes(x = score)) + geom_density() 그런데 확률밀도 함수는 추정된 것이므로 실제 데이터와 잘 부합되는지 확인해 보아야 한다. 따라서 히스토그램과 확률밀도 함수를 같은 좌표평면에 나타내서 서로 부합되는지 확인하는 것이 필요하다. 그런데 히스토그램은 각 구간의 절대 빈도로 세로축의 축적을 사용하고, 확률 밀도는 함수의 밑의 면적이 1이 되도록 세로축의 축적을 사용한다. 그러므로 두 그래프가 좌표평면에서 같이 표현되려면 히스토그램을 절대 빈도가 아니라 면적이 1이 되도록 상대 빈도로 그래프를 그려야 한다. 다음은 수치형 변수를 상대 빈도로 그래프를 그리는 문법이다. ggplot(데이터, aes(x = 수치형변수)) + geom_histogram(aes(y = ..density..)) 다음은 course 데이터에 대한 히스토그램과 함께 추정되는 밀도 함수를 그린 예이다. 확률밀도 그래프에서 총점이 두 개의 봉우리를 가지는 것으로 나타나는데, 총점이 매우 낮은 예외적인 한 명의 학생과 나머지 학생 그룹에 의해서 이러한 분포가 나타난 것을 확인할 수 있다. geom_vline()으로 분포의 평균(빨간 실선)과 중위수(파란 파선)도 같이 표현하였는데, 예외적으로 낮은 점수의 학생 한 명 때문에 평균이 중위수보다 작은 왼쪽으로 꼬리가 긴 분포의 모양을 가지고 있음을 볼 수 있다. &gt; ggplot(course, aes(score)) + + geom_histogram(aes(y=..density..), breaks = seq(from=0, to=100, by=10), closed=&quot;left&quot;) + + geom_density() + + geom_vline(xintercept = mean(course$score), color=&quot;red&quot;, linetype=1) + + geom_vline(xintercept = median(course$score), color=&quot;blue&quot;, linetype=2) Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ℹ Please use `after_stat(density)` instead. 예외적으로 매우 낮은 점수를 받은 학생은 시험을 치르지 않아 0점 처리된 학생이다. 이 학생을 제외하고 분포를 다시 그려보자. 약간의 비대칭성이 있지만 평균과 중위수가 거의 같은 자리에 있어서 총점이 거의 대칭에 가까운 분포임을 볼 수 있다. &gt; ggplot(course_omitted, aes(score)) + + geom_histogram(aes(y=..density..), breaks = seq(from=0, to=100, by=10), closed=&quot;left&quot;) + + geom_density() + + geom_vline(xintercept = mean(course_omitted$score), color=&quot;red&quot;, linetype=1) + + geom_vline(xintercept = median(course_omitted$score), color=&quot;blue&quot;, linetype=2) 예외적인 데이터를 제외한 총점의 기술통계량을 살펴보면 왜도가 거의 0에 가까워서 대칭적인 분포이고, 첨도는 0보다 작아서 정규분포보다는 조금 납작한 형태의 분포임을 알 수 있다. &gt; psych::describe(course_omitted$score) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 44 72.86 11.65 72.98 72.49 13.19 53.74 95 41.26 0.24 -1.12 1.76 8.1.2.3 Q-Q 그림 어떤 분포가 정규분포를 따르는지를 시각적으로 확인하는 방법 중 하나가 Q-Q 그림을 그려보는 것이다. Q-Q 그림은 실측된 변수와 이론적인 분포의 분위수(quantile)가 서로 부합되는지를 살펴본다. 부합이 된다면 Q-Q 그림은 직선에 가까운 그래프를 보인다. ggplot2 패키지가 제공하는 geom_qq() 함수는 실측된 변수를 정규분포의 분위수와 비교하는 점을 그려준다. geom_qq_line()은 이론적 분포에 실제 분포가 부합될 때 점들이 위치되어야 할 직선을 그려준다. 다음은 ggplot2 패키지를 이용하여 Q-Q 그림을 그리는 문법이다. ggplot(데이터, aes(sample = 수치형변수)) + geom_qq() + geom_qq_line() 다음은 course 데이터의 총점 변수에 대한 Q-Q 그림을 그린 예이다. &gt; ggplot(course, aes(sample = score)) + + geom_qq() + geom_qq_line(color=&quot;red&quot;) 총점은 예외적으로 낮은 점수의 한 학생 때문에 정규분포와 차이를 보이고 있다. 예외적인 학생을 제외하고 Q-Q 그래프를 다시 그려보자. Q-Q 그림에서 가로축은 이론적인 정규분포를 세로축은 실제 데이터를 나타낸다. Q-Q 그림에서 실제 데이터가 정규분포에 비해 양 끝이 좀 더 중심에 가깝게 분포되어 있는 것을 확인할 수 있다. 그러므로 총점 분포는 정규분포보다 더 평평한 모양을 가지고 이는 첨도 값에서도 확인할 수 있었다. &gt; ggplot(course_omitted, aes(sample = score)) + + geom_qq() + geom_qq_line(color=&quot;red&quot;) 이러한 정규분포와의 차이가 통계적으로 유의미한 것인지 분포의 정규성에 대해 가설검정을 해보자. p-값이 크게 나와 실제 데이터와 정규분포와의 차이는 통계적으로 유의미하지 않은 것으로 확인된다. &gt; shapiro.test(course_omitted$score) Shapiro-Wilk normality test data: course_omitted$score W = 0.95653, p-value = 0.09646 8.1.2.4 상자 그림 어떤 분포에 이상치가 있는지를 살펴보려면 상자 그림(box plots)를 그려보는 것이 좋다. 상자 그림은 그림 8.1와 같은 상자 모양으로 수치형 변수의 분포를 나타낸다. 상자 그림으로 수치형 변수의 분포에 대해서 알아낼 수 있는 정보는 다음과 같다. Figure 8.1: 상자 그림의 의미 상자의 상단은 수치형 분포의 3분위수(3Q)를, 상자의 하단은 수치형 분포의 1분위수(1Q)를 나타낸다. 따라서 상자의 범위만으로 상위 25%와 하위 25%를 제외한 가운데 50%의 데이터의 범위를 확인할 수 있다. 상자 가운데 진한 선은 2분수(2Q), 즉, 중위수를 나타낸다. 중위수의 위치로 분포가 대략적으로 대칭인지 한쪽으로 쏠려있는지를 파악할 수 있다. 중위수가 상자의 중간에 위치하면 분포가 어느 정도 대칭적인 모양임을 알 수 있다. 중위수가 상자의 상단에 가까우면 분포가 오른쪽으로 치우친(왼쪽으로 꼬리가 긴) 분포이고, 중위수가 상자의 하단에 가까우면 왼쪽으로 치우친(오른쪽으로 꼬리가 긴) 분포일 가능성이 크다. 상자 상단과 하단의 수염(whiskers)은 이상치를 제외한 분포의 최대값과 최소값을 나타낸다. 3분위수와 1분위수의 차이를 IQR(interquartile range)라고 한다. 일반적으로 3분위수에서 분포의 상단쪽으로 IQR의 1.5 배보다 멀리 떨어진 수치는 이상치로 간주한다. 마찬가지로 1분위수에서 분포의 하단쪽으로 IQR의 1.5 배보다 멀리 떨어진 수치도 이상치로 간주한다. 상자의 수염은 상자에서 1.5 IQR 범위 내의 데이터 중 가장 큰 값과 가장 작은 값의 위치를 알려준다. 상자에서 1.5 IQR보다 더 멀리 떨어진 모든 데이터는 이상치로 간주하여 점으로 표현한다. ggplot2 패키지의 geom_boxplot() 함수는 상자 그림을 그려준다. 다음은 ggplot2 패키지를 이용하여 상자 그림을 그리는 문법이다. ggplot(데이터, aes(x 또는 y = 수치형변수)) + geom_boxplot() 다음은 course 데이터의 총점 변수에 대한 상자 그림을 그린 예이다. y 속성에 score 변수를 매핑하였다. 이렇게 한 수치형 변수를 y에 매핑하여 상자 그림을 그릴 때는 그래프의 가로축의 수치는 별다른 의미를 가지지 않는다. 나중에 상자 그래프는 범주형 변수에 따라 수치형 변수의 분포가 어떻게 변하는지를 보기 위해 자주 사용되는데 그 때는 가로축은 범주형 변수의 값을 의미한다. &gt; ggplot(course, aes(y = score)) + geom_boxplot() 총점은 약간 상단에 치우친(오른쪽에 치우친) 분포의 모습을 보여주고 있고, 최소값이 일반적인 데이터에서 크게 떨어져 있는 이상치임을 확인할 수 있다. 8.1.3 수치형 변수의 변환 오른쪽으로 꼬리가 긴 분포를 가지는 수치형 변수의 변환 ggplot2 패키지가 제공하는 diamonds 데이터에서 다이아몬드의 중량(carat)과 가격(price) 변수의 분포를 확인해 보자. 특히 다이아몬드 가격은 오른쪽으로 매우 꼬리가 긴 분포로 전혀 대칭적이지 않다. &gt; ggplot(diamonds, aes(x = carat)) + geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. &gt; psych::describe(diamonds$carat) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 53940 0.8 0.47 0.7 0.73 0.47 0.2 5.01 4.81 1.12 1.26 0 &gt; ggplot(diamonds, aes(x = price)) + geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. &gt; psych::describe(diamonds$price) vars n mean sd median trimmed mad min max range skew X1 1 53940 3932.8 3989.44 2401 3158.99 2475.94 326 18823 18497 1.62 kurtosis se X1 2.18 17.18 이러한 분포처럼 대부분의 관측치가 한 쪽에 치우쳐 있는 분포를 그대로 사용하여 모형을 만들면 다음과 같은 문제점이 발생한다. 모형이 예외적으로 큰 값의 영향을 크게 받아 대다수의 값이 모여 있는 구간에서의 분석의 정확도가 떨어질 수 있다. 가설검정이나 회귀모형에서 분포의 정규성이 가정되어야 하는 경우 가설검정이나 회귀모형을 수행할 수 없게 된다. 수치형 변수가 이렇게 가격이나 소득처럼 관측값이 모두 0 이상이고 왼쪽으로 치우친 분포를 보이는 경우, 로그 변환이나 제곱근으로 변환하여 대칭적인 분포를 만들어 통계 분석을 하는 것이 좋다. 로그 변환은 1, 10, 100, 1000 등으로 동일한 배수로 늘어나는 수치를 0, 1, 2, 3 등으로 등간격 척도로 변환해 준다. 즉, 100 만원과 1,000 만원의 차이가 1,000 만원에서 1 억의 차이와 같아지도록 척도를 변환해 준다. 제곱근으로 변환하면, 1, 4, 9, 16 등으로 제곱수로 늘어나는 값을 1, 2, 3, 4 등의 등간격 척도로 변환해 준다. 즉, 만원을 가진 사람에게 3만원을 더해주는 효과와 4만원을 가진 사람에게 5만원을 더해주는 효과가 같다고 간주한다. ggplot2는 scale_x_log10()과 scale_x_sqrt() 함수를 가지고 있어서 가로축의 값을 자동으로 로그 변환 또는 제곱근 변환을 하여 그래프를 그려준다. &gt; ggplot(diamonds, aes(x = price)) + geom_histogram() + scale_x_log10() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. &gt; ggplot(diamonds, aes(x = price)) + geom_histogram() + scale_x_sqrt() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 그래프의 결과를 보듯이 제곱근 변환으로는 분포를 충분히 대칭적인 형태로 변환하지 못한다. 반면 로그 변환을 하면 다이아몬드 가격의 분포가 어느 정도 대칭적인 모습으로 변하는 것을 볼 수 있다. 아울러 로그 변환한 변수의 히스토그램을 보면 2 개 이상의 봉우리가 보인다. 확률 밀도 그래프를 그려 분포의 봉우리를 다시 확인해 보자. &gt; ggplot(diamonds, aes(x = price)) + + geom_histogram(aes(y=..density..)) + geom_density(color=&quot;red&quot;) + scale_x_log10() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 가격 분포에서 여러 봉우리가 있는 것으로 보아 가격과 관련하여 다이아몬드가 여러 개의 군집으로 나누어 질 수 있음을 알 수 있다. 가격이 왜 이러한 군집된 형태를 보이는가에 대한 탐구는 다음 절로 넘기고, 여기서는 다이아몬드 중량에 대해서도 같은 변환을 한 후 그래프를 그려보자. &gt; ggplot(diamonds, aes(x = carat)) + geom_histogram() + scale_x_log10() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. &gt; ggplot(diamonds, aes(x = carat)) + geom_histogram() + scale_x_sqrt() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 중량도 제곱근보다는 로그 변환이 더 적절해 보인다. 로그 변환 그래프를 보면 2 개 이상의 봉우리가 보인다. 다시 확률 밀도 그래프를 그려 분포의 봉우리를 확인해 보자. &gt; ggplot(diamonds, aes(x = carat)) + + geom_histogram(aes(y=..density..)) + geom_density(color=&quot;red&quot;) + scale_x_log10() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 다이아몬드 중량과 가격 변수를 로그 변환한 후의 기술통계량을 살펴보자. 수치 변수를 밑이 10일 로그로 변환하려면 log10() 함수를 사용한다. (제곱근으로 변환하려면 sqrt() 함수를 사용한다.) 두 변수 모두 로그 변환 후에 평균과 중위수의 값의 차이가 작고, 왜도도 0에 가까워 대칭적인 분포의 모습을 보인다. 첨도는 두 변수 모두 음의 값으로 정규분포보다는 납작하게 퍼진 분포를 보여준다. &gt; psych::describe(log10(diamonds$carat)) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 53940 -0.17 0.25 -0.15 -0.18 0.31 -0.7 0.7 1.4 0.1 -1.06 0 &gt; psych::describe(log10(diamonds$price)) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 53940 3.38 0.44 3.38 3.37 0.56 2.51 4.27 1.76 0.12 -1.1 0 로그 변환을 할 때 한 가지 주의 사항은 로그 값은 오직 양의 값에 대해서만 정의된다. 수치 변수가 0의 값을 가지면 로그 변환하면 음의 무한대의 값을 가지므로 제대로된 변환이 되지 않는다. 그러한 경우에는 수치 변수에 1을 더해서 로그 변환한다. 예를 들어 diamond의 y 변수를 로그 변환한다고 가정해 보자. 이 변수는 0으로 측정된 값이 있으므로 로그 변환하면 평균 등이 모두 음의 무한대가 되는 것을 볼 수 있다. &gt; summary(diamonds$y) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.000 4.720 5.710 5.735 6.540 58.900 &gt; psych::describe(log10(diamonds$y)) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 53940 -Inf NaN 0.76 0.75 0.11 -Inf 1.77 Inf NaN NaN NaN 이러한 경우 1을 변수에 더한 후 로그 변환을 하면 된다. 물론 이렇게 1이 더해진 수치변수는 해석을 할 때 1이 더해진 수치임을 잊지 말아야 한다. &gt; psych::describe(log10(diamonds$y + 1)) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 53940 0.82 0.07 0.83 0.82 0.09 0 1.78 1.78 0.01 1.88 0 자주 사용되는 변환 방법 지금까지는 오른쪽으로 꼬리가 긴 분포에 대하여 로그 변환과 제곱근 변환을 하는 방법을 살펴보았다. 그러나 이러한 변환 외에도 변수의 역수를 취하거나 제곱을 하는 변환 등도 사용할 수도 있다. 다음 표는 마케팅이나 경영 문제에서 자주 사용되는 수치형 변수의 변환 방법이다. ((Chapman and Feit 2015, p 102)에서 인용) 변수 자주 사용되는 변환 방법 판매량, 판매수입, 가구수입, 가격 \\(\\log(x)\\) 거리 \\(1/x\\), \\(1/x^2\\), \\(\\log(x)\\) 오른쪽으로 꼬리가 긴 분포 \\(\\sqrt{x}\\), \\(\\log(x)\\) 왼쪽으로 꼬리가 긴 분포 \\(x^2\\) 변환된 변수를 데이터 열로 추가하기 수치형 변수에 대하여 적절한 변환을 수행한 후, 변환된 변수를 분석에 사용하려면 데이터에 새로운 열로 추가하는 것이 좋다. 데이터에 새로운 열을 추가하는 방법은 다음과 같다. 데이터$추가할_열_이름 &lt;- log10(데이터$수치형변수) # 밑이 10인 로그로 변환 후 열 추가 데이터$추가할_열_이름 &lt;- sqrt(데이터$수치형변수) # 제곱근으로 변환 후 열 추가 #데이터$추가할_열_이름 &lt;- 수치함수(데이터$수치형변수) 결과나 수치 벡터 연산으로 변환 후 저장 다음은 diamonds 데이터의 carat과 price 열을 각각 밑이 10인 로그로 변환한 후 carat_log10과 price_log10이라는 열로 diamonds 데이터에 추가한 예이다. &gt; diamonds$carat_log10 &lt;- log10(diamonds$carat) &gt; diamonds$price_log10 &lt;- log10(diamonds$price) &gt; summary(diamonds) carat cut color clarity depth Min. :0.2000 Fair : 1610 D: 6775 SI1 :13065 Min. :43.00 1st Qu.:0.4000 Good : 4906 E: 9797 VS2 :12258 1st Qu.:61.00 Median :0.7000 Very Good:12082 F: 9542 SI2 : 9194 Median :61.80 Mean :0.7979 Premium :13791 G:11292 VS1 : 8171 Mean :61.75 3rd Qu.:1.0400 Ideal :21551 H: 8304 VVS2 : 5066 3rd Qu.:62.50 Max. :5.0100 I: 5422 VVS1 : 3655 Max. :79.00 J: 2808 (Other): 2531 table price x y Min. :43.00 Min. : 326 Min. : 0.000 Min. : 0.000 1st Qu.:56.00 1st Qu.: 950 1st Qu.: 4.710 1st Qu.: 4.720 Median :57.00 Median : 2401 Median : 5.700 Median : 5.710 Mean :57.46 Mean : 3933 Mean : 5.731 Mean : 5.735 3rd Qu.:59.00 3rd Qu.: 5324 3rd Qu.: 6.540 3rd Qu.: 6.540 Max. :95.00 Max. :18823 Max. :10.740 Max. :58.900 z carat_log10 price_log10 Min. : 0.000 Min. :-0.69897 Min. :2.513 1st Qu.: 2.910 1st Qu.:-0.39794 1st Qu.:2.978 Median : 3.530 Median :-0.15490 Median :3.380 Mean : 3.539 Mean :-0.17153 Mean :3.382 3rd Qu.: 4.040 3rd Qu.: 0.01703 3rd Qu.:3.726 Max. :31.800 Max. : 0.69984 Max. :4.275 8.1.3.1 Box-Cox 변환 자주 사용되는 변환 방법으로도 좋은 결과를 얻지 못했거나 어떠한 변환이 좋을지 모를 때는 일반적인 변환 방법인 Box-Cox 변환을 사용할 수 있다. Box-Cox 변환은 수치형 변수를 거듭제곱 형태로 변환한다. 예를 들어 원 수치형 변수 \\(x\\)를 \\(x^2, 1/x = x^{-1}, x^{1/2} = \\sqrt{x}\\) 등의 거듭제곱 형태로 변환을 한다. 좀 더 엄밀히 정의하자면 다음처럼 변수 \\(x\\)를 거듭제곱 형태인 \\(x_{\\lambda}\\)로 변환하는데, 거듭제곱의 지수 \\(\\lambda\\)에 여러 값을 대입하여 변환한 후 그 중 가장 적합한 \\(\\lambda\\)의 값을 결정한다. 가장 적합한 변환이란 변환된 \\(x_{\\lambda}\\)의 분포가 정규분포에 가까운 변환을 의미한다. \\[ x_{\\lambda} = \\begin{cases} \\frac{x^{\\lambda} - 1}{\\lambda}, &amp; \\lambda \\neq 0 \\\\ \\log(x), &amp; \\lambda = 0 \\end{cases} \\] car 패키지의 powerTransform() 함수는 Box-Cox 변환을 수행하여 가장 적합한 \\(\\lambda\\) 값을 알려준다. car 패키지가 아직 설치되어 있지 않으면 다음 명령이나 RStudio의 [Package] 탭을 사용하여 car 패키지를 설치한다. &gt; install.packages(&quot;car&quot;) Box-Cox 변환에서 어떤 \\(\\lambda\\) 값이 최적인지 파악하려면 다음 문법처럼 powerTransform() 함수에 Box-Cox 변환을 테스트할 수치형변수를 전달한 후 그 결과를 뒤에서 사용하기 위해 R 변수에 할당을 한다. 결과_저장_변수 &lt;- car::powerTransform(데이터$수치형변수) # 결과를 변수에 저장 결과_저장_변수 # 결과 출력 다음은 diamonds의 price 열에 대하여 Box-Cox 변환에서 최적 \\(\\lambda\\)를 탐색한 결과이다. &gt; bc &lt;- car::powerTransform(diamonds$price) &gt; bc Estimated transformation parameter diamonds$price -0.06699008 최적의 \\(\\lambda\\) 값으로 -0.0669901이 추정되었다. 그런데 일반적으로 제시된 추정 값으로 변환을 하기 앞서 변환을 하지 않는 것(\\(\\lambda = 1\\))과 로그 변환(\\(\\lambda = 0\\))하는 것에 비해 제시된 변환이 통계적으로 확실히 유의미한 변환인지 검정해 볼 필요가 있다. 왜냐하면 원래 변수나 로그 변환한 변수는 그 의미를 파악하기 쉽지만 원래 변수를 -0.0669901 제곱한 변수의 의미가 무엇인지 해석하기 어렵기 때문이다. 그러므로 변환이 확실하게 유의미하게 좋다고 판단되지 않으면 변환을 하지 않거나 로그 변환 등의 자주 사용되는 변환을 수행하는 것이 좋다. 제시된 \\(\\lambda\\) 값으로 변환하는 것이 유의미한지 정보를 얻으려면 Box-Cox 변환 결과를 summary() 함수에 전달을 하여 상세 변환 결과를 출력한다. &gt; summary(bc) bcPower Transformation to Normality Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd diamonds$price -0.067 -0.07 -0.0761 -0.0579 Likelihood ratio test that transformation parameter is equal to 0 (log transformation) LRT df pval LR test, lambda = (0) 210.8779 1 &lt; 2.22e-16 Likelihood ratio test that no transformation is needed LRT df pval LR test, lambda = (1) 53082.28 1 &lt; 2.22e-16 Likelihood ratio test로 시작하는 두 문단이 로그 변환(\\(\\lambda = 0\\))과 무변환(\\(\\lambda = 1\\))보다 제시된 변환이 통계적으로 유의미한지 최우도비 검정을 한 결과이다. 이 결과에서 우리가 살펴볼 값은 pval로 표시된 검정통계량의 p-값이다. p-값이 작게 나올수록 제시된 변환이 통계적으로 유의미한 변환이라 할 수 있다. 이 예에서는 모두 매우 작은 값이 나왔으므로 제시된 값으로 변환하는 것이 통계적으로 유의미하다고 할 수 있다. 제시된 \\(\\lambda\\) 값에 따라 원 수치형 변수를 Box-Cox 변환을 하여 원래의 데이터에 변환된 열을 추가하려면 다음처럼 car 패키지의 bcPower() 함수를 사용하는 다음 문법을 이용한다. 데이터$추가할_열_이름 &lt;- car::bcPower(데이터$수치형_변수, coef(powerTransfrom_결과_저장_변수)) 다음은 diamonds의 price 열에 대하여 앞에서 찾은 최적 \\(\\lambda\\) 값으로 변환을 수행한 후, 변환된 변수에 대하여 히스토그램과 통계 요약을 수행한 결과이다. &gt; diamonds$price_bc &lt;- car::bcPower(diamonds$price, coef(bc)) &gt; ggplot(diamonds, aes(x = price_bc)) + geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. &gt; psych::describe(diamonds$price_bc) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 53940 6.05 0.6 6.07 6.04 0.77 4.8 7.21 2.41 0.03 -1.13 0 마찬가지 방법으로 diamonds 데이터의 carat 열에 대해 변환을 수행해 보자. &gt; bc &lt;- car::powerTransform(diamonds$carat) &gt; summary(bc) bcPower Transformation to Normality Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd diamonds$carat -0.0949 -0.09 -0.1105 -0.0793 Likelihood ratio test that transformation parameter is equal to 0 (log transformation) LRT df pval LR test, lambda = (0) 143.377 1 &lt; 2.22e-16 Likelihood ratio test that no transformation is needed LRT df pval LR test, lambda = (1) 20088.35 1 &lt; 2.22e-16 &gt; diamonds$carat_bc &lt;- car::bcPower(diamonds$carat, coef(bc)) &gt; ggplot(diamonds, aes(x = carat_bc)) + geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. &gt; psych::describe(diamonds$carat_bc) vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 53940 -0.42 0.61 -0.36 -0.43 0.76 -1.74 1.49 3.23 0.02 -1.11 0 변환 후 두 변수 모두 어느 정도 대칭적인 분포가 되었다. 그런데 변환된 후의 다이아몬드 중량과 가격의 분포 그래프를 보면 봉우리의 세부적인 모양을 다르지만 가장 큰 두 봉우리의 양상이 유사한 측면이 있다. 그러므로 이 두 변수에 상관성이 있는지 확인해 볼 필요가 있다. 다이아몬드 중량과 가격에 상관성이 있는지를 분석하기 위해서는 두 수치형 변수의 상관성에 대한 기술통계 분석 방법이 필요하다. 8.2 둘 이상의 수치형 변수의 상관성 분석 다변량 수치 데이터가 있을 때 각 변수의 분포를 파악 한 후 다음로 파악해야 할 사항은 각 변수 간의 상관관계를 파악하는 것이다. 예를 들어 course 데이터에서는 중간고사 점수와 기말고사 점수의 상관성이 있는지, 최종평가 점수와 숙제 점수는 연관성이 있는지, 또는 diamonds 데이터에서는 다이아몬드 중량과 가격은 연관성이 있는지를 파악해야 한다. 8.2.1 상관계수 두 변수 데이터에 대한 (선형적) 상관관계를 수치적으로 측정하는 대표적 통계량이 Pearson 상관계수(correlation coefficient)이다. 다음과 같이 \\(n\\)개의 쌍으로 이변량 데이터 \\((x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\)가 측정되었다면 두 변수의 Pearson 상관계수 \\(r_{xy}\\)는 다음과 같이 정의된다. \\[ r_{xy} = \\frac{s_{xy}}{s_x s_y} = \\frac{ \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x}) (y_i - \\bar{y}) }{ \\sqrt{ \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 } \\sqrt{ \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{y})^2 } } \\] Pearson 상관계수는 두 변수 간의 선형 상관성의 정도를 나타내는 통계량으로 -1부터 1 사이의 값을 가진다. 두 변수의 선형 상관성이 없으면 0에 가까운 값이 된다. 1에 가까울 수록 양의 상관성이 있다고 한다. -1에 가까울수록 음의 상관성을 가진다. 그런데 Pearson 상관계수는 두 변수 간의 선형 상관성에 대한 통계량이기 때문에 비선형적인 관계는 잘 포착하지는 못한다. Figure 8.2는 두 변수 간의 상관계수와 산점도를 보여준다. 그래프의 두 번째 행은 두 변수의 관계를 나타내는 선의 기울기와 상관계수의 값은 기울기가 양인지, 음인지, 0인지를 제외하고는 관계가 없음을 보여준다. 아울러 그래프의 마지막 행처럼 비선형적 관계가 있지만 선형적 관계가 없으면 0에 가까운 상관계수 값이 나오는 것을 확인할 수 있다. Figure 8.2: 피어슨 상관계수 (출처: 위키피디아) 그럼 Pearson 상관계수의 값이 어느 정도의 값이 나와야 두 수치형 변수가 상관성이 있다고 보는가? 이 질문에 대한 답은 문제 상황에 따라 다르다. 물리적 현상과 관련된 자연과학이나 공학 분야의 실험 데이터처럼 측정의 정확도가 높은 경우에는 상관계수의 절대값이 0.9 이상이어야 두 변수의 상관관계가 높다고 볼 수 있다. 반면 사람의 심리나 행동과 관련된 사회과학 분야에서는 측정의 정확도가 물리적 현상만큼 높지 않으며 요인도 매우 복잡하게 상호작용하는 경우에는 상관계수의 절대값이 0.3 이상이면 높은 상관 관계가 있다고 보기도 한다. 사람의 심리나 행동을 연구하는 심리학에서 발전한 Cohen의 어림짐작 규칙은 상관계수의 절대값에 대해 다음을 제시한다. 상관계수의 절대값이 0.1 정도이면 상관성이 작거나 약하다고 본다. 상관계수의 절대값이 0.3 정도이면 상관성이 중간 정도라고 본다. 상관계수의 절대값이 0.5 정도이면 상관성이 크고 강하다고 본다. Cohen은 상관성이 큰 경우 일반적인 관찰자도 두 변수의 상관성을 알아채게 된다고 본다. 그러나 이러한 기준은 사람의 심리와 행동을 연구하는 분야나 유사한 분야에 적용하기는 적절하지만 모든 분야에 일률적으로 적용될 수 없다는 점에 주의하여야 한다. R의 기본 패키지의 cor() 함수는 두 변수의 상관성을 구해 준다. cor(데이터$수치형변수1, 데이터$수치형변수2) # 두 수치형 변수의 상관계수 계산 cor(데이터[수치형_변수_인덱스_벡터]) # 선택된 수치형 변수의 모든 조합에 대해 계산 다음은 중간고사와 기말고사의 Pearson 상관계수를 구한 예이다. 중간고사와 기말고사에는 매우 강한 선형 상관성이 있다. &gt; cor(course$mid, course$final) [1] NA &gt; cor(course$mid, course$final, use = &quot;complete.obs&quot;) [1] 0.8348258 중간과 기말고사에 결측치가 있기 때문에 use 인수로 결측치를 어떻게 처리할지를 지정하지 않으면 결과가 NA로 나온다. use는 다음과 같은 값을 가질 수 있다. “everything”: 모든 데이터를 사용하고 상관계수를 계산할 두 변수 중에 NA가 있으면 결과도 NA가 나온다. use 인수의 기본 설정은 “everything”이다. “all.obs”: 상관계수를 계산할 변수 중에 NA가 있으면 오류를 발생시킨다. “complete.obs”: 변수 중에 하나라도 NA가 있으면 그 행은 삭제하고 완전한 행만 가지고 상관계수를 계산한다. 만약 완전한 행이 하나도 없으면 오류를 발생시킨다. “na.or.complete”: “complete.obs”와 같은데, 완전한 행이 하나도 없으면 NA를 반환한다. “pairwise.complete.obs”: 상관계수를 계산할 두 변수에서 NA가 있으면 그 관측은 제외하고 상관계수를 계산한다. use 인수는 cor() 함수가 데이터 프레임 전체에 작용될 때 그 의미가 잘 들어난다. cor() 함수가 수치형 변수로만 이루어진 데이터 프레임에 적용되면 모든 두 변수 쌍에 대한 상관계수를 계산해 준다. &gt; cor(course[5:8]) mid final hw score mid 1 NA NA NA final NA 1 NA NA hw NA NA 1.000000 0.697733 score NA NA 0.697733 1.000000 use 인수의 기본 값이 “everything”이므로 결측치가 있는 중간고사와 기말고사가 상관계수 계산에 사용된 경우에는 NA가 결과로 나왔다. “complete.obs”을 use 인수에 사용하면 중간, 기말, 숙제, 총점 중 하나라도 결측치가 있는 학생과 관련된 데이터 행은 없애고 상관계수를 구한다. 그러기 때문에 모든 변수 조합에 대하여 상관계수가 잘 계산되어 나왔다. 중간과 기말고사는 총점과 높은 상관성이 있지만 숙제는 총점과 약한 상관성만 있다. &gt; cor(course[5:8], use = &quot;complete.obs&quot;) mid final hw score mid 1.0000000 0.8348258 0.3128638 0.9571183 final 0.8348258 1.0000000 0.2843525 0.9472175 hw 0.3128638 0.2843525 1.0000000 0.4078304 score 0.9571183 0.9472175 0.4078304 1.0000000 “complete.obs”은 결측치가 있는 행은 모두 삭제하므로 일관성을 가지고 상관계수를 계산할 수 있는 장점이 있지만, 결측치가 흩뿌려져 있는 경우 상관성 계산에 사용되지 못하는 데이터의 양이 많아져 데이터 손실이 클 수 있다. 상관계수는 결국 두 변수의 관계이므로, 이러한 경우에는 상관계수 계산에 사용되는 변수에 결측치가 없으면 다른 변수에 결측치가 있어도 사용하도록 하는 게 좋다. 이러한 방식으로 상관계수를 계산하려면 use 인수를 “pairwise.complete.obs”으로 설정한다. 결측치가 없는 hw과 score 변수의 상관계수 계산에 mid와 final에 결측치가 있는 행도 사용하였으므로 앞의 결과와는 조금 다른 결과를 볼 수 있다. &gt; cor(course[5:8], use = &quot;pairwise.complete.obs&quot;) mid final hw score mid 1.0000000 0.8348258 0.3128638 0.9571183 final 0.8348258 1.0000000 0.2843525 0.9472175 hw 0.3128638 0.2843525 1.0000000 0.6977330 score 0.9571183 0.9472175 0.6977330 1.0000000 Pearson 상관계수는 평균, 분산과 마찬가지로, 산술 계산 상의 좋은 수학적 성질을 가지고 있지만 이상치에 의해 영향을 크게 받는다. 이러한 문제점을 개선한 상관계수가 Spearman 상관계수이다. Spearman 상관계수는 수치 값이 아니라 각 변수의 관측치의 등수(rank)를 사용하여 상관계수를 계산한다. 따라서 소수의 이상치가 있어도 등수에 큰 변화가 없으므로 이상치의 영향을 덜 받는다. Spearman 상관계수를 구하려면, cor() 함수의 method 인수를 “spearman”으로 설정하면 된다. course 데이터는 Pearson과 Spearman 상관계수의 차이가 크지 않다. &gt; cor(course[5:8], use = &quot;pairwise.complete.obs&quot;, method = &quot;spearman&quot;) mid final hw score mid 1.0000000 0.8368262 0.3814754 0.9492544 final 0.8368262 1.0000000 0.2667068 0.9386216 hw 0.3814754 0.2667068 1.0000000 0.4647101 score 0.9492544 0.9386216 0.4647101 1.0000000 Kendall 상관계수는 관측치 쌍 \\((x_i, y_i), (x_j, y_j)\\)에 대하여 \\(x\\)와 \\(y\\)가 같은 방향으로 움직이면 1, 반대로 움직이면 -1, 한 변수라도 같은 값이면 0으로 하여 관측치 쌍의 상관계수를 구한 후, 모든 관측치 쌍의 상관계수를 더하여 구한다. 관측치 쌍들 사이에 경향이 동일하게 움직이는가만 계산하기 때문에 이상치에 크게 영향을 받지 않는다. Kendall 상관계수를 구하려면, cor() 함수의 method 인수를 “kendall”로 설정하면 된다. course 데이터는 Kendall 상관계수가 Pearson과 Spearman 상관계수보다는 적게 나오는 것을 볼 수 있다. &gt; cor(course[5:8], use = &quot;pairwise.complete.obs&quot;, method = &quot;kendall&quot;) mid final hw score mid 1.0000000 0.6494909 0.2758297 0.8160261 final 0.6494909 1.0000000 0.1835906 0.8051283 hw 0.2758297 0.1835906 1.0000000 0.3309720 score 0.8160261 0.8051283 0.3309720 1.0000000 앞서서 중간고사와 기말고사의 선형 상관성이 높은 것으로 나타났는데 이러한 상관성이 통계적으로 유의미한지를 파악하려면 상관성에 대한 가설검정을 수행해야 한다. cor.test() 함수를 이용하면 상관계수에 대한 가설검정을 수행할 수 있다. cor.test() 함수의 문법은 다음 두 가지가 있다. cor.test(수치_벡터1, 수치_벡터2, method = &quot;상관계수_종류&quot;) cor.test(~ 수치열1 + 수치열2, data = 데이터, method = &quot;상관계수_종류&quot;) 중간과 기말고사의 Pearson, Spearman, Kendall 상관계수 모두 매우 작은 p-값을 가지므로 통계적으로 유의미하다는 것을 알 수 있다. 단, Spearman과 Kendall 상관계수는 수치 값에 동률이 있으면 정확한 p-값을 구할 수 없어서 경고가 출력되었다. &gt; cor.test(course$mid, course$final, method = &quot;pearson&quot;) Pearson&#39;s product-moment correlation data: course$mid and course$final t = 9.8277, df = 42, p-value = 1.88e-12 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: 0.7152041 0.9069297 sample estimates: cor 0.8348258 &gt; cor.test(~ mid + final, data = course, method = &quot;spearman&quot;) Warning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): tie때문에 정확한 p값을 계산할 수 없습니다 Spearman&#39;s rank correlation rho data: mid and final S = 2315.4, p-value = 1.486e-12 alternative hypothesis: true rho is not equal to 0 sample estimates: rho 0.8368262 &gt; cor.test(~ mid + final, data = course, method = &quot;kendall&quot;) Warning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): tie때문에 정확한 p값을 계산할 수 없습니다 Kendall&#39;s rank correlation tau data: mid and final z = 6.1296, p-value = 8.809e-10 alternative hypothesis: true tau is not equal to 0 sample estimates: tau 0.6494909 데이터에 수치형 변수가 매우 많으면 cor() 함수로 계산된 수치에서 상관성이 높은 변수 쌍이 무엇인지 한 눈에 파악하기가 쉽지 않다. 이러한 경우에는 corrplot 패키지의 corrplot.mixed() 함수를 사용하면 많은 수치형 변수들 간의 상관성을 파악하기 좋다. corrplot 패키지의 corrplot.mixed() 함수를 사용하려면 먼저 corrplot 패키지를 설치해야 한다. &gt; install.packages(&quot;corrplot&quot;) corrplot.mixed() 함수의 첫번째 인수는 cor() 함수의 결과를 입력하고, upper 인수는 그래프의 오른쪽 위 삼각형 부분에 두 변수의 상관성을 보여주는 도형을 무엇으로 할 것인가를 지정하는데 \"ellipse\"로 입력하면 두 변수의 양의 상관성이 높으면 우상향하는 가는 타원을, 음의 상관성이 높으면 우하향하는 가는 타원으로 상관성을 표시하고, 상관성이 없으면 원에 가까운 모양을 표시한다. 그래프의 대각선 영역은 변수 이름을 나타내고, 왼쪽 아래 삼각형 부분에는 두 변수의 상관계수를 표시하는데, 상관계수의 값이 크면 짙은 색으로 상관계수를 표시한다. 그리고 양의 상관성이 높으면 짙은 파란색으로, 음의 상관성이 높으면 짙은 붉은 색으로 상관계수와 타원을 표현한다. &gt; corrplot::corrplot.mixed(cor(diamonds[c(1, 5:10)]), upper = &quot;ellipse&quot;) 그런데 상관계수는 수치형 변수의 상관성을 측정하는데 다음과 같은 한계점을 갖는다. 상관계수는 두 수치변수의 선형상관성만 측정하지 이차식의 포물선과 같은 비선형적 상관성에 대한 측정은 불가능하다. 그러므로 선형상관성 이외의 상관성이 있는지를 파악하려면 그래프를 그려보거나, 두 변수를 변환하여 상관성을 확인하여야 한다. 또는 최근에 정보이론에 기반을 둔 maximal information coefficient (MIC) (Reshef et al. 2011) 등을 사용하여 비선형적 상관성을 탐색할 수도 있다. 상관계수는 두 변수의 상관성만 탐색하므로 세 개 이상의 변수가 연관된 상관성을 파악하기 어렵다. 세 개 이상의 변수들의 상관성을 탐색하려면 회귀모형 등을 이용하여 변수들의 관계를 탐색하여야 한다. 8.2.2 산점도 상관계수가 두 수치 변수의 상관성을 통계량으로 살펴본 것이라면, 산점도(scatter plot)는 두 수치형 변수의 상관성을 시각적으로 살펴보는 방법이다. 그러므로 두 변수의 상관성을 선형 상관성 뿐 아니라 더 다양한 측면에서 살펴볼 수 있다. ggplot2의 geom_point() 함수를 사용하면 다음의 문법으로 두 변수의 산점도를 그릴 수 있다. ggplot(데이터, aes(x = 수치변수1, y = 수치변수2)) + geom_point() 다음 예는 앞서 상관계수를 구한 중간고사와 기말고사 변수에 대해 산점도를 그린 예이다. 전반적으로 살펴보면 중간고사가 높은 학생이 기말고사 점수도 높은 경향을 보인다. &gt; ggplot(course, aes(x = mid, y = final)) + geom_point() Warning: Removed 1 rows containing missing values (`geom_point()`). 만약 여러 수치형 변수에 대해 산점도를 빠르게 그리고 싶으면 다음처럼 수치형 변수로만 이루어진 데이터 프레임을 만들어 plot() 함수에 전달하면 된다. &gt; plot(course[5:8]) 산점도에서 숙제 점수는 대부분 비슷하여 최종평균 점수에 별 영향을 미치지 못함을 파악할 수 있다. 중간과 기말, 중간과 최종, 기말과 최종은 어느 정도 강한 상관관계를 가지고 있음을 확인할 수 있다. 8.2.3 추세선 그리기 두 수치형 변수에 비선형적 상관성이 있으면 산점도만 보고 이를 파악하기 어려운 경우가 많다. 이러한 경우에는 geom_smooth() 함수를 사용하면 두 변수의 변화 추세를 보여주는 선을 그려보면 비선형적 상관성 파악에 도움이 된다. 회색으로 표시된 부분은 추세선의 95% 신뢰구간이며 se=FALSE로 인수를 설정하면 사라진다. &gt; ggplot(course, aes(x = mid, y = final)) + geom_point() + geom_smooth() `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; Warning: Removed 1 rows containing non-finite values (`stat_smooth()`). Warning: Removed 1 rows containing missing values (`geom_point()`). 추세선은 데이터가 적으면 지역 다항 회귀선(loess)을 이용하여, 데이터가 많으면 일반화 가법 모형(gam)을 사용하여 추정한다. method 인수를 사용하면 추세선을 그릴 때 사용할 적합 모형을 지정할 수 있다. method = \"lm\"으로 설정하면 선형회귀 모형을 사용하여 추세선을 그린다. &gt; ggplot(course, aes(x = mid, y = final)) + + geom_point() + geom_smooth(method = &quot;lm&quot;) `geom_smooth()` using formula = &#39;y ~ x&#39; 지역 다항 회귀선으로 추세션을 그릴 때 span 인수를 이용하면 얼마나 지역적으로 추세선을 적합할지를 조정할 수 있다. span이 1에 가까울수록 전체 데이터를 모두 사용하여 추세선을 적합하므로 매우 부드러운 곡선이 적합되고span이 0에 가까울수록 매우 가까운 소수의 데이터만을 사용하여 추세선을 적합하므로 데이터의 변화에 따라 구불구불한 추세선이 만들어진다. 너무 작은 값을 사용하면 추세선이 데이터에 과적합되어서 추세선이 소수의 데이터에 영향을 많이 받게 된다. &gt; ggplot(course, aes(x = mid, y = final)) + + geom_point() + geom_smooth(span = 1) &gt; ggplot(course, aes(x = mid, y = final)) + + geom_point() + geom_smooth(span = 0.7) &gt; ggplot(course, aes(x = mid, y = final)) + + geom_point() + geom_smooth(span = 0.4) 8.2.4 수치형 변수의 변환 앞서 살펴보았던 다이아몬드의 가격과 중량이 상관성이 있는지를 산점도를 그려 살펴보자. 전체 데이터를 대상으로 산점도를 그릴 수도 있지만, 다이아몬드 데이터는 관측치가 매우 많아서 컴퓨터 성능에 따라 산점도를 만들고 표시하는데 시간이 어느 정도 걸릴 수 있다. 그래서 데이터의 10%만 표본 추출하여 산점도를 그려보자. dplyr 패키지는 이러한 역할을 하는 sample_n()과 sample_frac() 함수를 가지고 있다. 전자는 n 인수에 설정된 숫자만큼 임의로 행을 추출하고, 후자는 size에 설정된 비율만큼 행을 임의 추출한다. dplyr 패키지가 설치되어 있지 않다면 먼저 설치를 해야 한다. &gt; install.packages(&quot;dplyr&quot;) 다음은 diamonds 데이터에서 10%만 표본 추출한 후, 표본 추출한 데이터를 diamonds_sample이라는 변수에 할당하는 예이다. &gt; diamonds_sample &lt;- dplyr::sample_frac(diamonds, size = 0.1) 전반적으로 보았을 때 중량이 커지면 다이아몬드의 가격도 상승하는 경향이 있다. 그러나 소수의 중량이 큰 관측치로 인해 정확한 관계를 파악하기 어렵다. &gt; ggplot(diamonds_sample, aes(x = carat, y = price)) + + geom_point() + geom_smooth() `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; &gt; cor(diamonds_sample$carat, diamonds_sample$price) [1] 0.9226451 두 변수 모두 로그 변환을 하여 산점도를 다시 그려보자. 마지막 몇 데이터를 제외하고는 중량과 가격은 거의 선형에 가까운 관계를 보인다. 이는 로그 변환 후에 상관계수를 구해보면 확실히 알 수 있다. 따라서 다이아몬드의 가격은 중량에 의해 많은 부분을 설명하고 예측할 수 있을 것이라는 것을 예상할 수 있다. &gt; ggplot(diamonds_sample, aes(x = carat, y = price)) + + geom_point() + geom_smooth() + + scale_x_log10() + scale_y_log10() `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; &gt; cor(log10(diamonds_sample$carat), log10(diamonds_sample$price)) [1] 0.9658444 8.2.5 범주형 변수를 조건으로 수치형 변수의 상관성 탐색 앞의 다이아몬드의 중량과 가격 사례는 중량이 가격에 매우 높은 상관성이 있음을 보여준다. 그러나 우리는 다음의 두 가지 추가 질문을 해 볼 필요가 있다. 동일한 중량에도 가격의 차이가 상당히 발생함을 볼 수 있다. 그러면 다이아몬드 중량을 제외하고 남은 가격의 변동성은 어디서 왔을까? 산점도의 선형 추세선에 잘 들어맞지 않는 중량에 비해 가격이 낮은 다이아몬드들은 그 이유가 무엇일까? 이 질문에 대한 답이 혹시 다이아몬드의 가공품질(cut)에 있는 것은 아닌지 한번 살펴보자. 그러려면 중량과 가격의 상관관계가 가공품질에 따라 달라지는지 확인해 보아야 한다. 산점도에서 범주형 변수의 값에 따라 두 수치형 변수의 상관성에 차이가 있는지를 살펴보는 가장 쉬운 방법은 산점도의 점을 범주형 변수의 값에 따라 다른 색상 또는 모양으로 그려보는 것이다. &gt; ggplot(diamonds_sample, aes(x = carat, y = price, color = cut)) + + geom_point() + geom_smooth(se=F) + + scale_x_log10() + scale_y_log10() `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 산점도에 나타나는 너무 많은 데이터가 오히려 변수들의 상관 관계를 확인하기 어렵게 만든다. 그래프에서 점을 제외하고 추세선만 그려보자. 가장 낮은 가공 품질인 Fair와 다른 가공품질의 가격 추이가 조금은 다른 것을 볼 수 있다. 그러나 Good에서 Ideal 등급 사이의 추세선은 신뢰구간이 서로 겹쳐 있어서 가공품질이 나머지 가격 변동성을 설명해주는 부분은 그리 크지 않은 것으로 파악된다. &gt; ggplot(diamonds_sample, aes(x = carat, y = price, color = cut)) + + geom_smooth() + + scale_x_log10() + scale_y_log10() `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 이번에 다이아몬드의 투명도(clarity)에 따라 중량과 가격의 상관성을 확인해 보자. 이번에는 점을 흐리게 하여 추세선의 아래 층에 같이 그렸다. 중량이 같은 경우 투명성이 커질수록 가격의 상단에 데이터와 추세선이 위치하는 것을 볼 수 있다. 그리고 투명도에 따른 가격의 차이가 중량을 제외한 가격의 변동성의 대부분을 설명하는 것으로 보인다. 그리고 하나 더 파악할 수 있는 것은 중량이 1 캐럿이 넘어가면 중량과 가격의 로그 변환의 선형성이 비선형적으로 움직이는 것을 볼 수 있다. &gt; ggplot(diamonds_sample, aes(x = carat, y = price, color = clarity)) + + geom_point(alpha = 0.1) + + geom_smooth() + + scale_x_log10() + scale_y_log10() `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 범주형 변수의 값에 따라 두 수치형 변수의 관계를 살펴보기는 측면으로 나누어 그래프를 그려 볼 수도 있다. 이 경우에 각 범주별로 그래프가 분리되어 그려져 각각의 경향을 파악하기는 쉬우나 서로 비교하는 것은 어렵다. &gt; ggplot(diamonds_sample, aes(x = carat, y = price)) + + geom_point() + geom_smooth() + + scale_x_log10() + scale_y_log10() + + facet_wrap(~ clarity) `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 두 수치형 변수의 관계를 범주형 변수에 따라 어떻게 달라지는지 더 자세히 살펴보려면 회귀분석 모형을 사용해야 한다. 관련된 내용은 회귀 분석과 관련된 강의와 9 장을 참조한다. 8.2.6 수치형 변수를 조건으로 두 수치형 변수의 상관성 분석 그러면 다른 수치형 변수의 값에 따라 수치형 변수의 상관성에 차이가 있는지도 분석할 수 있을까? 일반적으로 3개 이상의 수치 변수의 관계는 다중 회귀 모형과 공분산분석을 이용하여 탐구한다. 이에 대해서는 회귀 분석과 공분산분석을 다룰 때 살펴보도록 한다. 기술통계 방법을 사용하여 이를 살펴보는 방법은 조건이 되는 수치형 변수를 범주형 변수로 변환한 후 앞서 범주형 변수를 조건으로 두 수치형 변수에 대한 상관성 분석을 한 방법을 이용하는 것이다. 예를 들어 다음은 diamonds 데이터의 table 변수를 4분위수로 4 개의 구간으로 나누어 table_cut 열에 저장한 후, 이 열을 기준으로 측면으로 나누어 다이아몬드의 중량과 가격 산점도를 그려 볼 수 있다. &gt; diamonds_sample$table_cut &lt;- + cut(diamonds_sample$table, breaks = quantile(diamonds_sample$table), include.lowest = T) &gt; ggplot(diamonds_sample, aes(x = carat, y = price)) + + geom_point() + geom_smooth() + + scale_x_log10() + scale_y_log10() + + facet_wrap(~ table_cut) `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 8.2.7 ggpairs()를 이용한 수치형 변수를 한 번에 분석하기 GGally 패키지에서 제공하는 ggpairs() 함수를 사용하면 수치형 변수의 확률 밀도 그래프, 수치형 변수 간의 산점도, 수치형 변수 사이의 상관계수와 가설검정 결과를 한 번에 확인할 수 있어 편리하다. 먼저 GGally 패키지를 설치한다. &gt; install.packages(&quot;GGally&quot;) ggpairs() 함수의 첫 번째 인수는 데이터, 두번째 인수에는 그래프를 그릴 열의 위치를 지정한다. &gt; GGally::ggpairs(course, 5:8) 그래프 행렬의 대각선에는 각 변수의 확률 밀도 그래프가 그려진다. 우상단 삼각형에는 두 변수 간의 상관계수와 가설검정 결과를 보여준다. * 유의수준 10%에서 두 변수의 상관성이 의미있다는 것을 나타내며, **와 ***은 각각 유의수준 5%와 1%에서 상관성이 의미있다는 것을 나타낸다. 우하단의 삼각형은 두 변수 간의 산점도를 보여준다. ggpairs() 함수는 수치형 변수뿐 아니라 범주형 변수에 대해서도 그래프를 그려준다. 관심있는 독자는 course 데이터 전체에 대하여 ggpairs() 함수를 적용해 보기 바란다. (두 번째 인수를 생략하면 전체 열에 대하여 ggpairs() 함수를 적용할 수 있다.) References "],["ch-categorical-numeric.html", "Chapter 9 범주형 변수와 수치형 변수의 관계 분석 9.1 범주별로 수치형 변수에 대해 통계 요약하기 9.2 범주별 수치 변수의 분포 그래프", " Chapter 9 범주형 변수와 수치형 변수의 관계 분석 통계 데이터 분석을 할 때 course 데이터처럼 범주형 변수와 수치 변수가 같이 있는 경우가 많다. 이러한 경우에 범주형 변수의 값에 따라 수치 변수의 분포가 다른지가 관심 사항일 수 있다. 예를 들어 성별에 따라 총점의 분포에 차이가 있는지, 학년별에 따라 총점의 분포에 차이가 있는지 등이 course 데이터에서는 분석의 대상이 될 수 있다. 9.1 범주별로 수치형 변수에 대해 통계 요약하기 9.1.1 한 범주형 변수를 조건으로 수치형 변수를 통계 요약하기 tapply()와 aggregate()의 기본 문법 범주형 변수와 수치형 변수의 관계를 파악하는 방법 중의 하나가 범주형 변수의 범주별로 수치 변수의 통계량을 비교해 보는 것이다. 이를 수행하는 R 함수의 문법은 다음과 같다. tapply(데이터$수치형변수, 데이터$범주형변수, 통계함수) aggregate(수치형변수 ~ 범주형변수, data = 데이터, 통계함수) 다음은 tapply()와 aggregate() 함수를 이용하여 course 데이터에서 성별 총점의 평균을 비교한 결과이다. tapply()는 테이블 형식으로 결과를 주는데 반해, aggregate()는 데이터프레임 형식으로 결과를 반환한다. &gt; library(bizstatp) &gt; tapply(course$score, course$gender, mean) F M 71.97611 71.11741 &gt; aggregate(score ~ gender, data = course, mean) gender score 1 F 71.97611 2 M 71.11741 마찬가지 방법으로 성별로 총점의 중위수, 표준편차, 중앙값 절대편차를 구해보자. &gt; aggregate(score ~ gender, data = course, median) gender score 1 F 72.665 2 M 72.600 &gt; aggregate(score ~ gender, data = course, sd) gender score 1 F 10.47439 2 M 17.35242 &gt; aggregate(score ~ gender, data = course, mad) gender score 1 F 14.24779 2 M 12.60210 사용자 함수로 여러 통계량으로 한 번에 요약하기 여러 개의 통계량을 범주별로 구할 때는 다음처럼 사용자 함수를 정의하여 통계량이 같이 출력되도록 하는 것이 좋다. tapply(데이터$수치형변수, 데이터$범주형변수, function(x) c(이름1 = 통계함수1(x), 이름2 = 통계함수2(x), ....) ) aggregate(수치형변수 ~ 범주형변수, function(x) c(이름1 = 통계함수1(x), 이름2 = 통계함수2(x), ....) ) 다음은 aggregate() 함수를 이용하여 성별로 사용자 정의 함수를 사용하여 총점 데이터 수, 평균, 중위수, 표준편자, 중앙값 절대편차를 한 번에 보여주는 예이다. &gt; aggregate(score ~ gender, data = course, function(x) + c(n = length(x), mean = mean(x), median = median(x), + sd = sd(x), mad = mad(x))) gender score.n score.mean score.median score.sd score.mad 1 F 18.00000 71.97611 72.66500 10.47439 14.24779 2 M 27.00000 71.11741 72.60000 17.35242 12.60210 여학생과 남학생의 평균과 중위수의 차이는 거의 없었지만 남학생의 표준편차가 여학생에 비해 크게 나타난 것을 볼 수 있다. 이는 남학생 성적의 변동성이 컸다는 것을 의미한다. 그러나 예외적인 값에 영향을 잘 받지 않는 중앙값 절대 편차를 보면 오히려 여학생의 점수가 좀 더 펴져 있는 것으로 나타난다. 혹시 시험을 안 본 학생에 의해 남학생의 표준편차가 커진 것은 아닌지를 파악하기 위해 이 학생을 제외하고 성별 비교를 다시해 보자. 예외적인 값에 의해 영향을 받았던 남학생의 평균과 표준편차의 값이 크게 바뀐 것을 확인할 수 있다. &gt; course_omitted &lt;- na.omit(course) &gt; aggregate(score ~ gender, data = course_omitted, function(x) + c(n = length(x), mean = mean(x), median = median(x), sd = sd(x), mad = mad(x))) gender score.n score.mean score.median score.sd score.mad 1 F 18.00000 71.97611 72.66500 10.47439 14.24779 2 M 26.00000 73.46808 72.98500 12.56943 12.66140 수치형 변수의 통계량의 범주별 차이에 대한 가설검정 이상치를 제외하고 살펴보니 남학생의 표준 편차가 감소하였지만 여학생보다 조금 크고 평균도 여학생보다 크게 나왔다. 성별에 따른 평균의 차이는 크지 않았다. 이러한 평균과 표준편차(분산)의 차이가 통계적으로 유의미한지를 가설검정해 볼 수 있다. 가설검정에서 배울 예정인 t.test()와 var.test() 함수를 사용하면 두 집단의 평균과 분산의 차이에 대한 가설검정을 할 수 있다. 가설 검정 결과 p-값이 크게 나와서 남자와 여자의 평균과 분산의 차이는 통계적으로 유의미하지 않음을 볼 수 있다. &gt; t.test(score ~ gender, data = course_omitted) Welch Two Sample t-test data: score by gender t = -0.42764, df = 40.453, p-value = 0.6712 alternative hypothesis: true difference in means between group F and group M is not equal to 0 95 percent confidence interval: -8.540634 5.556702 sample estimates: mean in group F mean in group M 71.97611 73.46808 &gt; var.test(score ~ gender,data = course_omitted) F test to compare two variances data: score by gender F = 0.69443, num df = 17, denom df = 25, p-value = 0.4409 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.2942656 1.7696899 sample estimates: ratio of variances 0.6944266 학년별 총점도 같은 방식으로 분석해 보자. 학년이 올라갈수록 평균과 중위수가 증가하는 경향을 보인다. 표준편차와 중앙값 절대 편차는 3학년이 가장 컸고, 2학년, 4학년 순으로 감소하였다. &gt; course_omitted &lt;- na.omit(course) &gt; aggregate(score ~ year, data = course_omitted, function(x) + c(n = length(x), mean = mean(x), median = median(x), + sd = sd(x), mad = mad(x))) year score.n score.mean score.median score.sd score.mad 1 2 32.000000 71.447812 70.865000 11.284044 13.899375 2 3 9.000000 75.406667 73.370000 13.738011 17.598462 3 4 3.000000 80.250000 80.000000 6.908393 9.681378 그러나 4학년 학생의 관측수가 3으로 이러한 차이는 우연하게 발생한 것일 수 있다. 세 집단 이상의 평균의 차이에 대해 가설검정을 하려면 분산분석을 해야 한다. 분산분석은 aov() 함수를 사용한다. 분산분석에 대한 자세한 설명은 가설검정 부분을 참조하기 바란다. 분산분석을 한 결과 학년에 대해 총점이 통계적으로 유의미한 차이를 보이지 않았다. &gt; aov_result &lt;- aov(score ~ year, data = course_omitted) &gt; anova(aov_result) Analysis of Variance Table Response: score Df Sum Sq Mean Sq F value Pr(&gt;F) year 2 286.0 143.01 1.056 0.3571 Residuals 41 5552.5 135.43 분반에 따른 성적 차이가 있는지도 살펴보자. 2분반이 1분반 보다 평균과 중위수가 모두 높았지만 통계적으로 유의미한 차이까지는 아니었다. &gt; aggregate(score ~ class, data = course_omitted, function(x) + c(n = length(x), mean = mean(x), median = median(x), + sd = sd(x), mad = mad(x))) class score.n score.mean score.median score.sd score.mad 1 1 22.00000 69.93409 68.05000 11.55647 11.72737 2 2 22.00000 75.78136 74.98500 11.25011 11.96458 &gt; t.test(score ~ class, data = course_omitted) Welch Two Sample t-test data: score by class t = -1.7005, df = 41.97, p-value = 0.09643 alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0 95 percent confidence interval: -12.786661 1.092115 sample estimates: mean in group 1 mean in group 2 69.93409 75.78136 9.1.2 여러 범주형 변수를 조건으로 수치형 변수를 통계 요약하기 만약 분반에 따라 성별이 총점에 미치는 차이가 있었는지를 확인해 보려면 어떻게 해야 할까? 먼저 성별-분반별로 총점과 관련된 통계량을 확인해 보아야 한다. 이렇게 여러 범주형 변수에 대해 수치형 변수를 통계 요약하려면 다음과 같은 문법을 사용한다. tapply(데이터$수치형변수, list(데이터$범주형변수1, 데이터$범주형변수), 통계함수) aggregate(수치형변수 ~ 범주형변수1 + 범주형변수2 + ..., data = 데이터, 통계함수) 다음은 성별-분반별로 총점에 대하여 평균을 구한 예이다. tapply() 함수는 범주형 변수별로 행과 열로 나누어 결과를 주는 반면, aggregate() 함수는 각 성별-분반 조합에 대한 결과를 한 행으로 결과를 주는 것을 볼 수 있다. &gt; tapply(course_omitted$score, + list(course_omitted$gender, course_omitted$class), mean) 1 2 F 68.08100 76.84500 M 71.47833 75.17357 &gt; aggregate(score ~ gender + class, data = course_omitted, mean) gender class score 1 F 1 68.08100 2 M 1 71.47833 3 F 2 76.84500 4 M 2 75.17357 한 범주형 변수를 기준으로 요약할 때와 마찬가지로 사용자 함수를 사용하여 여러 통계량을 한 번에 출력할 수 있다. 여학생의 분반별 점수 차이가 남학생보다 더 큰 것을 볼 수 있다. 그러나 이러한 차이가 통계적으로 유의미 하지는 않은 것으로 보인다. &gt; aggregate(score ~ gender + class, data = course_omitted, function(x) + c(n = length(x), mean = mean(x), median = median(x), + sd = sd(x), mad = mad(x))) gender class score.n score.mean score.median score.sd score.mad 1 F 1 10.000000 68.081000 64.390000 10.624309 7.568673 2 M 1 12.000000 71.478333 71.595000 12.525445 11.564280 3 F 2 8.000000 76.845000 77.440000 8.517770 4.744320 4 M 2 14.000000 75.173571 74.230000 12.817588 16.886814 &gt; aov_result &lt;- aov(score ~ gender * class, data = course_omitted) &gt; anova(aov_result) Analysis of Variance Table Response: score Df Sum Sq Mean Sq F value Pr(&gt;F) gender 1 23.7 23.68 0.1759 0.6772 class 1 361.9 361.94 2.6884 0.1089 gender:class 1 67.7 67.65 0.5025 0.4825 Residuals 40 5385.3 134.63 9.2 범주별 수치 변수의 분포 그래프 지금까지 범주별로 수치 변수를 기술통계량으로 용약하는 방법을 설명하였다. 그러나 많은 경우에 범주별로 수치 변수의 분포를 그래프로 표현하는 것이 범주형 변수가 수치 변수에 주는 영향을 파악하기에 더 수월하다. 9.2.1 상자 그래프 한 범주형 변수에 대해 수치형 변수의 상자 그래프 그리기 범주별로 수치형 변수의 분포를 확인하는 가장 대표적인 방법은 상자 그래프를 그리는 것이다. ggplot2의 geom_boxplot() 함수는 수치형 변수에 대한 상자 그래프를 그려주는데, 범주형 변수의 범주 별로 수치형 변수의 상자 그래프를 그릴려면 다음 문법을 사용한다. ggplot(데이터, aes(x = 범주형변수, y = 수치형변수)) + geom_boxplot() 다음은 course 데이터의 총점 변수를 성별로 나누어 상자 그래프를 그린 예이다. &gt; library(ggplot2) &gt; ggplot(course, aes(x = gender, y = score)) + geom_boxplot() 8.1.2.4 절의 그림 8.1에서 설명한 바와 같이 상자 그래프는 다음과 같은 정보를 나타낸다. 상자의 상단이 3분위수, 하단이 1분위수, 상자의 가운데 있는 줄이 중위수를 나타낸다. 따라서 상자의 길이가 IQR을 나타낸다. 상자의 위와 아래로 난 수염은 상자에서 \\(1.5 \\times IQR\\) 만큼 떨어지지 않은 관측치 중에서 최대값과 최소값을 나타낸다. 상자에서 \\(1.5 \\times IQR\\)보다 더 떨어진 관측값은 수치 변수가 정규분포를 따른다고 가정할 때 매우 예외적인 값이다. 이러한 값은 별도의 점으로 나타낸다. 중위수의 신뢰구간을 표시하기 상자 그래프는 사분위수를 나타내 주므로 분포가 대칭인지 아닌지도 확인할 수 있다. 분포가 대칭이면 상자의 중심선으로부터 위와 아래가 대칭적인 길이로 표현된다. geom_boxplot() 함수 notch = TRUE로 설정하면 중위수의 95% 신뢰구간을 표시한다. 분반별 총점 분포를 상자그림으로 비교해 보면 분포가 대체로 대칭적이고 중위수의 신뢰구간이 겹쳐 있음을 볼 수 있다. &gt; ggplot(course, aes(x = class, y = score)) + geom_boxplot(notch = TRUE) 두 범주형 변수에 대해 수치형 변수의 상자 그래프 그리기 두 범주형 변수의 범주 조합에 대해 수치형 변수의 분포를 그리고 싶으면 다음처럼 상자의 채우기 속성(fill)을 또 다른 범주형 변수로 지정을 하면 된다. ggplot(데이터, aes(x = 범주형변수1, y = 수치형변수, fill = 범주형변수2)) + geom_boxplot() 그러면 fill로 매핑한 범주형 변수 값에 따라 다른 채우기 색상으로 상자 그래프가 나란히 표시된다. 다음은 course 데이터의 총점 변수의 상자 그래프를 분반-성별 범주 조합에 따라 상자 그래프를 그린 예이다. 분반별로 성별 총점의 중위수는 차이를 보이지만 신뢰구간의 많은 부분이 겹쳐져 있어서 통계적으로 유의미한 차이로 보이지 않는다. &gt; ggplot(course, aes(x = class, y = score, fill=gender)) + + geom_boxplot(notch = TRUE) Notch went outside hinges ℹ Do you want `notch = FALSE`? Notch went outside hinges ℹ Do you want `notch = FALSE`? 두 변수의 관계를 살펴볼 때의 주의할 점 - 혼동 효과 다음은 다이아몬드의 투명도에 따라 가격의 분포가 어떻게 달라지는지를 상자 그래프로 그린 예이다. 주목할 점은 다이아몬드의 투명도가 올라갈수록 다이몬드 가격이 오히려 내려가는 것을 볼 수 있다. &gt; ggplot(diamonds, aes(x = clarity, y = price)) + geom_boxplot(notch = TRUE) 위의 상자 그래프가 보여주는 데이터 경향은 다이아몬드 투명도가 좋아질수록 가격이 오를거라는 직관에 부합되지 않는다. 그렇다면 이러한 경향이 나타나는 이유는 무엇일까? 두 변수만으로 상관성을 분석할 때 주의해야 할 것은 두 변수를 제외한 제 삼의 변수에 의한 혼동 효과(confounding effects)이다. 혼동 효과란 두 변수는 사실 상관성이 없는데, 다른 제 삼의 변수의 영향으로 그래프나 통계량에 마치 두 변수에 상관성이 있는 것처럼 나타나는 효과를 의미한다. 또는 오히려 반대 방향의 상관성이 있는 것처럼 나타나기도 한다. 위의 상자 그래프에서 투명도에 따라 오히려 가격이 하락하는 경향이 나타난 이유는 제 삼의 변수인 다이아몬드 중량(carat)에 의한 혼동 효과가 있기 때문이다. 다이아몬드 가격은 중량에 크게 영향을 받는다. 그런데 투명도가 큰 다이아몬드들은 대부분 중량이 작았기 때문에 투명도보다 가격에 더 큰 영향을 미치는 중량이라는 변수 때문에 마치 투명도가 높으면 가격이 낮은 것처럼 혼동되는 효과를 보인 것인다. 다음처럼 다이아몬드 중량과 투명도의 관계에 대한 상자 그래프를 그려보면 투명도가 높은 다이아몬드는 중량이 낮게 분포되어 있음을 볼 수 있다. &gt; ggplot(diamonds, aes(x = clarity, y = carat)) + geom_boxplot(notch = TRUE) 따라서 두 변수만의 나타난 관계로 두 변수의 상관성을 속단해서는 안된다. 만약 직관에 부합되지 않는 경향이 보인다면 왜 그런 경향을 보이는지, 혼동 효과가 있는 것은 아닌지에 대한 후속 분석이 필요하다. 그러면 다이아몬드 가격에서 중량의 혼동 효과를 빼고 투명도가 가격에 미치는 영향만 확인해 보려면 어떻게 해야 할까? 다음처럼 가격을 중량에 회귀 분석한 후 남은 잔차를 대상으로 상자 그래프를 그려보면 된다. 그러면 가격 변수에서 중량 변수가 설명한 부분을 제외한 가격의 변동성이 잔차로 남게 되고, 이 변동성이 투명도와 상관성이 있는지 확인할 수 있다. &gt; lmfit &lt;- lm(log(price) ~ log(carat), data = diamonds) &gt; ggplot(diamonds, aes(x = clarity, lmfit$residuals)) + + geom_boxplot(notch = T) 9.2.2 범주별로 수치형 변수의 분포 모양을 비교하기 상자 그래프는 사분위수와 이상치의 유무를 범주별로 쉽게 비교할 수 있는 장점이 있지만 수치형 변수의 자세한 분포를 확인하는데는 한계를 가진다. 범주별로 자세한 분포를 확인할 때는 여러 가지 그래프를 사용할 수 있다. 각각의 그래프는 자신만의 장단점이 존재한다. 그러므로 데이터에 따라, 분석가가 분석하고자 하는 목적에 따라서 다음에 설명하는 그래프 중 일부를 취사선택하여 사용한다. 바이올린 차트로 비교하기 상자 그림과 비슷한데 범주별 수치형 변수의 확률 밀도를 보여주기 때문에 분포의 차이를 좀 더 자세히 확인할 수 있다. 바이올린 차트를 그리는 문법은 상자 그래프와 동일한데 geom_boxplot() 함수 대신 geom_violine() 함수를 사용하는 점만 다르다. 다음은 course 데이터에서 총점의 성별 차이를 바이올린 차트로 표현한 예이다. 여학생의 점수가 좀더 평평한 형태로 분포되어 있는 것을 확인할 수 있다. 그리고 여학생의 총점 분포에 두 개의 봉우리가 보인다. &gt; ggplot(course, aes(x = gender, y = score)) + geom_violin() 앞의 그래프에 분반 변수를 추가하여 성별-분반별 총점 분포를 더 자세히 살펴보자. 남학생의 분포는 예외적으로 점수가 낮은 학생을 제외하면 1, 2 분반이 비슷한 반면 여학생은 1분반과 2분반의 봉우리가 서로 달라서 여학생 전체 분포에 두 개 이상의 봉우리를 만들었음을 확인할 수 있다. &gt; ggplot(course, aes(x = gender, y = score, fill = class)) + geom_violin() 히스토그램으로 비교하기 범주별 수치 변수의 분포의 차이는 히스토그램으로도 확인해 볼 수 있다. 범주형 변수에 따라 측면으로 나누어 히스토그램을 그리는 문법은 다음과 같다. ggplot(데이터, aes(x = 수치형변수)) + geom_histrogram() + facet_wrap(~ 범주형변수) 다음은 성별로 총점의 히스토그램을 측면으로 나누어 그래프를 그린 예이다. &gt; ggplot(course, aes(x = score)) + geom_histogram(bins = 15) + + facet_wrap(~ gender) 그런데 이렇게 측면으로 나누어 그리면 분포의 차이를 비교하기가 어려울 수 있다. 만약 두 히스토그램을 한 그래프에 겹쳐 그려서 범주별 차이를 비교하고자 한다면, geom_histogram()의 채우기 색상(fill)에 범주형 변수를 매핑한 후 position인수를“dodge”`로 설정하면 된다. 그런데 범주별로 절대 빈도수가 서로 다르므로 비교하기 어렵기 때문에 히스토그램을 확률밀도 형태로 그리는 것이 좋다. ggplot(데이터, aes(x = 수치형변수, y = ..density, fill = 범주형변수)) + geom_histrogram() 다음은 성별 차이를 보기 위해서 확률 밀도로 총점의 히스토그램을 겹쳐 표현한 예이다. &gt; ggplot(course, aes(x = score, y = ..density.., fill = gender)) + + geom_histogram(position = &quot;dodge&quot;, bins = 15) Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ℹ Please use `after_stat(density)` instead. Freqpoly 그래프로 비교하기 그런데, 히스토그램을 겹쳐 그리면 범주별로 분포를 보기가 조금 어렵다. 이런 경우 freqpoly 그래프를 그리는 것이 분포를 겹쳐서 살펴보기 좋다. freqpoly 그래프는 히스토그램과 같은 문법으로 데이터를 그래프로 표현하는데 다른 점은 막대가 아니라 선으로 분포를 표현한다는 것이다. 그렇기 때문에 범주형 변수를 fill 속성이 아니라 선의 색상인 color에 매핑을 한다. ggplot(데이터, aes(x = 수치형변수, y = ..density, color = 범주형변수)) + geom_freqpoly() &gt; ggplot(course, aes(score, ..density.., color = gender)) + + geom_freqpoly(bins = 15) 다음은 앞의 그래프를 분반 변수를 기준으로 측면으로 나누어 Freqpoly 그래프를 그려본 것이다. 2분반은 남여의 분포의 위치가 비슷한 곳에 있는데 1분반은 여학생의 점수 분포가 남학생의 분포보다 조금은 아래에 있음을 볼 수 있다. &gt; ggplot(course, aes(score, ..density.., color = gender)) + + geom_freqpoly(bins = 15) + + facet_wrap(~ class) 확률 밀도 그래프 히스토그램과 freqpoly()는 실제 관측치로 데이터를 확인할 수 있는 장점이 있지만 어떻게 구간을 나눌지에 따라 모양이 크게 변한다. 따라서 확률 밀도 함수를 추정하여 밀도 함수에 대해 그래프를 그려보는 것이 범주별 차이를 파악하기 쉬울 수 있다. ggplot(데이터, aes(x = 수치형변수, color = 범주형변수, linetype = 범주형변수)) + geom_density() 다음은 앞서 그린 분반을 기준으로 측면으로 나누어 성별로 총점에 대해 Freqpoly 그래프를 확률 밀도 그래프로 다시 그린 예이다. 남학생의 분포는 분반별 차이가 크지 않은데 여학생은 1분반은 왼쪽으로, 2분반은 오른쪽으로 분포가 치우쳐 있음을 확인할 수 있다. &gt; ggplot(course, aes(score, color = gender, linetype = gender)) + + geom_density() + + facet_wrap(~ class) 산점도로 범주형 변수와 수치형 변수의 상관성 분석하기* 산점도는 두 수치형 변수의 관계를 나타낼 때 주로 사용되지만 범주형 변수의 범주가 2개일 때는 범주형 변수와 수치형 변수의 관계를 살펴보기 위해서도 사용될 수 있다. 댜음은 ISLR 패키지의 default 데이터이다. bizstatp 패키지를 설치하였다면 이미 설치가 되어 있을 것이다. &gt; library(ISLR) &gt; head(Default) default student balance income 1 No No 729.5265 44361.625 2 No Yes 817.1804 12106.135 3 No No 1073.5492 31767.139 4 No No 529.2506 35704.494 5 No No 785.6559 38463.496 6 No Yes 919.5885 7491.559 다음은 신용 잔고(balance)에 따른 채무불이행(default)을 산점도로 표시한 것이다. 채무불이행이 범주형 변수여서 동일한 위치에 데이터가 중복되어서 찍히는 것을 방지하기 위해서 geom_jitter()를 사용하여 데이터를 위아래로 0.2 범위 정도로 임의로 흩뿌렸다. 그리고 geom_smooth() 함수로 로지스틱 회귀 적합선을 그렸다. 신용 잔고가 1,500 달러보다 올라가면 채무 불이행의 확률이 크게 증가함을 볼 수 있다. &gt; ggplot(ISLR::Default, aes(balance, as.numeric(default) - 1)) + + geom_jitter(height = 0.2) + + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;)) `geom_smooth()` using formula = &#39;y ~ x&#39; 다음은 학생 여부에 따라 신용잔고가 채무불이행에 어떤 영향을 주는지를 살펴본 그래프이다. 학생이 아닌 경우에 신용 잔고 상승이 채무불이행을 초래할 확률을 더 높이는 것을 볼 수 있다. &gt; ggplot(ISLR::Default, aes(balance, as.numeric(default) - 1, color = student)) + + geom_jitter(height = 0.2) + + geom_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;)) `geom_smooth()` using formula = &#39;y ~ x&#39; "],["ch-hypoTest.html", "Chapter 10 가설검정이란? 10.1 가설의 설정 10.2 검정통계량과 표본 분포 10.3 기각역과 유의수준 10.4 유의확률 p-값(p-value)", " Chapter 10 가설검정이란? 통계적 가설검정은 모집단의 특성에 대한 가설을 설정한 뒤에 표본관찰을 통하여 그 가설의 채택여부를 결정하는 통계적 분석방법이다. 예를 들어, 동전 던지기 게임을 하는데 “지금 게임에 사용되는 동전은 앞면과 뒷면이 나올 확률이 동일한 공정한 동전이다”라는 가설을 세웠다고 하자. 표본관찰을 위해 10번 동전을 던져 본 뒤 앞면이나 뒷면이 나오는 횟수를 세어서 이 가설이 적합한지를 판단하였다면 이는 통계적 가설검정을 수행한 것이다. 표본을 관찰해보니, 만약 동전이 공정한 것이라고 생각되기에는 너무 많은 앞면이나 뒷면이 나오면 가설을 기각하고, 그렇지 않은 경우에는 가설을 채택한다. 그림 10.1는 가설검정의 일반적인 절차를 보여준다. Figure 10.1: 가설검정의 절차 10.1 가설의 설정 보통 어떤 모집단에 대한 가설검정을 할 때 먼저 모집단에 대해 서로 대립되는 두 개의 가설을 설정한다. 위의 예에서는 동전이 공정한 것이다라는 가설과 동전이 편향되어 있다는 가설이 서로 대립되고 있다. 대립되는 두 가설 중 일반적으로 받아들여지는 가설을 귀무가설(null hypothesis)이라고 하고, 통계적으로 상당한 증거가 있어야만 받아들여지는 가설을 대립가설(alternative hypthesis)이라고 한다. 앞의 예에서는 상단한 증거가 없는 한 동전은 공정한 것이라고 판단하므로 이 가설이 귀무가설이 된다. 가설검정이란 표본관찰 또는 실험을 통하여 귀무가설(\\(H_0\\))과 대립가설(\\(H_1\\)) 중에서 하나를 선택하는 과정이다. 다음은 다양한 가설검정 문제에서 가설 수립을 한 예이다. Example 10.1 게임에 사용되는 동전이 있을 때, 앞면이 나올 확률을 \\(p\\)라고 하자. 동전의 앞면이 나올 확률에 대하여 다음과 같이 가설을 수립할 수 있다. \\(H_0\\): \\(p \\, = \\, 1/2\\) (게임에 사용되는 동전은 공정한 것이다.) \\(H_1\\): \\(p \\, \\neq \\, 1/2\\) (게임에 사용되는 동전은 편향된 것이다.) Example 10.2 2010 년 초등학교 4학년 학생의 평균신장이 142cm였다. 2020 년의 초등학교 4학년 학생의 신장의 평균을 \\(\\mu\\)라고 하자. 그러면 2020 년도의 초등학교 4학년의 평균 신장에 대하여 다음과 같이 가설을 수립할 수 있다. \\(H_0\\): \\(\\mu \\, = \\, 142\\) (2020년의 초등학교 4학년 학생의 평균신장도 142cm일 것이다.) \\(H_1\\): \\(\\mu \\, &gt; \\, 142\\) (2020년의 초등학교 4학년 학생의 평균신장도 142cm보다 클 것이다.) Example 10.3 타이어 제조사에서 새로운 공정을 도입하려고 한다. \\(\\mu_1\\)을 재래식 공정으로 제조된 타이어의 평균 수명, \\(\\mu_2\\)를 신규 공정으로 제조된 타이어의 평균 수명이라고 하자. 그러면 신규 공정으로 제조된 타이어의 평균 수명에 대하여 다음과 같이 가설을 수립할 수 있다. \\(H_0\\): \\(\\mu_1 \\, = \\, \\mu_2\\) (재래식 공정이나 신규 공정이나 타이어의 평균 수명은 동일할 것이다.) \\(H_1\\): \\(\\mu \\, &lt; \\, \\mu_2\\) (신규 공정으로 제조된 타이어의 평균 수명이 더 길 것이다.) 가설검정은 대립되는 두 가설 \\(H_0\\)와 \\(H_1\\) 중에서 하나를 선택하는 것이다. 그러므로 \\(H_0\\)를 채택(accept)하면 \\(H_1\\)를 기각(reject)하게 되고, \\(H_0\\)를 기각하면 \\(H_1\\)를 채택하게 된다. 10.2 검정통계량과 표본 분포 검정통계량(test statistic)은 \\(H_0\\) 와 \\(H_1\\) 중 어느 하나를 채택하는 데 사용되는 표본 통계량이다. 앞의 예에서는 동전을 10번 던져 나오는 앞면의 수 또는 뒷면의 수가 검정통계량이 될 수 있다. 검정통계량이 정해지면 귀무가설 \\(H_0\\)가 맞다는 가정 하에 검정통계량의 표본 분포를 구한다. 동전이 공정한지를 보는 Example 10.1 문제에서 검정통계량 \\(T\\)를 10 번 던져서 나온 앞면의 수라고 하였다고 하자. 그러면 귀무가설 하에서 검정통계량 \\(T\\)는 크기 \\(n=10\\)이고 성공 확률 \\(p=1/2\\)인 이항분포를 따르므로 다음과 같이 검정통계량의 표본 분포를 구할 수 있다. 앞면이 나온 횟수 확률 0 0.0009766 1 0.0097656 2 0.0439453 3 0.1171875 4 0.2050781 5 0.2460938 6 0.2050781 7 0.1171875 8 0.0439453 9 0.0097656 10 0.0009766 10.3 기각역과 유의수준 기각역(critical region)은 귀무가설이 기각되고 대립가설이 채택되는 검정통계량의 영역을 의미한다. 기각역은 유의수준 \\(\\alpha\\)에 의해 결정된다. 유의수준이란 귀무가설이 옳은데도 불구하고 이를 기각할 확률을 의미한다. 표본의 검정통계량 값이 매우 예외적인 값이 나왔다고 하자. 예를 들어 Example 10.1 에서 10번 동전을 던져서 앞면이 10번 나왔다고 하자. 귀무가설이 맞다는 가정 하에 10번 던졌을 때 모두 앞 면이 나올 확률은 0.000977로 매우 작다. 이러한 사건은 1,000 번 이러한 실험을 반복하면 1 번 정도 발생하는 예외적인 사건이다. 그러므로 통계적 가설검정에서는 귀무 가설이 참인데 이러한 예외적인 사건이 발생했다고 판단하기보다는, 귀무가설을 기각하고 동전이 공정하지 않다는 대립가설을 채택하는게 차라리 더 합리적이라고 판단한다. 기각역이란, 귀무가설이 참이라면 매우 예외적인 확률로 발생하는 검정통계량의 영역이어서 차라리 귀무가설을 기각하고 대립가설을 채택하는 구간이다. 그러나 검정통계량의 값이 기각역에 포함되는 사건이, 귀무 가설이 참이어도 예외적으로 발생할 수 있는 사건이지 전혀 발생하지 않는 사건은 아니기 때문에 귀무가설이 참인데도 귀무가설을 기각할 확률은 존재한다. 그리고 이 확률을 유의수준이라고 한다. 그러면 얼마나 예외적인 일이 발생해야 귀무가설을 기각하고 대립가설을 채택해야 할까? 일반적으로 유의수준 \\(\\alpha\\)를 5%로 정하지만, 문제에 따라 1%나 10%로 하는 경우도 있다. 유의수준 \\(\\alpha\\)가 5%이면, 귀무가설 하에서 구한 검정통계량의 값이 발생할 가능성이 5% 이하인 영역에서 발생했으면 귀무가설을 기각하고, 그렇지 않으면 귀무가설을 채택하겠다는 의미이다. 다시 말해 검정통계량이 발생할 가능성이 예외적인 5% 영역에서 발생하면 귀무가설이 맞을 ’가능성이 작다’라고 판단하겠다는 것이다. 기각역의 크기는 유의수준 \\(\\alpha\\)에 의해서 결정되지만 기각역의 위치는 대립가설에 의해 결정된다. 기각역의 위치가 검정통계량 값의 양측에 있으면 양측검정, 기각역의 위치가 한 쪽에 있으면 단측검정이라 한다. 양측검정(two-side test)은 귀무가설이 ’모수가 특정값이다’라고 할 때, 대립가설이 ’모수가 특정값이 아니다’라고 주어지는 경우에 발생한다. 단측검정(one-side test)은 왼쪽에 기각역이 생기는 왼쪽 단측검정과 오른쪽에 생기는 오른쪽 단측검정으로 나뉘어진다. 왼쪽 단측검정은 대립가설이 ’모수가 특정 값보다 작다’로 주어지는 경우에 발생한다. 오른쪽 단측검정은 대립가설이 ’모수가 특정 값보다 크다’로 주어지는 경우에 발생한다. Example 10.1는 대립가설이 동전의 앞면이 나올 확률이 \\(1/2\\)이 아니라는 것이다. 그러므로 동전의 앞면이 나올 확률이 너무 크거나 작은 경우 모두가 관심의 대상이다. 따라서 10번 던져서 앞면이 나오는 수를 \\(x\\)라고 하면, \\(x\\)가 너무 크거나 너무 작으면 대립 가설을 채택하게 된다. 따라서 유의수준 \\(\\alpha = 0.1\\)로 가설검정을 한다면 양측검정의 기각역은 다음 그림처럼 \\(x \\le 1\\) 또는 \\(x \\ge 9\\)가 된다. (기각역에 2와 8을 포함시키면 귀무가설이 참인데도 기각될 확률이 10%보다 커진다.) 그러나 만약 대립가설이 앞면이 나올 확률이 \\(1/2\\)보다 크다였다면 앞면이 예외적으로 많이 나온 경우만 대립가설을 채택, 즉 귀무가설을 기각하게 된다. 따라서 기각역의 위치는 동전의 앞면이 예외적으로 많이 나온 영역이 된다. 따라서 이 가설검정은 오른쪽 단측검정이 되고 유의 수준 \\(\\alpha = 0.1\\)에서 기각역은 다음 그림처럼 \\(x \\ge 8\\)이 된다. (기각역에 7을 포함시키면 귀무가설이 참인데도 기각될 확률이 10%보다 커진다.) 가설검정을 할 때, 가설검정은 항상 오류 가능성을 포함하고 있다는 것에 주의해야 한다. 가설검정에서 발생할 수 있는 오류에는 제1종 오류(\\(\\alpha\\))와 제2종 오류(\\(\\beta\\))의 두 가지 종류가 있다. 제1종 오류(type I error)는 귀무가설이 옳은데도 불구하고 귀무가설을 기각하는 오류이고 제2종 오류(type II error)는 귀무가설이 사실이 아님에도 귀무가설을 채택하는 오류이다. 다음 표는 귀무가설과 대립가설이 참일 때 귀무 가설과 대립 가설을 채택하는 것에 따라 발생할 수 있는 오류의 형태를 보여 준다. 사실 \\(H_0\\) 채택 \\(H_1\\) 채택 \\(H_0\\)가 참 옳은 결정 제1종 오류 \\(H_1\\)이 참 제2종 오류 옳은 결정 1종 오류가 발생할 확률은 유의수준 \\(\\alpha\\)이다. 그러면 2종 오류가 어떤 의미를 가지고 있는지 살펴보자. Example 10.1과 같은 동전의 앞면이 나올 확률 \\(p\\)에 대해 \\(p = 1/2\\)라는 귀무가설과 \\(p &gt; 1/2\\)라는 대립가설이 서로 대립하고 있다고 하자. 그러면 앞서 본 그림처럼 기각역은 유의 수준 \\(\\alpha = 0.1\\)에서 \\(x \\ge 8\\)이 된다. 만약 \\(p = 0.7\\)이어서 대립가설이 참이라고 하자. 그러면 \\(p = 0.7\\)인데도 귀무가설 \\(p = 1/2\\)가 채택될 확률, 즉, 2종 오류는 얼마일까? 이는 크기가 10이고 성공확률이 0.7인 이항분포를 사용하면 쉽게 계산할 수 있다. 다음 그림은 \\(p = 0.7\\)이 참일 때 귀무가설 \\(p = 1/2\\)가 채택될 확률을 보여주며, 이 확률은 61.7%로 매우 크다는 것을 알 수 있다. 동일한 검정통계량을 사용할 때 2종 오류를 줄이려면 표본 크기를 증가시켜야 한다. 동전 문제에서 표본 크기가 10개가 아니라 40 개로 증가시키면 더 많은 정보를 가지고 좀 더 정밀한 가설검정을 할 수 있어서 2종 오류가 11.5%로 감소하는 것을 볼 수 있다. 그런데 만약 실제 값이 \\(p \\neq 1/2\\)이지만 \\(p \\approx 1/2\\)로 귀무가설의 값과 매우 가깝다면 어떻게 될까? 표본의 크기를 매우 크게 늘려도 2종 오류가 잘 감소하지 않을 것이다. 그러므로 가설검정에서 귀무가설이 채택되었다 하더라도 대립가설이 참일 가능성이 없다고 판단해서는 안된다. 가설검정에는 항상 오류가 포함될 수 있기 때문이다. 따라서 귀무가설이 채택되었다는 의미는 표본에서 귀무가설이 기각될 만한 충분한 통계적 증가를 발견하지 못했다라고 판단해야 한다. 10.4 유의확률 p-값(p-value) 지금까지 살펴본 유의수준 \\(\\alpha\\) 값에 따라 기각역을 설정하고, 표본의 검정통계량이 기각역에 있는지에 따라 가설검정을 하는 방법은 유의수준 값이 달라질 때마다 이러한 절차를 반복해야 한다. 따라서 R, SPSS, SAS 등의 대부분의 통계 소프트웨어는 기각역을 계산하기 보다는 유의확률 p-값(p-value)을 계산하여 제공한다. 유의확률 p-값은 귀무가설이 참이라고 할 때 검정통계량의 값이 귀무 가설에 반하여 얼마나 예외적인 사건이었는지를 알려주는 지표이다. p-값의 정확한 정의는 검정통계량의 값이 귀무 가설에 반하여 현재의 값 정도나 그것보다 더 예외적인 값이 나올 확률이다. Example 10.1에서 10번 던진 결과 앞면이 2회 나왔다고 하자. 대립가설이 \\(1/2\\)가 아니라는 것이므로 귀무가설에 반하는 사건은 매우 적은 앞면이 나오거나 매우 많은 앞면이 나오는 것이다. 검정통계량이 귀무 가설에 반하여 현재의 값 정도나 그것보다 더 예외적인 값이 나오는 경우는 0, 1, 2 회로 매우 앞면이 적게 나오거나, 8, 9, 10회로 매우 앞면이 많이 나오는-뒷면이 0, 1, 2회로 적게 나오는-경우이다. 따라서 양측검정인 경우 p-값은 다음과 같다. \\[ \\text{p-value} = P(N = 0, 1, 2, 8, 9, \\text{ or } 10) = 0.109375 \\] 만약 대립가설이 \\(p &lt; 1/2\\)이었다면, 현재의 검정통계량 값 정도나 그보다 더 귀무가설에 반하여 대립 가설을 지지하는 경우는 앞면이 0, 1, 2회 나오는 것이다. 따라서 왼쪽 단측검정인 경우 p-값은 다음과 같다. \\[ \\text{p-value} = P(N = 0, 1, \\text{ or } 2) = 0.0546875 \\] 만약 대립가설이 \\(p &gt; 1/2\\)이었다면, 현재의 검정통계량 값 정도나 그보다 더 귀무가설에 반하여 대립 가설을 지지하는 경우는 앞면이 2부터 10회까지가 나오는 것이다. 따라서 오른쪽 단측검정인 경우 p-값은 다음과 같다. \\[ \\text{p-value} = P(N \\ge 2) = 0.9892578 \\] 실제 가설검정에서 그러한 결과가 나오는지 binom.test() 함수를 사용하여 확인해 보자. 결과에서 p-value로 표시된 값이 앞에서 계산한 확률값에 수렴하는 것을 볼 수 있다. &gt; binom.test(2, n = 10, p = 1/2, alternative = &quot;two.sided&quot;) Exact binomial test data: 2 and 10 number of successes = 2, number of trials = 10, p-value = 0.1094 alternative hypothesis: true probability of success is not equal to 0.5 95 percent confidence interval: 0.02521073 0.55609546 sample estimates: probability of success 0.2 &gt; binom.test(2, n = 10, p = 1/2, alternative = &quot;less&quot;) Exact binomial test data: 2 and 10 number of successes = 2, number of trials = 10, p-value = 0.05469 alternative hypothesis: true probability of success is less than 0.5 95 percent confidence interval: 0.0000000 0.5069013 sample estimates: probability of success 0.2 &gt; binom.test(2, n = 10, p = 1/2, alternative = &quot;greater&quot;) Exact binomial test data: 2 and 10 number of successes = 2, number of trials = 10, p-value = 0.9893 alternative hypothesis: true probability of success is greater than 0.5 95 percent confidence interval: 0.03677144 1.00000000 sample estimates: probability of success 0.2 따라서 p-값이 유의수준 \\(\\alpha\\)보다 크면 검정통계량의 값은 기각역 바깥에 놓이게 되고, p-값이 \\(\\alpha\\)보다 작거나 같으면 검정통계량은 기각역에 놓이게 된다. 그러므로 p-값이 작을수록 대부분의 유의수준에서 기각역에 포함되게 되므로 귀무 가설을 기각해야 하는 강한 증거가 된다. 대립가설이 \\(p &gt; 1/2\\)의 가설검정 결과를 보면 유의수준 5%로 가설검정한다면 p-값이 0.05보다 크므로 귀무가설을 채택하나, 유의수준 10%로 가설검정한다면 p-값이 0.1보다 작으므로 귀무가설을 기각한다. "],["ch-categoricalTest.html", "Chapter 11 범주형 변수에 대한 가설검정 11.1 단일 모집단의 모비율에 대한 가설검정 11.2 여러 모집단의 모비율의 차이에 대한 가설검정 11.3 적합성 검정 11.4 독립성 검정 11.5 범주형 변수의 가설검정에 대한 정리", " Chapter 11 범주형 변수에 대한 가설검정 이 장에서는 R을 이용하여 범주형 변수에 대해 가설검정하는 방법을 알아본다. 11.1 단일 모집단의 모비율에 대한 가설검정 모집단이 하나일 때, 특정 범주가 차지하는 비율 \\(p\\)에 대해 가설검정하는 방법을 살펴보자. 모집단에서의 관심의 대상이 되는 범주의 비율 \\(p\\)를 모비율이라고 한다. 여기서 관심의 대상이 되는 범주는 문제마다 다르게 정의될 수 있다. 모비율이 어떤 전염병에 대한 항체 보유자에 대한 비율일 수도 있고, 어떤 정단에 대한 지지율일 수도 있다. 가설검정을 위해 모집단에서 \\(n\\) 개의 표본을 추출하였다고 하자. 그 중 \\(x\\) 개가 해당 범주의 관측도수라면 표본비율 \\(\\hat{p}\\)은 다음과 같이 계산된다. \\[ \\hat{p} = x / n. \\] 단일 모집단의 모비율에 대한 가설검정에서 귀무가설은 모집단의 비율 \\(p\\)가 특정값 \\(p_0\\)이다로 설정된다. 반면 대립가설은 모비율 \\(p\\)가 \\(p_0\\)가 아니다, 더 크다, 더 작다 중 하나로 설정된다. 앞서 보았던 Example 10.1의 동전의 앞면이 나올 비율에 대한 가설검은 단일 모집단의 모비율에 대한 가설검정의 예라 할 수 있다. 모비율에 대한 가설검정은 검정통계량과 표본분포로 다음 두 가지 중 하나가 사용된다. 이항분포로 검정: 가설검정에 사용할 검정통계량으로 표본에서의 특정 범주가 관측된 수 \\(x\\)를 사용한다. 그러면 모집단의 크기가 크고 표본의 선택이 서로 독립이라면 검정통계량 \\(x\\)는 모비율이 \\(p = p_0\\)라는 귀무가설 하에 이항분포 \\(Binom(n, p_0)\\)를 따른다. \\[ x \\sim Binom(n, p_0). \\] 정규분포로 검정: 검정통계량으로 표본비율 \\(\\hat{p}\\)을 사용하다. 그러면 \\(\\hat{p}\\)은 모비율이 \\(p = p_0\\)라는 귀무가설 하에 정규분포 \\(N(p_0, \\sqrt{p_0(1-p_0)/n})\\)을 근사적으로 따른다. 따라서 다음과 같이 표준정규분포를 따른는 검정통계량 \\(T\\)를 사용하여 가설검정을 수행한다. \\[ T = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1 - p_0)}{n}}} \\sim N(0, 1) \\] 이항분포 검정은 표본의 추출이 독립적이라는 가정 하에 정확한 확률분포이고, 정규분포 검정은 검정통계량에 대한 근사적 확률분포이므로 가능하면 이항분포 검정을 사용하는 것이 좋다. 그러나 예전에는 컴퓨터의 계산 능력이 높지 않았기 때문에 비율 검정을 사용하는 경우가 많았다. 다만 \\(n\\)이 매우 크고 \\(np\\)의 값이 충분히 큰 경우에는 이항분포 검정이나 정규분포 검정의 차이가 거의 없다. 이 경우에는 계산 시간의 절약을 위하여 정규분포 검정을 사용할 수 있다. 대립가설에 따라 기각역의 위치는 다음과 같이 정리될 수 있다. 귀무가설 (\\(H_0\\)) 대립가설 (\\(H_1\\)) 기각역의 위치 \\(p = p_0\\) \\(p \\neq p_0\\) 양측검정 \\(p = p_0 \\, (p \\ge p_0)\\) \\(p &lt; p_0\\) 왼쪽 단측검정 \\(p = p_0 \\, (p \\le p_0)\\) \\(p &gt; p_0\\) 오른쪽 단측검정 왜냐하면 대립가설이 \\(p &lt; p_0\\)가 채택되려면 표본의 관측도수 \\(x\\)가 귀무가설이 맞다고 했을 때의 이항분포에서 예외적으로 작게 나와야 한다. 그러므로 분포의 왼쪽을 기각역으로 설정하는 왼쪽 단측검정을 한다. 마찬가지로 대립가설이 \\(p &gt; p_0\\)가 채택되려면 관측도수 \\(x\\)가 귀무가설 하의 이항분포에서 예외적으로 크게 나와야 한다. 그러므로 분포의 오른쪽을 기각역으로 설정하는 오른쪽 단측검정을 한다. 대립가설이 \\(p \\neq p_0\\)이면 관측도수 \\(x\\)가 귀무가설 하의 이항분포에서 예외적으로 작거나 크게 나올 때 대립가설을 채택하므로, 기각역은 분포의 양쪽에 모두 있게 된다. 같은 방식으로 표본비율 \\(\\hat{p}\\)의 값이 대립가설이 받아들여지려면 귀무가설의 모비율 \\(p_0\\)보다 작아야 하는지, 커야 하는지를 생각해 보면 기각역의 위치가 위의 표처럼 되는 것을 쉽게 이해할 수 있다. 11.1.1 binom.test()로 단일 모집단 모비율 검정하기 R의 기본 패키지인 stat 패키지의 binom.test() 함수는 이항분포를 사용하여 단일 모집단에 대한 모비율에 대한 가설검정을 수행한다. binom.test() 함수를 이용하여 단일 모집단의 모집율에 대한 가설검정을 하는 문법은 다음과 같다. binom.test(x = 관측도수, n = 표본수, p = 귀무가설_모비율, alternative = &quot;대립가설_종류&quot;) binom.test(x = 관측도수, n = 표본수, p = 귀무가설_모비율, alternative = &quot;대립가설_종류&quot;, conf.level = 신뢰수준) # 신뢰구간의 신뢰수준을 조정 binom.test() 함수에 사용되는 인수는, stat 패키지의 가설검정 함수들이 공통적으로 사용하는 인수도 있고, 모비율 검정에만 관련된 인수가 있다. binom.test()의 처음 세 인수는 모비율 검정에만 관련된 인수이다. x: 표본에서 특정 범주가 발생한 횟수 n: 표본의 크기 p: 귀무가설의 모비율 \\(p_0\\) 그 다음의 두 인수는 stat 패키지의 가설검정 함수들이 공통적으로 사용하는 인수이다. alternative: 대립가설의 종류를 지정한다. 대립가설이 \\(p \\neq p_0\\)이면 양측 검정을 의미하는 \"two.sided\"로, \\(p &lt; p_0\\)이면 왼쪽 검증을 의미하는 \"less\"로, \\(p &gt; p_0\\)이면 오른쪽 검정을 의미하는 \"greater\"로 값을 입력한다. conf.level: 대부분의 가설검정 함수는 신뢰구간도 함께 알려주는데 이 인수는 신뢰구간의 신뢰수준을 지정한다. 기본값은 0.95로 95% 신뢰구간을 계산하여 알려준다. Example 11.1 어떤 회사 제품의 불량률이 10%였다고 하자. 새로운 공정을 도입한 후 300개의 제품을 생산한 후 불량품을 조사하였더니 20개가 발견되었다. 새로운 공정 도입으로 불량률이 저하되었는지 유의수준 5%에서 가설검정하시오. Example 11.1의 가설검정은 불량률이 감소했다는 것을 검정하고자 하는 것이다. 그러므로 \\(p\\)를 새 공정의 불량률이라고 하면 귀무가설과 대립가설은 다음과 같이 설정한다. 왜냐하면 귀무가설은 일반적으로 받아들여지는 가설이다. 이 예에서 지금까지의 불량률이 10%였으므로 특별한 증거가 있지 않다면 새로운 공정의 불량률도 10%라고 생각하는 것이 합리적이다. 대립가설은 표본에서 특별한 증거가 발생하면 채택하고자 하는 가설이 된다. \\[ \\begin{align} H_0: &amp; \\quad p = 0.1 \\\\ H_1: &amp; \\quad p &lt; 0.1 \\end{align} \\] binom.test()을 사용하여 가설검정을 하면 다음과 같은 결과를 얻는다. &gt; binom.test(x = 20, n = 300, p = 0.1, alternative = &quot;less&quot;) Exact binomial test data: 20 and 300 number of successes = 20, number of trials = 300, p-value = 0.02868 alternative hypothesis: true probability of success is less than 0.1 95 percent confidence interval: 0.00000000 0.09540198 sample estimates: probability of success 0.06666667 인수들을 순서에 맞게 기술하면 인수의 이름을 생략하거나 일부만 기술해도 된다. 인수의 이름을 기술하면 순서는 중요하지 않다. 다음 명령문은 모두 동일한 결과를 준다. &gt; binom.test(20, 300, p = 0.1, alternative = &quot;less&quot;) &gt; binom.test(20, 300, 0.1, &quot;less&quot;) &gt; binom.test(p = 0.1, alternative = &quot;less&quot;, x = 20, n = 300) 이항분포 검정을 통해 우리는 다음 사실을 알 수 있다. 표본 비율 \\(\\hat{p}\\)는 0.0666667이다. p-값은 0.028679로 유의수준 0.05에서 귀무가설을 기각한다. (대립가설을 채택한다.) Example 11.2 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 이 과목은 평균적으로 수강생의 여학생 비율이 30%였다. 현재 이 과목 수강생의 여학생 비율의 과거와 달라졌다고 볼 수 있는지 유의수준 5%에서 가설검정하시오. Example 11.2의 가설검정은 여학생의 비율이 달라졌는지를 검정하는 것이다. \\(p\\)를 수강생 중 여학생의 비율이라고 하면 귀무가설과 대립가설을 다음과 같이 설정한다. \\[ \\begin{align} H_0: &amp; \\quad p = 0.3 \\\\ H_1: &amp; \\quad p \\neq 0.3 \\end{align} \\] binom.test()을 사용하여 가설검정을 하려면, x와 n의 값을 구해야 한다. Example 11.2에서는 x는 여학생의 수, n은 전체 수강생이 된다. 이를 구하기 위해서는 성별 수강생의 빈도표가 필요하다. &gt; library(bizstatp) &gt; head(course) major year gender class mid final hw score 1 Others 4 M 1 62 66 83.6 73.47 2 Others 3 F 1 46 37 88.7 61.50 3 ME 2 M 1 94 82 87.9 89.18 4 ME 2 M 1 73 71 88.7 78.47 5 ME 2 M 1 96 93 90.6 93.88 6 ME 2 M 1 54 43 84.3 64.39 &gt; tg &lt;- xtabs(~ gender, data = course) &gt; tg gender F M 18 27 x는 빈도표의 첫번째 요소이고 n은 빈도표의 모든 관측도수를 합하면 구할 수 있다. 그러므로 이 값을 binom.test()에 입력하면 다음 결과를 얻는다.. &gt; binom.test(tg[1], sum(tg), p = 0.3, alternative = &quot;two.sided&quot;) Exact binomial test data: tg[1] and sum(tg) number of successes = 18, number of trials = 45, p-value = 0.1457 alternative hypothesis: true probability of success is not equal to 0.3 95 percent confidence interval: 0.2569759 0.5566865 sample estimates: probability of success 0.4 이항분포 검정을 통해 우리는 다음 사실을 알 수 있다. 표본 비율 \\(\\hat{p}\\)는 0.4이다. p-값은 0.1457496로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 모비율의 95% 신뢰구간은 0.2569759에서 0.5566865이다. Example 11.3 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 이 과목은 과거에 평균적으로 수강생 중 2학년 학생의 비율이 80%였다. 현재 이 과목의 2학년 학생의 수강 비율이 과거보다 줄었다고 볼 수 있는지 유의수준 5%에서 가설검정하시오. Example 11.3의 가설검정은 2학년 학생의 수강 비율이 줄어들었는지를 검정하고자 하는 것이다. \\(p\\)를 2학년 학생의 수강 비율이라고 하면 귀무가설과 대립가설은 다음과 같이 설정한다. \\[ \\begin{align} H_0: &amp; \\quad p = 0.8 \\\\ H_1: &amp; \\quad p &lt; 0.8 \\end{align} \\] binom.test()를 이용하여 가설검정을 하려면 먼저 빈도표를 구해야 한다. 범주형 변수의 범주가 세 개 이상인 경우 빈도표를 이용하여 가설검정할 때, 범주표에서 x의 위치를 정확히 지정하여야 한다. 이 예에서는 2학년 학생의 수는 빈도표의 2번째 요소이다. n은 전체 관측도수의 합으로 구하면 된다. &gt; ty &lt;- xtabs(~ year, data = course) &gt; ty year 1 2 3 4 1 32 9 3 &gt; binom.test(ty[2], sum(ty), p = 0.8, alternative = &quot;less&quot;) Exact binomial test data: ty[2] and sum(ty) number of successes = 32, number of trials = 45, p-value = 0.09945 alternative hypothesis: true probability of success is less than 0.8 95 percent confidence interval: 0.0000000 0.8198828 sample estimates: probability of success 0.7111111 이항분포 검정을 통해 우리는 다음 사실을 알 수 있다. 표본 비율 \\(\\hat{p}\\)는 0.7111111이다. p-값은 0.0994542로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 11.1.2 빈도표를 입력변수로 전달하기 범주형 변수를 빈도표로 요약한 후 가설검정하는 경우가 빈번하기 때문에 binom.test()와 뒤에서 볼 prop.test()는 첫번째 인수로 빈도표를 입력받아 가설검정을 수행할 수 있다. 빈도표를 직접 입력받아 가설검정할 때, binom.test()와 prop.test()는 빈도표의 첫번째 범주에 대한 비율에 대하여 가설 검정을 수행한다. &gt; tg gender F M 18 27 &gt; binom.test(tg, p = 0.3, alternative = &quot;two.sided&quot;) Exact binomial test data: tg number of successes = 18, number of trials = 45, p-value = 0.1457 alternative hypothesis: true probability of success is not equal to 0.3 95 percent confidence interval: 0.2569759 0.5566865 sample estimates: probability of success 0.4 이 경우 빈도표는 성별의 빈도표처럼 두 개의 범주로만 이루어져 있어야 한다. 학년의 빈도표처럼 3 개 이상의 범주가 있으면 앞에서 설명한 것처럼 직접 x와 n 인수를 각각 빈도표에서 지정하여 입력하여야 한다. &gt; ty year 1 2 3 4 1 32 9 3 &gt; binom.test(ty, p = 0.8, alternative = &quot;less&quot;) Error in binom.test(ty, p = 0.8, alternative = &quot;less&quot;): &#39;x&#39;의 길이가 올바르지 않습니다 11.1.3 prop.test()로 단일 모집단 모비율 검정하기 prop.test() 함수는 정확한 이항분포 대신 근사적인 표준정규분포를 이용하여 가설검정을 수행한다. 단일 모집단의 모비율에 대한 가설검정의 경우 prop.test()의 인수의 사용방법은 binom.test()와 동일하다. 다음은 Example 11.1 문제를 prop.test() 함수를 이용하여 가설검정을 수행한 결과이다. binom.test()에서 검정통계량만 달라지므로 귀무가설과 대립가설은 모두 동일하다. &gt; prop.test(20, 300, p = 0.1, alternative = &quot;less&quot;) 1-sample proportions test with continuity correction data: 20 out of 300, null probability 0.1 X-squared = 3.3426, df = 1, p-value = 0.03375 alternative hypothesis: true p is less than 0.1 95 percent confidence interval: 0.00000000 0.09635565 sample estimates: p 0.06666667 비율 검정을 통해 우리는 다음 사실을 알 수 있다. 표본 비율 \\(\\hat{p}\\)는 0.0666667이다. (이항분포 검정과 동일하다.) p-값은 0.0337541로 유의수준 0.05에서 귀무가설을 기각한다. (대립가설을 채택한다.) p-값은 이항분포 검정과 조금 다른 것을 볼 수 있다. 비율 검정은 근사치로 분포를 계산하므로 n이 매우 크지 않으면 정확한 검정인 이항분포 검정과는 차이가 발생한다. 모비율의 95% 신뢰구간은 0에서 0.0963556이다. 신뢰구간도 사용되는 추정 통계량이 다르므로 이항분포 검정의 결과와는 조금 값이 다르다. 다음은 Example 11.2 문제를 prop.test() 함수를 이용하여 비율 검정을 수행한 결과이다. 이 문제도 검정통계량만 달라지므로 귀무가설과 대립가설은 모두 동일하다. &gt; prop.test(tg, p = 0.3, alternative = &quot;two.sided&quot;) 1-sample proportions test with continuity correction data: tg, null probability 0.3 X-squared = 1.6931, df = 1, p-value = 0.1932 alternative hypothesis: true p is not equal to 0.3 95 percent confidence interval: 0.2606306 0.5562701 sample estimates: p 0.4 비율 검정을 통해 우리는 다음 사실을 알 수 있다. 표본 비율 \\(\\hat{p}\\)는 0.4이다. (이항분포 검정과 동일하다.) p-값은 0.19319로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) p-값은 이항분포 검정과 조금 다른 것을 볼 수 있다. 비율 검정은 근사치로 분포를 계산하므로 n이 매우 크지 않으면 정확한 검정인 이항분포 검정과는 차이가 발생한다. 모비율의 95% 신뢰구간은 0.2606306에서 0.5562701이다. 신뢰구간도 사용되는 추정 통계량이 다르므로 이항분포 검정의 결과와는 조금 값이 다르다. 11.1.4 정규분포를 이용한 비율 검정에서 연속성 수정 prop.test() 함수는 binom.test() 함수보다 correct라는 인수를 하나 더 가지고 있다. 범주형 변수의 발생 건수 x는 0 또는 자연수의 값을 가지므로 이산형 확률변수이다. 그러나 정규분포를 사용하여 비율 검정을 할 경우에 검정통계량 T를 연속형 확률변수로 가정하여 p-값 등이 계산된다. 이러한 이산형 확률변수와 연속형 확률변수 사이의 불일치를 해소하기 위하여 이산형 확률변수의 값 x를 마치 연속형 확률변수의 값인 것처럼 수정하게 되는데 이를 연속성 수정이라고 한다. 예를 들어 x=10이라는 이산형 값은 연속적인 수직선 상에서 [9.5, 10.5)의 구간을 의미하는 것으로 수정한다. prop.test()는 기본적으로 연속형 수정을 하여 가설검정을 수행한다. 연속형 수정을 하지 않고 가설점을 하려면 correct = FALSE로 인수를 설정한다. 다음은 Example 11.1을 연속형 수정을 하지 않고 정규분포로 비율 검정을 수행한 결과이다. 연속형 수정을 한 결과와 p-값이 조금 다른 것을 볼 수 있다. &gt; prop.test(20, 300, p = 0.1, alternative = &quot;less&quot;, correct = FALSE) 1-sample proportions test without continuity correction data: 20 out of 300, null probability 0.1 X-squared = 3.7037, df = 1, p-value = 0.02715 alternative hypothesis: true p is less than 0.1 95 percent confidence interval: 0.00000000 0.09443818 sample estimates: p 0.06666667 11.2 여러 모집단의 모비율의 차이에 대한 가설검정 11.2.1 prop.test()를 이용한 두 모집단의 모비율의 차이 검정 범주형 변수의 특정 범주에 대해 두 집단에서 모비율이 차이를 가설검정하는 방법을 살펴보자. 두 집단의 모비율의 차이를 검정하는 대표적인 예가 어떤 백신이 전염병에 효과가 있는지 없는지를 가설검정하는 것이다. 진짜 백신을 투여한 집단과 가짜 백신을 투여한 집단에서 전염병에 걸리는 비율에 차이가 있는지를 살펴보아 백신의 효과에 대해 가설검정을 수행한다. 이 때의 귀무가설은 백신은 효과가 없으므로 ’두 집단에서 전염병에 걸리는 비율은 같다’이고, 대립가설은 ’진짜 백신을 맞은 집단에서 전염병에 걸리는 비율이 가짜 백신을 맞은 집단보다 전염병에 걸리는 비율이 낮다’이다. 두 모집단의 모비율에 대해 가설검정을 하려면 두 집단에서 각각 \\(n_1\\)과 \\(n_2\\) 개의 표본을 추출하하여 관심있는 범주의 관측도수 \\(x_1\\)과 \\(x_2\\)를 측정한다. 그리고는 두 표본에서의 표본비율 \\(\\hat{p}_1\\)과 \\(\\hat{p}_2\\)을 다음과 같이 계산한다. \\[ \\hat{p}_1 = x_1 / n_1, \\quad \\hat{p}_2 = x_2 / n_2. \\] 두 집단의 모비율 차이에 대한 검정의 귀무가설은 ’두 모집단의 모비율 \\(p_1\\)과 \\(p_2\\)은 같다’로 수립하고, 대립가설은 모비율이 같지 않다, \\(p_1\\)이 더 크다, 작다로 수립한다. \\(n_1\\)과 \\(n_2\\)가 충분히 크면 두 집단의 모비율 차이의 검정통계량 \\(T\\)는 다음과 같이 정의될 수 있고 근사적으로 표준정규분포를 따른다. \\[ T = \\frac{\\hat{p}_1 - \\hat{p}_2}{ \\sqrt{ \\hat{p} ( 1- \\hat{p}) \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}} \\sim N(0, 1) \\] 단, \\(\\hat{p} = (x_1 + x_2) / (n_1 + n_2)\\). 대립가설에 따라 유의수준 \\(\\alpha\\) 에 대해 기각역은 다음 표와 같다. 귀무가설 (\\(H_0\\)) 대립가설 (\\(H_1\\)) 기각역 \\(p_1 = p_2\\) \\(p_1 \\neq p_2\\) \\(T \\ge z_{\\alpha/2}\\) 또는 \\(T \\le -z_{\\alpha/2}\\) \\(p_1 = p_2\\) \\(p_1 &lt; p_2\\) \\(T \\le -z_{\\alpha}\\) \\(p_1 = p_2\\) \\(p_1 &gt; p_2\\) \\(T \\ge z_{\\alpha}\\) Example 11.4 기존 공정에서 400개를 생산했을 때 30개의 불량률이 발생하였다. 새로운 공정을 도입하고 300개의 제품을 생산한 후 불량품을 조사하였더니 20개가 발견되었다. 새로운 공정 도입으로 불량률이 저하되었는지 유의수준 5%에서 가설검정하시오. Example 11.4은 새 공정의 불량률이 감소했다는 것을 검정하는 것이므로 기존 공정과 새 공정의 불량률을 \\(p_1\\)과 \\(p_2\\)라고 하면 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: &amp; \\quad p_1 = p_2 \\\\ H_1: &amp; \\quad p_1 &gt; p_2 \\end{align} \\] R의 prop.test() 함수는 두 모집단의 모비율의 차이 검정에도 사용된다. prop.test(x = 관측도수_벡터, n = 표본수_벡터, alternative = &quot;대립가설_종류&quot;) prop.test() 함수를 여러 모집단의 모비율 차이를 검정할 때, 단일 모집단의 모비율 검정과의 차이는 다음과 같다. x와 n에 두 표본에서의 해당 범주의 관측도수와 표본 크기를 크기가 2인 벡터로 입력해야 한다. 이 때 주의해야 할 것은 x와 n 벡터에 두 집단의 정보를 나열할 때 귀무가설과 대립가설에서 첫 번째 모집단으로 설정된 표본의 값이 먼저 나열되어야 한다. 귀무가설이 두 모비율이 같다는 것이기 때문에, 단일 모집단에 대한 검정처럼 모비율을 특정 값으로 설정하지 않는다. 따라서 p 인수를 사용하지 않는다. Example 11.4에서는 기존 공정을 첫 번째 모집단으로 신규 공정을 두 번째 모집단으로 설정하여 대립가설을 설정하였으므로, x와 n도 해당 순서로 데이터가 입력되었다. 대립가설은 \\(p_1 &gt; p_2\\)이므로 \"greater\"로 설정되었다. &gt; prop.test(c(30, 20), c(400, 300), alternative = &quot;greater&quot;) 2-sample test for equality of proportions with continuity correction data: c(30, 20) out of c(400, 300) X-squared = 0.075833, df = 1, p-value = 0.3915 alternative hypothesis: greater 95 percent confidence interval: -0.02668306 1.00000000 sample estimates: prop 1 prop 2 0.07500000 0.06666667 표본 비율 \\(\\hat{p}\\)는 기존 공정과 신규 공정이 각각 0.075, 0.0666667이다. p-값은 0.3915127로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 따라서 신규 공정이 기존 공정보다 불량률이 낮다는 유의미한 통계적 증거는 없다고 할 수 있다. 11.2.2 교차표를 이용하여 여러 모집단의 모비율 차이를 검정하기 Example 11.5 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 분반(class)에 따라 여학생 비율에 차이가 있었는지 유의수준 5%에서 가설검정하시오. Example 11.5는 두 분반의 성별 차이가 있는지를 가설검정하는 것이다. 1분반과 2분반의 여학생 비율을 \\(p_1\\)과 \\(p_2\\)라고 하면 귀무가설과 대립가설은 다음과 같이 설정한다. \\[ \\begin{align} H_0: &amp; \\quad p_1 = p_2 \\\\ H_1: &amp; \\quad p_1 \\neq p_2 \\end{align} \\] prop.test() 함수의 x와 n 인수에 입력할 데이터를 구하려면 분반-성별 교차표를 계산하여야 한다. &gt; tcg &lt;- xtabs(~ class + gender, data = course) &gt; tcg gender class F M 1 10 12 2 8 15 x는 분반별 여학생의 수이므로 tcg의 첫번째 열이고, n은 분반별 학생 수이므로 tcg의 행별 합이된다. 그러므로 다음처럼 prop.test() 함수를 이용하여 두 분반의 여학생 비율의 차이에 대한 가설검정을 수행할 수 있다. &gt; prop.test(tcg[,1], marginSums(tcg, 1), alternative = &quot;two.sided&quot;) 2-sample test for equality of proportions with continuity correction data: tcg[, 1] out of marginSums(tcg, 1) X-squared = 0.18157, df = 1, p-value = 0.67 alternative hypothesis: two.sided 95 percent confidence interval: -0.2226672 0.4361059 sample estimates: prop 1 prop 2 0.4545455 0.3478261 여학생의 표본 비율 \\(\\hat{p}\\)는 1, 2 분반이 각각 0.4545455, 0.3478261이다. p-값은 0.6700265로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 따라서 분반별 성별 비율의 차이에 대한 통계적 증거는 없다고 할 수 있다. 교차표를 직접 인수로 전달하여 가설검정하기 그런데 모비율의 차이에 대한 가설검정을 하기 위하여 교차표에서 매번 열을 지정하여 x에 전달하고, 행별 합을 구하여 n에 전달하는 작업은 조금 번거로운 작업이다. prop.test()는 교차표를 첫 번째 인수로 직접 전달받아 모비율의 차이에 대한 가설검정을 수행할 수 있다. 이 때 첫 번째 인수로 전달될 교차표는 다음 조건이 만족되어야 한다. 교차표의 행은 모집단을 표현한다. Example 11.5에서 모집단은 분반이 된다. 교차표의 열은 검정하려는 범주형 변수를 표현해야 한다. Example 11.5에서 검정하고자 하는 범주형 변수는 성별이다. 교차표는 두 열만을 가져야 한다. 즉, 검정하고자 하는 범주형 변수의 범주는 두 개이어야 한다. Example 11.5의 범주형 변수는 성별이고 여자(F)와 남자(M)라는 두 변수만 가지고 있다. 모비율을 계산할 때 교차표의 첫 번째 열을 기준으로 계산을 수행한다. 그러므로 교차표 tcg에서는 여자의 비율을 계산하여 가설검정한다. 사실 두 개의 범주만 있는 경우에는 두 범주 중 무엇을 기준으로 계산하는 지는 표본비율에만 영향을 미치지 가설검정의 결과에는 영향을 미치지는 않는다. 따라서 모비율 가설검정을 할 때 xtabs()을 이용하여 교차표를 만들 때 다음처럼 교차표를 만들어 가설검정을 수행하면 된다. 교차표_결과 &lt;- xtabs(~ 모집단_구분_변수 + 검정할_범주형_변수, data = 데이터) prop.test(교차표_결과, alternative = &quot;대립가설_종류&quot;) x와 n 인수에 직접 값을 입력한 결과와 동일한 결과를 주는 것을 확인할 수 있다. Example 11.5은 분반을 각각의 모집단으로 하여 성별 비율의 차이를 검정하는 것이므로 분반이 행, 성별이 열이 되도록 교차표를 만들었다. 그리고 prop.test()는 모집단의 그룹을 행으로, 검정하려는 범주형 변수를 열로 된 교차표를 직접 입력 받아 가설검정을 수행하였다. &gt; tcg gender class F M 1 10 12 2 8 15 &gt; prop.test(tcg, alternative = &quot;two.sided&quot;) 2-sample test for equality of proportions with continuity correction data: tcg X-squared = 0.18157, df = 1, p-value = 0.67 alternative hypothesis: two.sided 95 percent confidence interval: -0.2226672 0.4361059 sample estimates: prop 1 prop 2 0.4545455 0.3478261 만약 Example 11.5 범주형 변수의 순서를 변경하여 남자(M)가 첫 번째 열에 나오도록 하여 남자의 모비율을 가지고 가설검정을 하려면 어떻게 해야 할까? factor() 함수를 사용하여 범주형 변수의 범주(levels)의 순서를 바꾼 후 교차표를 만들면 된다.8 (factor()에 대한 자세한 내용은 R 프로그래밍의 범주형 데이터와 요인 절을 참조하기 바란다.) 다음은 남자와 여자의 순서를 바꾸어 교차표를 만든 후 앞의 가설 검정을 다시 수행한 결과이다. p-값 등이 모두 동일하고 단지 여자가 아니라 남자로 표본비율을 계산하였기 때문에 모비율의 추정 값이 달라지는 것을 볼 수 있다. &gt; tcgM &lt;- xtabs(~ class + factor(gender, levels=c(&quot;M&quot;, &quot;F&quot;)), data = course) &gt; tcgM factor(gender, levels = c(&quot;M&quot;, &quot;F&quot;)) class M F 1 12 10 2 15 8 &gt; prop.test(tcgM, alternative = &quot;two.sided&quot;) 2-sample test for equality of proportions with continuity correction data: tcgM X-squared = 0.18157, df = 1, p-value = 0.67 alternative hypothesis: two.sided 95 percent confidence interval: -0.4361059 0.2226672 sample estimates: prop 1 prop 2 0.5454545 0.6521739 사례 연구: 여러 모집단의 모비율 차이에 대한 가설검정 Example 11.6 bizstatp 패키지의 BrokenMarriage는 덴마크 사회 조사국에서 수행한 성별 및 사회적 계급에 따라 이혼 또는 영구적 관계가 깨진 빈도를 측정한 데이터이다. 여성의 경우 사회적 등급(rank)에 따라 이혼 비율이 다른지 유의수준 5% 하에 가설검정 하시오. &gt; BrokenMarriage Freq gender rank broken 1 14 male I yes 2 102 male I no 3 39 male II yes 4 151 male II no 5 42 male III yes 6 292 male III no 7 79 male IV yes 8 293 male IV no 9 66 male V yes 10 261 male V no 11 12 female I yes 12 25 female I no 13 23 female II yes 14 79 female II no 15 37 female III yes 16 151 female III no 17 102 female IV yes 18 557 female IV no 19 58 female V yes 20 321 female V no Example 11.6은 다섯 개의 사회적 계급별로 여성의 이혼율이 같은지를 가설검정하는 것으로 \\(p_i\\)를 등급 \\(i\\)의 여성의 이혼율이라고 하면 귀무가설과 대립가설은 다음과 같다. 두 모집단의 경우 대립가설이 모비율이 같지 않다, 작다, 크다의 세 종류가 있지만 모집단이 3 개 이상이 되면 모비율이 서로 같지 않은 두 집단이 있다라는 한 가지 종류밖에 없다. \\[ \\begin{align} H_0: &amp; \\quad p_1 = p_2 = \\cdots = p_5 \\\\ H_1: &amp; \\quad p_i \\neq p_j \\text{인 } i, j \\text{가 있다. 단, } i, j = 1, 2, \\ldots, 5, i \\neq j. \\end{align} \\] prop.test()에 교차표를 전달하여 가설검정을 하려면 교차표의 행이 모집단을 표현하고, 열이 검정하려는 범주형 변수를 표현해야 한다. Example 11.6는 사회적 계급을 행으로, 이혼 여부를 열로 교차표를 만들면 된다. BrokenMarriage는 이미 범주별로 관측도수가 요약된 데이터이다. 이렇게 이미 요약된 데이터를 이용하여 빈도표를 만드는 방법은 7.3.2 절에서 설명한 것처럼 xtabs() 함수의 수식 좌변에 관측도수를 나타내는 열을 지정하는 것이다. 아울러 여자의 이혼률에 대해서만 가설검정하려는 것이므로, subset 인수를 사용하여 성별이 여자인 데이터로 한정하여 교차표를 만들도록 하였다. &gt; trb_femail &lt;- xtabs(Freq ~ rank + broken, data = BrokenMarriage, + subset = gender == &quot;female&quot;) &gt; trb_femail broken rank yes no I 12 25 II 23 79 III 37 151 IV 102 557 V 58 321 prop.test()를 이용하여 가설검정을 하면 다음과 같은 결과를 얻는다. 이 때 모집단이 3 개 이상이면 모비율이 서로 같지 않은 두 집단이 있다라는 한 종류의 대립가설만 있으므로 alternative 인수는 기술하지 않는다. &gt; prop.test(trb_femail) 5-sample test for equality of proportions without continuity correction data: trb_femail X-squared = 11.286, df = 4, p-value = 0.02353 alternative hypothesis: two.sided sample estimates: prop 1 prop 2 prop 3 prop 4 prop 5 0.3243243 0.2254902 0.1968085 0.1547800 0.1530343 표본 비율 \\(\\hat{p}\\)은 사회적 계급 별로 각각 0.3243243, 0.2254902, 0.1968085, 0.15478, 0.1530343이다. p-값은 0.023535로 유의수준 0.05에서 귀무가설을 기각한다. (대립가설을 채택한다.) 따라서 여성의 사회적 계급 별로 이혼율의 차이가 있다고 할 수 있다. 모집단이 세 개 이상인 경우의 모비율의 차이에 대한 가설검정에서 귀무가설이 기각되고 대립가설이 채택되면, 어느 모집단이 전체 데이터의 평균 비율보다 유의미하게 컸는지 작았는지에 대한 분석이 필요하다. 이를 분석하는 방법에 대해서는 카이제곱 검정을 사용하는 독립성 검정에서 논의하도록 한다. 사실 prop.test()도 모비율의 차이에 대한 가설검정을 카이제곱 검정으로 하기 때문에 다음처럼 chisq.test()를 사용해도 동일한 결과를 얻는다. 다만 chisq.test()는 이 검정이 모집단의 모비율에 대한 가설 검정인지 분포에 대한 독립성 검정인지 구분하지 못하므로 표본 비율에 대한 정보는 제공하지 않는다. &gt; chisq.test(trb_femail) Pearson&#39;s Chi-squared test data: trb_femail X-squared = 11.286, df = 4, p-value = 0.02353 11.2.3 Fisher의 Exact Test Example 11.7 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 학년(year)에 따라 여학생 비율에 차이가 있었는지 유의수준 5%에서 가설검정하시오. Example 11.7은 학년간 성별 차이가 있는지를 가설검정하는 것으로 각 학년의 여학생 비율을 \\(p_i\\)라고 하면 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: &amp; \\quad p_1 = p_2 = p_3 = p_4 \\\\ H_1: &amp; \\quad p_i \\neq p_j \\text{인 } i, j \\text{가 있다. 단, } i, j = 1, 2, 3, 4, i \\neq j. \\end{align} \\] Example 11.7은 학년을 각각의 모집단으로 하여 성별 비율의 차이를 검정하는 것이므로 학년이 행, 성별이 열이 되도록 교차표를 만든다. &gt; tyg &lt;- xtabs(~ year + gender, data = course) &gt; tyg gender year F M 1 0 1 2 14 18 3 3 6 4 1 2 앞에서 구해진 교차표를 prop.test()고 전달하여 가설검정을 하면 다음 결과를 얻는다. &gt; prop.test(tyg) Warning in prop.test(tyg): 카이제곱 approximation은 정확하지 않을수도 있습니다 4-sample test for equality of proportions without continuity correction data: tyg X-squared = 1.0764, df = 3, p-value = 0.7828 alternative hypothesis: two.sided sample estimates: prop 1 prop 2 prop 3 prop 4 0.0000000 0.4375000 0.3333333 0.3333333 그런데 가설검정을 해보면 결과가 정확하지 않을 수 있다는 경고가 나타난다. 여러 모집단의 모비율에 대한 가설검정은 Peason의 카이제곱 검정을 하는데 이 검정 방법은 범주형 변수를 연속형 변수로 근사하여 수행하게 된다. 그리고 한 셀의 관측도수의 기대치가 최소 5 이상이어야만 이러한 근사가 어느 정도 정확할 수 있다. 그런데 Example 11.7은 2학년을 제외하고는 다른 셀의 관측도수가 적어서 기대치가 5 미만인 셀이 많다. 이렇듯 교차표의 셀의 관측치가 적은 경우에는 Fisher의 Exact Test를 수행하는 것이 좋다. 단일 모집단의 모비율에 대해 검정할 때 이항분포를 사용하여 정확한 분포로 가설섬정을 할 수 있었던 것과 마찬가지로, Fisher의 Exact Test는 초기하 분포라는 이산형 분포를 사용하여 정확한 가설검정을 수행할 수 있다. R에서 Fisher의 Exact Test를 하는 함수fisher.test() 함수이다. prop.test() 함수와 마찬가지로 &gt; fisher.test(tyg) Fisher&#39;s Exact Test for Count Data data: tyg p-value = 0.9235 alternative hypothesis: two.sided prop.test()와 달리 표본 비율에 대한 정보는 주지 않는다. p-값은 0.9234755로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 그러므로 학년별로 성별 비율에 차이가 있었다는 통계적 증거는 없었다. 11.3 적합성 검정 지금까지는 범주형 변수에서 한 범주가 발생하는 비율에 대한 가설검정을 살펴보았다. 성별 변수에서 여학생의 비율, 학년 변수에서 2학년의 비율 등이 그 예라 할 수 있다. 이제부터는 범주형 변수에서 한 범주의 비율이 아니라 전체 범주의 분포에 대하여 가설검정하는 방법을 살펴보자. 즉, 학년 변수에서 특정 학년의 비율이 아니라 전체 학년의 분포에 대해 가설검정을 하는 것이 그 예라 할 수 있다. 적합성 검정(Goodness-of-Fit Test)은 \\(k\\) 개의 범주를 가지는 범주형 변수에 대하여 모집단에서 각 범주의 발생 비율이 특정 값인지 아닌지를 검정한다. 범주형 변수의 \\(i\\)-번째 범주의 모집단에서의 비율을 \\(p_i\\)라고 하자. 단, \\(i=1, \\ldots, k\\). \\(\\sum_{i} p_i = 1\\). 그러면 적합성 검정에서의 귀무가설은 다음과 같다. \\[ H_0: \\quad p_1 = p_{10}, \\, p_2 = p_{20}, \\, \\ldots, \\, p_k = p_{k0} \\] 대립가설 \\(H_1\\)은 ’위의 조건 중 하나 이상이 만족하지 않는다’가 된다. 모집단에서 \\(n\\)개의 표본을 임의로 추출하였을 때, \\(i\\)-번째 범주의 관측치의 수를 나타내는 확률변수를 \\(X_i\\)라고 하자. 그러면 \\(\\sum_{i=1}^{k} X_i = n\\)이고, 귀무가설이 맞다면 표본 분포는 다음과 같은 다항분포를 따른다. \\[ (X_1, X_2, ..., X_k) \\sim \\text{multinomial}(n, p_{10}, p_{20}, .... p_{k0}) \\] 표본의 크기가 \\(n\\)일 때 범주 별 관측도수 \\((X_1, X_2, ..., X_k)\\)가 다항분포를 따르면, 다음처럼 정의되는 검정통계량 \\(X^2\\)는 자유도 \\((k-1)\\)의 카이제곱 분포로 근사적으로 따른다고 알려져 있다. \\[ X^2 = \\sum_{i=1}^{k} \\frac{[X_i-E(X_i)]^2}{E(X_i)} = \\sum_{i=1}^{k} \\frac{[X_i- n \\, p_{i0}]^2}{n \\, p_{i0}}. \\] 즉, \\[ X^2 \\sim \\chi^2(k-1). \\] 그런데 이러한 근사 방법이 잘 작동하려면 각 범주의 기대 관측도수 \\(E(X_i) = n p_i\\)가 5 이상이어야 한다. 이보다 작으면 근사의 정확도가 떨어진다. 귀무가설이 맞는다면 표본의 각 범주의 실제 관측도수 \\(x_i\\)가 기대치 \\(n \\, p_i\\)와 가까워지고, 그렇지 않으면 차이가 나게 된다. 따라서 귀무가설의 조건이 성립하지 않으면 \\(X^2\\) 값이 커지게 된다. 따라서 적합성 검정은 카이제곱 분포를 이용하여 오른쪽 단측검정으로 가설검정을 수행한다. Example 11.8 3가지 색상으로 구성된 제품이 판매되고 있다. 고객이 특별히 선호하는 색상은 없고 동일한 비율로 판매된다는 가설에 대해 검정하고자 한다. 시험적으로 판매된 \\(n=90\\)개 판매 데이터를 분석해 보니, 각 색상별 판매량이 \\(x_1 = 23, x_2 = 36, x_3 = 31\\)로 집계되었다. 유의수준 5%에서 가설검정을 하시오. 세가지 색상의 고객 선호 비율을 각각 \\(p_1, p_2, p_3\\)라고 하면 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: \\quad &amp; p_1 = p_2 = p_3 = 1/3\\\\ H_1: \\quad &amp; p_i \\neq 1/3 \\, \\text{ for some } \\, i. \\end{align} \\] R에서는 chisq.test() 함수를 이용하면 적합성 검정을 한다. chisq.test(x = 범주별_관측도수, p = 범주별_비율) chisq.test(x = 범주별_관측도수, p = 범주별_비율, rescale.p, correct) x: 각 범주별 관측치 수를 나타내는 벡터 또는 빈도표 p: 적합성 검정을 할 때 사용할 귀무가설 하의 범주별 비율을 나타내는 벡터 rescale.p: p의 합이 1이 아닐 때, 1이 되도록 스케일을 조정할지를 결정하는 논리값 인수 correct: 연속성 수정을 할지를 결정하는 논리값 인수 이 외에도 카이제곱 확률분포를 사용한 가설검정이 아니라 몬테 카를로 시뮬레이션을 이용한 가설검정을 할 때 사용하는 simulation.p.value와 B 인수가 있다. 이에 대해서는 뒤에 설명을 하겠다. 다음은 Example 11.8의 카이제곱 검정 결과이다. 기본적으로 출력되는 정보뿐 아니라 상세 정보를 이용하기 위해 결과를 변수에 할당한 후 출력하였다. &gt; result &lt;- chisq.test(c(23, 36, 31), p=c(1/3, 1/3, 1/3)) &gt; result Chi-squared test for given probabilities data: c(23, 36, 31) X-squared = 2.8667, df = 2, p-value = 0.2385 위의 예에서는 p-value가 0.2385126가 나와 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) chisq.test()를 수행한 결과를 변수에 저장하면 화면에 출력되지 않은 상세한 정보를 나중에 확인할 수 있다. 어떠한 상세 정보를 제공하는지 확인하려면 names() 함수를 이용하여 변수에 저장된 요소의 이름을 출력해 본다. &gt; names(result) [1] &quot;statistic&quot; &quot;parameter&quot; &quot;p.value&quot; &quot;method&quot; &quot;data.name&quot; &quot;observed&quot; [7] &quot;expected&quot; &quot;residuals&quot; &quot;stdres&quot; chisq.test()의 결과 중에서 중요한 요소가 observed, expected, residuals, stdres이다. observed는 각 범주별 관측 개수이다. expected 는 귀무가설 하에서 각 범주별 관측 개수의 기대치이다. residuals은 \\([x_i-E(x_i)]/\\sqrt{E(x_i)}\\)의 값이다. 따라서 residual을 제곱하여 다 더하면 \\(X^2\\)가 된다. stdres는 표준화된 잔차로 \\([x_i-E(x_i) ]/SE( x_i-E(x_i) )\\)로 셀의 관측값이 커지면 정규분포에 근사된다. chisq.test()의 결과의 각 요소를 출력하려면, 출력결과$요소의 명령을 사용하면 된다. &gt; result$observed [1] 23 36 31 &gt; result$expected [1] 30 30 30 &gt; result$residuals [1] -1.2780193 1.0954451 0.1825742 &gt; result$stdres [1] -1.5652476 1.3416408 0.2236068 stdres를 살펴보면 귀무가설을 기각하게 만드는데 기여한 셀이 무엇인지 확인할 수 있다. 일반적으로 한 범주의 stdres의 절대값이 2보다 크면 그 셀의 관측치가 귀무가설 하의 기대치에서 크게 차이가 난 것으로, 3이상이면 차이가 매우 크게 난 것으로 판단한다. stdres 값이 양수이면 관측치가 귀무가설 하의 기대치에 비해 컸다는 것이며, 음수이면 관측치가 귀무가설 하의 기대치보다 작았다는 것이다. 여기서 주의할 점은 귀무가설이 맞더라도 표준화된 잔차의 절대값이 2이상일 확률은 정규분포 하에서 약 5%가 된다. 따라서 20개의 범주가 있다면 귀무가설이 맞더라도 표준화된 잔차의 절대값이 2 이상이 되는 셀이 평균적으로 1개 정도는 나타나게 된다. 따라서 귀무가설의 채택과 기각 여부는 p-값으로 판단해야지 stdres로 판단해서는 안된다. Example 11.8의 예에서는 귀무가설을 기각하지 못했고 모든 범주에 대해 stdres의 값이 \\(\\pm 2\\) 구간 안에 있으므로 각 범주별 표본의 관측 개수가 기대치를 크게 벗어나지 않았다. Example 11.9 어느 지역에서 발생하는 하루 동안의 교통사고 수 \\(Y\\)를 \\(n=50\\)일간 조사하였다. 조사한 결과 다음과 같은 결과를 얻었다. 교통사고 수 \\(Y\\)가 \\(\\lambda = 1/2\\)인 포아송 분포를 따르는지에 대해서 유의수준 5%에서 가설검정 하시오. y frequency 0 32 1 12 2 이상 6 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: \\quad &amp; Y \\sim Poisson(1/2) \\\\ H_1: \\quad &amp; Y \\text{는 Poisson(1/2) 분포를 따르지 않는다.} \\end{align} \\] 귀무가설 하의 사고가 하루에 0번, 1번, 2번 이상 일어날 확률을 다음처럼 \\(p_1, p_2, p_3\\)라고 하자. \\[p_1 = P(Y=0), \\, p_2=P(Y=1), \\, p_3 = P(Y \\ge 2).\\] 그러면 귀무가설 하의 \\(p_1, p_2, p_3\\)는 다음처럼 포아송 분포의 확률질량함수를 이용하여 구할 수 있다. &gt; lambda &lt;- 1/2 &gt; p &lt;- c(dpois(c(0, 1), lambda), ppois(1, lambda, lower.tail=F)); p [1] 0.60653066 0.30326533 0.09020401 chisq.test() 함수로 가설검정을 수행하면 다음 결과를 얻는다. &gt; result &lt;- chisq.test(c(32, 12, 6), p=p); result Warning in chisq.test(c(32, 12, 6), p = p): 카이제곱 approximation은 정확하지 않을수도 있습니다 Chi-squared test for given probabilities data: c(32, 12, 6) X-squared = 1.2444, df = 2, p-value = 0.5368 위의 예에서는 p-value가 0.5367749가 나와 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 그러므로 교통사고가 포아송 분포가 아니라는 통계적 증거는 없었다. 그러나 마지막 셀의 기대치가 5 미만이어서 가설검정에 정확성에 대한 경고가 출력되었다. &gt; result$expected [1] 30.326533 15.163266 4.510201 만약 \\(\\lambda\\)가 주어져 있지 않으면, 최우추정법(Maximum Likelihood Estimate)를 이용하여 \\(\\lambda\\)를 추정해야 하고, 이 경우 \\(\\chi^2\\) 분포의 자유도가 1 감소하게 된다. 이러한 경우에도 R을 사용하여 가설검정을 수행할 수 있는데, 이에 대한 설명은 이 교재의 범위를 넘어가므로 설명을 생략하도록 한다. 11.3.1 빈도표를 이용한 적합성 검정 Example 11.10 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 학년(year)별 수강 신청 비율이 0.05, 0.6, 0.25, 0.1이라는 귀무가설에 대하여 유의수준 5%에서 가설검정하시오. Example 11.10에서 각 학년의 수강생 비율을 \\(p_i\\)라고 하면 귀무가설은 다음과 같다. \\[ H_0: \\quad p_1 = 0.05, \\, p_2 = 0.6, \\, p_3 = 0.25, \\, p_4 = 0.1 \\] 학년별 수강생의 절대 빈도표와 상대 빈도표를 구하면 다음과 같다. &gt; ty &lt;- xtabs(~ year, data = course) &gt; ty year 1 2 3 4 1 32 9 3 &gt; proportions(ty) year 1 2 3 4 0.02222222 0.71111111 0.20000000 0.06666667 chisq.test()로 가설검정을 하면 다음의 결과를 얻는다. &gt; result &lt;- chisq.test(ty, p = c(0.05, 0.6, 0.25, 0.1)) Warning in chisq.test(ty, p = c(0.05, 0.6, 0.25, 0.1)): 카이제곱 approximation은 정확하지 않을수도 있습니다 &gt; result Chi-squared test for given probabilities data: ty X-squared = 2.5704, df = 3, p-value = 0.4627 &gt; result$expected 1 2 3 4 2.25 27.00 11.25 4.50 그러나 1학년과 4학년의 기대 관측도수가 5보다 작아서 가설검정의 정확성에 대한 경고가 출력되었다. 11.3.2 몬테 카를로 시뮬레이션을 이용한 적합도 가설검정 Example 11.10는 기대 관측도수가 5보다 작은 범주가 있으므로 카이제곱 검정의 정확도가 떨어진다. 단일모집단의 모비율 검정에서 이항분포를 사용하면 정확한 검정을 할 수 있는 것과 마찬가지로 적합도 검정을 원래의 정확한 분포인 다항분포를 사용하여 수행하면 기대 관측도수가 작더라도 정확한 가설검정을 수행할 수 있다. 그러나 다항분포를 이용하여 p-값을 계산하는 것은 매우 강도 높은 계산량을 요구한다. 그래서 다항분포의 식을 이용하여 p-값을 직접 구하기보다는 몬테 카를로 시뮬레이션을 이용하여 p-값을 구한다. \\(n\\)개의 표본을 임의로 추출하였을 때 귀무가설 하에 범주의 관측도수 \\((x_1, x_2, \\dots, x_k)\\)는 다항분포 \\(\\text{multinomial}(n, p_{10}, p_{20}, .... p_{k0})\\)를 따른다. 몬테 카를로 시뮬레이션은 다항분포를 따르는 관측도수 \\((x_1, x_2, \\dots, x_k)\\)를 B 번 시뮬레이션을 구한다. 그리고 이 B 번의 시뮬레이션 값 중에서 현재 관측된 관측도수보다 더 예외적인 결과가 나온 시뮬레이션 횟수를 구하여 p-값을 추정한다. 예를 들어 \\(B=1000\\)번 시뮬레이션 했는데, 이 중 25 번의 결과가 현재 관측된 값보다 더 예외적인 값이라면 현재 관측된 값보다 예외적인 값이 나올 확률은 \\(25 / 1000 = 2.5\\) %라고 추정한다. chisq.test() 함수가 근사적인 카이제곱 분포가 아니라 다항분포를 몬테 카를로 시뮬레이션 하여 p-값을 구하게 하려면 simulate.p.value = TRUE로 설정하면 된다. 시뮬레이션 횟수는 2,000번으로 설정되어 있다. 인수 B를 설정하면 시뮬레이션 횟수를 조정할 수 있다. &gt; result &lt;- chisq.test(ty, p = c(0.05, 0.6, 0.25, 0.1), + simulate.p.value = TRUE) &gt; result Chi-squared test for given probabilities with simulated p-value (based on 2000 replicates) data: ty X-squared = 2.5704, df = NA, p-value = 0.4518 위의 예에서는 p-value가 0.4517741가 나와 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 앞에서 근사적으로 카이제곱 분포로 p-값을 구한 결과와 큰 차이를 보이지는 않았다. 11.4 독립성 검정 독립성 검정은 어떤 두 범주형 변수가 독립인지 아닌지를 검정한다. 첫 번째 범주형 변수에 \\(R\\)개의 범주가 있고, 두 번째 범주형 변수에 \\(C\\)개의 범주가 있다고 하자. 그러면 두 범주형 변수와 관련된 교차표 또는 분할표는 \\(R \\times C\\) 행렬로 표현된다. 범주 1 2 \\(\\cdots\\) C 합계 1 \\(x_{11}\\) \\(x_{12}\\) \\(\\cdots\\) \\(x_{1C}\\) \\(r_1\\) 2 \\(x_{21}\\) \\(x_{22}\\) \\(\\cdots\\) \\(x_{2C}\\) \\(r_2\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\ddots\\) \\(\\vdots\\) \\(\\vdots\\) R \\(x_{R1}\\) \\(x_{R2}\\) \\(\\cdots\\) \\(x_{RC}\\) \\(r_R\\) 합계 \\(c_{1}\\) \\(c_{2}\\) \\(\\cdots\\) \\(c_{C}\\) \\(n\\) \\(n\\)을 전체 관측도수, \\(x_{ij}\\)를 i행-j열 셀의 관측도수라고 하자. 그리고 \\(r_i\\)와 \\(c_j\\)를 각각 i 행과 j 열의 관측도수의 합이라고 하자. 그러면 독립성 검정의 검정통계량 \\(X^2\\)은 다음과 같다. \\[ X^2 = \\sum_{i=1}^{R} \\sum_{j=1}^{C} \\frac{[x_{ij} - E(x_{ij})]^2}{E(x_{ij})} = \\sum_{i=1}^{R} \\sum_{j=1}^{C} \\frac{[(x_{ij} - r_i \\, c_j / n)]^2}{r_i \\, c_j / n} \\] 그리고 검정통계량 \\(X^2\\)는 자유도 \\((R-1) (C-1)\\)의 카이제곱 분포를 따른다. \\[ X^2 \\sim \\chi^2((R-1)(C-1)). \\] 적합성 검정과 마찬가지로 두 변수의 독립성 가정이 참이면 각 셀의 관측도수 \\(x_{ij}\\)와 귀무가설 하의 각 셀의 기대관측치 \\(r_i \\, c_j / n\\)의 차이가 크지 않고, 거짓이면 차이가 커지게 된다. 따라서 독립성 검정도 \\(X^2\\)이 예외적으로 커지면 대립가설을 받아들이므로 오른쪽 단측검정을 한다. Example 11.6에서는 사회 계급에 따라 여성의 이혼 비율에 대해 가설검정한 것이지만, 여성의 사회적 계급(rank)과 이혼 여부(broken)라는 두 변수의 독립성을 검정하는 문제로 보고 카이제곱 검정을 수행할 수도 있다. &gt; trb_femail broken rank yes no I 12 25 II 23 79 III 37 151 IV 102 557 V 58 321 &gt; result &lt;- chisq.test(trb_femail) &gt; result Pearson&#39;s Chi-squared test data: trb_femail X-squared = 11.286, df = 4, p-value = 0.02353 그런데 앞서서 p-값이 0.023535로 유의수준 0.05보다 작으므로 귀무가설이 기각된다고만 하고, 귀무가설이 기각된 이유에 대한 분석을 하지 않았다. 제대로 된 분석을 하려면 귀무가설이 기각되는 경우 어떠한 요인이 귀무가설을 기각하게 만들었는지를 살펴보아야 한다. 적합성 검정과 마찬가지로 stdres은 귀무가설이 맞다고 할 때 각 셀의 실제 관측도수가 기대 관측도수에서 얼마나 크게 벗어났는지를 알려준다. &gt; result$stdres broken rank yes no I 2.534424 -2.534424 II 1.552177 -1.552177 III 1.055350 -1.055350 IV -1.442944 1.442944 V -1.032415 1.032415 결과에서 보듯이 사회 계급 별로 이혼 여부의 차이를 만든 두드러진 요인은 사회 계급이 1등급인 여성이 전체 평균에 비해 이혼한 경우(yes)는 더 많고 이혼 하지 않은 경우(no)는 더 적었기 때문이었다. 그 다음으로 전체적인 이혼 추세에서 벗어난 계급은 2등급 여성과 4등급 여성이었다. 2등급은 1등급만큼은 아니지만 이혼 비율이 평균적인 이혼 비율보다 높았고, 4등급은 이혼 비율이 평균보다 낮았다. Example 11.11 bizstatp에 포함된 Arthritis 데이터에서 치료의 종류(Treatment)와 증상 개선 효과(Improved)가 서로 독립인지 유의수준 5% 하에 가설검정하시오. Arthritis 데이터에서 치료의 종류와 개선 효과에 대해 교차표를 구하면 다음과 같다. &gt; tti &lt;- xtabs(~ Treatment + Improved, data = Arthritis) &gt; tti Improved Treatment None Some Marked Placebo 29 7 7 Treated 13 7 21 chisq.test() 함수를 이용하여 독립성 검정을 하면 다음과 같은 결과를 얻는다. &gt; result &lt;- chisq.test(tti) &gt; result Pearson&#39;s Chi-squared test data: tti X-squared = 13.055, df = 2, p-value = 0.001463 위의 예에서는 p-value가 0.0014626가 나와 유의수준 0.05에서 귀무가설을 기각한다. (대립가설을 채택한다.) 즉, 치료법이 플라시보인지 진짜 치료인지에 따라 증상 개선에 차이가 있었다. 그러면 귀무가설을 기각시킨 주요 요인이 무엇인지 확인해 보자. 아래 결과를 보면, 플라시보 치료군에서는 귀무가설이 맞다고 할 때 기대되는 관측도수에 비해 증상 개선 없음(None)이 훨씬 많았고, 증상의 확실한 개선(Marked)은 훨씬 적었다. 반면 진짜 치료는 귀무가설이 맞다고 할 때 기대되는 관측도수에 비해 증상 개선 없음(None)이 훨씬 적었고, 증상의 확실한 개선(Marked)은 훨씬 많았다. &gt; result$stdres Improved Treatment None Some Marked Placebo 3.27419655 -0.09761768 -3.39563632 Treated -3.27419655 0.09761768 3.39563632 Example 11.12 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 학년(year) 분포와 분반(class)의 분포는 서로 독립이라는 귀무가설에 대하여 유의수준 5%에서 가설검정하시오. 교차표와 카이제곱 검정을 이용하여 가설검정을 하면 다음 결과를 얻는다. &gt; tcy &lt;- xtabs(~ class + year, data = course) &gt; tcy year class 1 2 3 4 1 0 18 3 1 2 1 14 6 2 &gt; result &lt;- chisq.test(tcy) Warning in chisq.test(tcy): 카이제곱 approximation은 정확하지 않을수도 있습니다 &gt; result Pearson&#39;s Chi-squared test data: tcy X-squared = 2.8125, df = 3, p-value = 0.4214 &gt; result$expected year class 1 2 3 4 1 0.4888889 15.64444 4.4 1.466667 2 0.5111111 16.35556 4.6 1.533333 2학년을 제외한 모든 셀의 기대 관측도수가 5 이하여서 카이제곱 분포를 사용한 가설검정이 적절하지 않기 때문에 경고 메시지가 출력되었다. 독립성 검정에서 셀의 기대 관측도수가 5 이하여서 경고가 나오는 경우에는 fisher.test() 함수를 이용하여 독립성에 대하여 Fisher의 Exact Test를 수행하는 것이 좋다. &gt; fisher.test(tcy) Fisher&#39;s Exact Test for Count Data data: tcy p-value = 0.4427 alternative hypothesis: two.sided 그런데 fisher.test()도 셀이 너무 많아지면 p-값 계산 시간이 많이 소요된다. 이러한 경우는 chisq.test()와 마찬가지 방식으로 몬테 카를로 시뮬레이션으로 p-값을 계산할 수 있다. Example 11.12는 그러한 경우는 아니지만 예제 삼아 몬테 카를로 시뮬레이션을 이용하여 p-값을 구해보자. 정확한 분포로 구한 결과와 시뮬레이션 결과에 큰 차이가 없음을 볼 수 있다. &gt; fisher.test(tcy, simulate.p.value = TRUE) Fisher&#39;s Exact Test for Count Data with simulated p-value (based on 2000 replicates) data: tcy p-value = 0.4553 alternative hypothesis: two.sided 몬테 카틀로 시뮬레이션으로 독립성 검정을 하려면 chisq.test() 함수를 사용하여도 된다. 두 함수 모두 동일한 방식으로 시뮬레이션을 하여 p-값을 구한다. 다만 시뮬레이션 결과가 매번 다르므로 p-값은 실행할 때마다 다를 수 있다. 다음은 동일한 시뮬레이션 값이 나오도록 시드를 동일하게 한 후 두 함수의 결과를 비교한 것이다. 시뮬레이션 결과가 동일하면 p-값이 동일함을 확인할 수 있다. &gt; set.seed(12) &gt; chisq.test(tcy, simulate.p.value = TRUE) Pearson&#39;s Chi-squared test with simulated p-value (based on 2000 replicates) data: tcy X-squared = 2.8125, df = NA, p-value = 0.4598 &gt; set.seed(12) &gt; fisher.test(tcy, simulate.p.value = TRUE) Fisher&#39;s Exact Test for Count Data with simulated p-value (based on 2000 replicates) data: tcy p-value = 0.4598 alternative hypothesis: two.sided 11.5 범주형 변수의 가설검정에 대한 정리 그림 11.1은 지금까지 살펴본 범주형 변수에 대한 여러 가지 가설검정의 차이점을 도식화하여 분류한 것이다. 범주형 변수의 가설검정은 크게 범주 하나의 비율에 대한 것인지 아니면 모든 범주에 대한 분포에 대한 것인지에 따라 나뉘어진다. 그리고 한 범주의 비율에 대한 검정은 하나의 모집단에서의 모비율에 대한 검정인지, 여러 모집단의 모비율의 차이에 대한 것인지에 따라 다시 나뉘어진다. 분포 검정도 마찬가지로 하나의 범주형 변수의 분포에 대한 것인지, 두 범주형 변수의 분포의 관계를 검정하는 것인지에 따라 적합성 검정과 독립성 검정으로 나뉘어진다. 각각의 검정은 범주에 대한 기대 관측도수가 충분히 크면-주로 5 이상이면-표준정규분포나 카이제곱 분포 등의 연속형 분포로 근사하여 가설검정을 하고, 기대 관측도수가 충분히 크지 않으면 이항분포, 다항분포, 초기하 분포 등의 이산형 분포를 이용하여 가설검정을 수행한다. 이산형 분포를 이용하는 경우 계산량이 많이 필요할 수 있다. 이 경우 분포를 직접 계산하기 보다는 몬테 카를로 시뮬레이션으로 p-값을 구한다. Figure 11.1: 범주형 변수의 가설검정의 종류와 사용해야 할 R 함수 이미 요인으로 변경된 범주형 변수는 relevel() 함수를 사용하여 첫 번째 범주를 더 쉽게 지정할 수 있다. 관심 있는 독자는 도움말을 참조하기 바란다.↩︎ "],["ch-numericTest.html", "Chapter 12 수치형 변수에 대한 가설검정 12.1 단일 모집단에서의 모평균에 대한 검정 12.2 두 모집단에서의 모평균 차이에 대한 검정 12.3 셋 이상의 모집단에서의 모평균 차이에 대한 검정 12.4 정규성을 따르지 않을 때의 가설검정", " Chapter 12 수치형 변수에 대한 가설검정 수치형 변수에 대한 가설검정은 수치형 변수가 정규분포를 따르는 경우와 그렇지 않은 경우에 따라 가설검정 방법에서 차이가 있다. 그러므로 수치형 변수에 대한 가설검정을 수행하기 앞서 수치형 변수가 정규분포를 따르는지에 대해 검토해 보아야 한다. 수치형 변수의 정규성을 검토하는 방법은 8.1.2.3 절에서 설명한 Q-Q 그림을 그려보는 것과 shapiro.test()를 이용하여 정규성을 만족하는지에 대해 가설검정을 하는 것이 있다. 만약 수치형 변수가 정규성을 만족하지 않으면 분포를 가정하지 않는 비모수적 방법으로 가설검정을 수행하여야 한다. 본 장에서는 다양한 가설검정 상황에서 수치형 변수가 정규분포를 따른다는 가정하고 모수적으로 가설검정하는 방법만을 다루도록 한다. 12.1 단일 모집단에서의 모평균에 대한 검정 단일 모집단의 모평균 \\(\\mu\\)에 대한 검정은 모집단의 분포가 평균 \\(\\mu\\)와 분산 \\(\\sigma^2\\)를 갖는 정규분포 \\(N(\\mu, \\sigma^2)\\)을 따른다고 가정한다. 모집단에 추출한 \\(n\\) 개의 데이터로 이루어진 표본을 \\((x_1, x_2, \\ldots, x_n)\\)이라고 하자. 그러면 표본평균 \\(\\bar{x}\\)와 표본분산 \\(s^2\\)은 각각 다음과 같이 정의된다. \\[\\begin{align} \\bar{x} =&amp; \\frac{1}{n} \\sum_{i=1}^{n} x_i \\\\ s^2 =&amp; \\frac{1}{n-1} \\sum_{i=1}^{n} \\left( x_i- \\bar{x} \\right)^2 \\end{align}\\] 단일 모집단의 모평균의 검정에서는 귀무가설은 ‘모평균 \\(\\mu\\)가 특정값 \\(\\mu_0\\)이다’로 수립되고, 대립가설은 ’모평균 \\(\\mu\\)가 \\(\\mu_0\\)가 아니다’, ‘더 크다’, ‘더 작다’ 중 하나로 수립된다. 단일 모집단의 모평균의 가설검정은 모분산이 알려져 있는 경우와 그렇지 않은 경우에 따라 검정통계량과 검정통계량의 분포가 달라진다. 모분산이 알려져 있는 경우에는 정규분포로 모분산이 알려져 있지 않은 경우에는 t-분포로 가설검정을 한다. 대부분의 경우 모평균을 모르기 때문에 가설검정을 하는 경우에는 모분산에 대한 정보도 알려져 있지 않은 경우가 많다. 그렇기 때문에 여기서는 모분산 \\(\\sigma^2\\)이 알려져 있지 않은 경우만을 다루도록 한다. 모분산 \\(\\sigma^2\\)이 알려져 있지 않은 경우에 다음과 같이 정의되는 검정통계량 \\(T\\)는 자유도(degree of freedom)가 \\((n-1)\\)인 t-분포를 따른다. \\[ T = \\frac{\\bar{x} - \\mu_0}{ s / \\sqrt{n}} \\, \\sim \\, t(n-1) \\] 대립가설에 따라 유의수준 \\(\\alpha\\)에 대해 기각역은 다음 표와 같다. 왜냐하면 대립가설이 \\(\\mu &lt; \\mu_0\\)이면, 대립가설이 채택되는 경우는 표본평균 \\(\\bar{x}\\)가 \\(\\mu_0\\)보다 예외적으로 작게 나올 때이므로 기각역은 분포의 왼쪽에 놓이게 된다. 반대로 대립가설이 \\(\\mu &gt; \\mu_0\\)이면, 대립가설이 채택되는 경우는 표본평균 \\(\\bar{x}\\)가 \\(\\mu_0\\)보다 예외적으로 작게 나올 때이므로 기각역은 분포의 오른쪽에 놓이게 된다. 대립가설이 \\(\\mu \\neq \\mu_0\\)이면, 표본평균이 귀무가설의 평균보다 배우 크거나 작게 나오는 두 영역이 기각역으로 설정된다. 귀무가설 (\\(H_0\\)) 대립가설 (\\(H_1\\)) 기각역 \\(\\mu = \\mu_0\\) \\(\\mu \\neq \\mu_0\\) \\(T \\ge t_{\\alpha/2}(n-1), T \\le -t_{\\alpha/2}(n-1)\\) \\(\\mu = \\mu_0 \\, (\\mu \\ge \\mu_0)\\) \\(\\mu &lt; \\mu_0\\) \\(T \\le -t_{\\alpha}(n-1)\\) \\(\\mu = \\mu_0 \\, (\\mu \\le \\mu_0)\\) \\(\\mu &gt; \\mu_0\\) \\(T \\ge t_{\\alpha}(n-1)\\) R의 기본 패키지인 stat 패키지의 t.test() 함수는 t-분포를 사용하여 모평균에 대한 가설검정을 수행한다. 다음은 t.test() 함수를 이용하여 단일 모집단의 모평균에 대하여 가설검정하는 문법이다. t.test(x = 표본, mu = 귀무가설_모평균, alternative = &quot;대립가설_종류&quot;) t.test(x = 표본, mu = 귀무가설_모평균, alternative = &quot;대립가설_종류&quot;, conf.level = 신뢰수준) # 신뢰구간의 신뢰수준을 조정 t.test() 함수의 인수로는 stat 패키지의 가설검정 함수들에 공통적으로 사용되는 인수와 모평균 검정과 관련된 인수가 있다. t.test()의 다음 인수는 단일 모집단의 모평균 검정과 관련된 인수이다. x: 가설검정을 위한 표본 데이터 mu: 귀무가설의 모평균 값 뒤에서 살펴보겠지만 두 모집단에 대한 모평균에 대한 가설검정에 사용되는 paired와 var.equal 등의 인수들도 있다. 다음의 두 인수는 범주형 변수의 가설검정에서 설명했던 stat 패키지의 가설 검정 함수들에 공통적으로 사용되는 인수이다. alternative: 대립가설의 형식. \\(\\mu \\neq \\mu_0\\) 형식이면 \"two.sided\"로, \\(\\mu &lt; \\mu_0\\) 형식이면 \"less\"로, \\(\\mu &gt; \\mu_0\\) 형식이면 \"greater\"로 값을 입력한다. conf.level: 대부분의 가설검정 함수가 신뢰구간도 함께 알려주는데 이 인수는 신뢰구간의 신뢰수준을 지정한다. 기본값은 0.95로 95% 신뢰구간을 알려준다. Example 12.1 2010년도 초등학교 4학년의 평균 키가 142cm이었고 표준편차는 알려져 있지 않다. 2020년에 8명의 초등학교 4학년의 키를 측정하여 다음과 같은 데이터를 얻었다. 142.5 138.9 139.6 148.2 152.9 129.6 143.5 151.3 10년 동안 초등학교 4학년 학생들의 평균 키가 더 커졌다고 할 수 있는가? 유의수준 5%에서 가설검정하시오. Example 12.1의 가설검정은 키가 커졌는지를 검정하고자 하는 것이므로 \\(\\mu\\)를 2020년의 초등학교 4학년의 평균 키라고 하면 귀무가설과 대립가설은 다음과 같이 설정한다. \\[ \\begin{align} H_0: &amp; \\quad \\mu = 142 \\\\ H_1: &amp; \\quad \\mu &gt; 142 \\end{align} \\] 위의 가설을 t-분포로 가설검정하려면 초등학생의 키가 정규분포를 따르는지 먼저 확인해 보아야 한다. &gt; x &lt;- c(142.5, 138.9, 139.6, 148.2, 152.9, 129.6, 143.5, 151.3) &gt; library(ggplot2) &gt; ggplot(NULL, aes(sample = x)) + + geom_qq() + geom_qq_line(color = &quot;red&quot;) &gt; shapiro.test(x) Shapiro-Wilk normality test data: x W = 0.95489, p-value = 0.7603 shapiro.test()로 분포의 정규성에 대하여 가설검정을 한 결과 p-값이 크게 나왔으므로 분포가 정규분포를 따른다는 귀무가설을 채택한다. 분포의 정규성을 가정할 수 있으므로 t.test()을 사용하여 모평균에 대하여 가설검정을 하면 다음과 같은 결과를 얻는다. &gt; t.test(x, mu = 142, alternative = &quot;greater&quot;) One Sample t-test data: x t = 0.49012, df = 7, p-value = 0.3195 alternative hypothesis: true mean is greater than 142 95 percent confidence interval: 138.239 Inf sample estimates: mean of x 143.3125 t-검정을 통해 우리는 다음 사실을 알 수 있다. 표본 평균 \\(\\bar{x}\\)는 143.3125이다. p-값은 0.3195181로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 12.2 두 모집단에서의 모평균 차이에 대한 검정 두 모집단의 모평균에 대한 검정은 두 모집단의 분포가 각각 정규분포 \\(N(\\mu_1, \\sigma_1^2)\\)과 \\(N(\\mu_2, \\sigma_2^2)\\)을 따른다고 가정한다. 가설검정을 위해 각 모집단에서 \\(n_1\\) 개와 \\(n_2\\) 개의 크기의 표본 \\((x_{1,1}, x_{1,2}, \\ldots, x_{1,n_1})\\)과 \\((x_{2,1}, x_{2,2}, \\ldots, x_{2,n_2})\\)을 추출하였다고 하자. 그러면 두 표본의 표본평균 \\(\\bar{x}_1\\)과 \\(\\bar{x}_2\\), 표본분산 \\(s_1^2\\)과 \\(s_2^2\\)은 각각 다음과 같이 정의된다. \\[\\begin{align} \\bar{x}_i =&amp; \\frac{1}{n_i} \\sum_{j=1}^{n_i} x_{i, j} \\\\ s_i^2 =&amp; \\frac{1}{n_i - 1} \\sum_{j=1}^{n_i} \\left( x_{i, j} - \\bar{x}_i \\right)^2 \\end{align}\\] 단, \\(i=1,2\\). 두 모집단의 모평균 차이에 대한 가설검정에서는 귀무가설은 ‘모평균의 차이 \\((\\mu_1 - \\mu_2)\\)가 어떤 값 \\(\\delta_0\\)이다’로 수립되고, 대립가설은 ’모평균의 차이가 \\(\\delta_0\\)가 아니다’, ‘더 큰다’, ‘더 작다’ 중 하나로 수립된다. 그런데 두 모집단의 모평균 차이에 대한 가설검정은 두 모집단의 모분산이 알려져 있는 경우와 그렇지 않은 경우에 따라 검정통계량과 검정통계량의 분포가 달라진다. 모분산이 알려져 있는 경우에는 정규분포로, 모분산이 알려져 있지 않은 경우에는 t-분포를 이용하여 가설검정을 한다. 일반적으로 모분산은 알려져 있지 않은 경우가 많으므로 여기서는 모분산이 알려져 있지 않은 경우만을 다루기로 한다. 12.2.1 등분산이 가정되는 경우의 모평균 차이 검정 모분산이 알려져 있지 않은 경우에도 모분산에 대한 다음의 두 가정에 따라 검정통계량이 달라진다. 먼저 모분산은 알려져 있지 않지만 두 모집단의 분산이 같다(\\(\\sigma_1^2 = \\sigma_2^2\\))고 가정되는 경우이다. 이 경우에는 두 모집단의 공통분산 \\(\\sigma^2\\)에 대한 합동추정량 \\(s_p^2\\)를 다음과 같이 정의할 수 있다. \\[ s_p^2 = \\frac{(n_1 -1 ) \\, s_1^2 + (n_2 -1) \\, s_2^2}{n_1 + n_2 - 2}. \\] 그러면 다음과 같은 검정통계량 \\(T\\)는 자유도가 \\((n_1 + n_2 -2)\\) 인 t-분포를 따른다. \\[ T = \\frac{(\\bar{x}_1 - \\bar{x}_2) - (\\mu_1 - \\mu_2)}{ s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} \\, \\sim \\, t(n_1 + n_2 -2) \\] 대립가설에 따라 유의수준 \\(\\alpha\\)에 대해 기각역은 다음 표와 같다. 귀무가설 (\\(H_0\\)) 대립가설 (\\(H_1\\)) 기각역 \\(\\mu_1 - \\mu_2 = \\delta_0\\) \\(\\mu_1 - \\mu_2 \\neq \\delta_0\\) \\(T \\ge t_{\\alpha/2}(n_1 + n_2-2), T \\le -t_{\\alpha/2}(n_1 + n_2-2)\\) \\(\\mu_1 - \\mu_2 = \\delta_0\\) \\(\\mu_1 - \\mu_2 &lt; \\delta_0\\) \\(T \\le -t_{\\alpha}(n_1 + n_2-2)\\) \\(\\mu_1 - \\mu_2 = \\delta_0\\) \\(\\mu_1 - \\mu_2 &gt; \\delta_0\\) \\(T \\ge t_{\\alpha}(n_1 + n_2-2)\\) R에서 두 모집단의 분산이 같다고 가정될 때의 모평균의 차이 검정은 t.test() 함수를 이용한 다음과 같은 문법으로 수행된다. t.test(표본1, 표본2, alternative = &quot;대립가설 종류&quot;, var.equal = TRUE) 일반적으로 두 모집단이 등분산인지 아닌지에 대한 판단은 이론적인 근거나 과거의 연구결과를 참조하여 결정하기도 하지만, 표본의 분산을 사용하여 두 모집단의 등분산성에 대하여 직접 가설검정을 할 수도 있다. 두 모집단에서 추출된 표본의 크기가 각각 \\(n_1\\)과 \\(n_2\\)이고 표본분산이 \\(s_1^2\\)과 \\(s_2^2\\)라고 하면, 두 모집단의 분산이 같다는 귀무가설이 참이라면 다음과 같은 \\(F\\) 검정통계량은 자유도가 \\((n_1 -1, n_2 -1)\\)인 F 분포를 따른다. \\[ F = \\frac{S_1^2}{S_2^2} \\sim F(n_1-1, n_2-1). \\] R에서는 var.test() 함수를 사용하여 다음처럼 두 모집단의 등분산성을 검정한다. var.test(표본1, 표본2) Example 12.2 2010년도와 2020년도에 각각 초등학교 4학년 8명에 대하여 키를 측정하였다. 초등학교 4학년 키의 분산은 알려져 있지 않다. 2010년과 2020년 초동학교 4학년 학생의 평균키에 차이가 있는지를 유의수준 5%에서 가설검정하시오. 2010년 139.4 139.8 137.2 149.2 151.2 131.8 141.5 152.3 2020년 142.5 138.9 139.6 148.2 152.9 129.6 143.5 151.3 Example 12.2의 가설검정에서 2010년도 키의 평균을 \\(\\mu_1\\), 2020년도 키의 평균을 \\(\\mu_2\\)라고 할 때 평균 키가 같은지 다른지를 가설검정하는 것이므로 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: &amp; \\quad \\mu_1 - \\mu_2 = 0 \\\\ H_1: &amp; \\quad \\mu_1 - \\mu_2 \\neq 0 \\end{align} \\] 위의 가설을 t-분포로 가설검정하려면 초등학생의 키가 정규분포를 따르는지 먼저 확인해 보아야 한다. &gt; x2010 &lt;- c(139.4, 139.8, 137.2, 149.2, 151.2, 131.8, 141.5, 152.3) &gt; x2020 &lt;- c(142.5, 138.9, 139.6, 148.2, 152.9, 129.6, 143.5, 151.3) &gt; shapiro.test(x2010) Shapiro-Wilk normality test data: x2010 W = 0.92354, p-value = 0.4592 &gt; shapiro.test(x2020) Shapiro-Wilk normality test data: x2020 W = 0.95489, p-value = 0.7603 shapiro.test()로 분포의 정규성에 대하여 가설검정을 한 결과 p-값이 크게 나왔으므로 두 수치형 변수 모두 정규분포를 따른다는 귀무가설을 채택한다. 두 모집단의 모평균을 가설검정하려면 등분산을 가정할 수 있는지 아닌지를 확인해 보아야 한다. 수치형 변수가 정규분포를 따를 때 두 집단의 분산의 동일성 여부는 F-검정으로 알아본다. R에서는 var.test() 함수가 두 모집단의 분산의 차이를 가설검정해 준다. 검정 결과 p-값이 크게 나와 두 집단의 분산이 같다는 귀무가설이 채택된다. &gt; var.test(x2010, x2020) F test to compare two variances data: x2010 and x2020 F = 0.93723, num df = 7, denom df = 7, p-value = 0.934 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.1876365 4.6813660 sample estimates: ratio of variances 0.9372274 분포의 정규성과 등분산성을 가정할 수 있으므로 t.test()을 사용하여 모평균 차이에 대하여 다음과 같이 가설검정을 할 수 있다. t.test()에서 두 모집단의 모평균 차이를 가설검정할 때는 var.equal 인수를 사용하여 분산을 같다고 가정하는지 아닌지를 설정할 수 있다. &gt; t.test(x2010, x2020, alternative = &quot;two.sided&quot;, var.equal = TRUE) Two Sample t-test data: x2010 and x2020 t = -0.1375, df = 14, p-value = 0.8926 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -8.506629 7.481629 sample estimates: mean of x mean of y 142.8000 143.3125 t-검정을 통해 우리는 다음 사실을 알 수 있다. 표본 평균 \\(\\bar{x}_1\\)과 \\(\\bar{x}_2\\)는 각각 142.8, 143.3125이다. p-값은 0.8925925로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 12.2.2 등분산이 가정될 수 없는 경우의 모평균의 차이 검정 모분산이 알려져 있지 않고 두 모집단의 분산이 서로 다르다(\\(\\sigma_1^2 \\neq \\sigma_2^2\\))고 가정되는 경우에는 검정통계량 \\(T\\)는 다음과 같이 정의되고 자유도가 \\(\\nu\\)인 t-분포를 근사적으로 따른다. \\[ T = \\frac{(\\bar{x}_1 - \\bar{x}_2) - (\\mu_1 - \\mu_2)}{ \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\, \\sim \\, t(\\nu) \\] 단, \\[ \\nu = \\frac{\\left( s_1^2 / n_1 + s_2^2 / n_2 \\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1 -1} + \\frac{(s_2^2/n_2)^2}{n_2 - 1}}. \\] 대립가설에 따라 유의수준 \\(\\alpha\\)에 대해 기각역은 다음 표와 같다. 귀무가설 (\\(H_0\\)) 대립가설 (\\(H_1\\)) 기각역 \\(\\mu_1 - \\mu_2 = \\delta_0\\) \\(\\mu_1 - \\mu_2 \\neq \\delta_0\\) \\(T \\ge t_{\\alpha/2}(\\nu), T \\le -t_{\\alpha/2}(\\nu)\\) \\(\\mu_1 - \\mu_2 = \\delta_0\\) \\(\\mu_1 - \\mu_2 &lt; \\delta_0\\) \\(T \\le -t_{\\alpha}(\\nu)\\) \\(\\mu_1 - \\mu_2 = \\delta_0\\) \\(\\mu_1 - \\mu_2 &gt; \\delta_0\\) \\(T \\ge t_{\\alpha}(\\nu)\\) R에서 두 모집단의 분산이 다르다고 가정될 때의 모평균의 차이 검정은 t.test() 함수를 이용한 다음과 같은 문법으로 수행된다. t.test(표본1, 표본2, alternative = &quot;대립가설 종류&quot;, var.equal = FALSE) Example 12.3 기존 공정과 새 공정에서 생산되는 제품의 지름을 측정하여 아래와 같은 데이터를 얻었다. 기존 공정보다 새 공정에서 생산한 제품의 지름이 작다고 할 수 있는지 유의수준 5%로 검정하시오. 기존공정 5.2 4.7 5.0 5.3 4.9 4.5 5.6 5.0 5.1 4.8 5.5 4.1 새 공정 4.6 4.4 4.6 4.7 4.5 4.3 4.1 4.7 4.5 4.2 Example 12.3의 가설검정에서 기존 공정 제품의 평균 지름을 \\(\\mu_1\\), 새 공정의 평균 지름을 \\(\\mu_2\\)라고 할 때 새 공정의 평균 지름이 더 작다는 것을 가설검정하는 것이므로 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: &amp; \\quad \\mu_1 - \\mu_2 = 0 \\\\ H_1: &amp; \\quad \\mu_1 - \\mu_2 &gt; 0 \\end{align} \\] 위의 가설을 t-분포로 가설검정하려면 제품 지름이 정규분포를 따르는지 먼저 확인해 보아야 한다. &gt; x_old &lt;- c(5.2, 4.7, 5.0, 5.3, 4.9, 4.5, 5.6, 5.0, 5.1, 4.8, 5.5, 4.1) &gt; x_new &lt;- c(4.6, 4.4, 4.6, 4.7, 4.5, 4.3, 4.1, 4.7, 4.5, 4.2) &gt; shapiro.test(x_old) Shapiro-Wilk normality test data: x_old W = 0.97539, p-value = 0.9583 &gt; shapiro.test(x_new) Shapiro-Wilk normality test data: x_new W = 0.92994, p-value = 0.4473 shapiro.test()로 분포의 정규성에 대하여 가설검정을 한 결과 p-값이 크게 나왔으므로 분포가 정규분포를 따른다는 귀무가설을 채택한다. 두 모집단의 모평균을 가설검정하려면 등분산을 가정할 수 있는지 아닌지를 확인해 보아야 한다. 검정 결과 p-값이 0.05보다도 작게 나와 두 집단의 분산이 같다는 귀무가설이 유의수준 5%에서 기각된다. &gt; var.test(x_old, x_new) F test to compare two variances data: x_old and x_new F = 4.1388, num df = 11, denom df = 9, p-value = 0.04186 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 1.057968 14.849772 sample estimates: ratio of variances 4.138849 분포의 정규성은 가정되지만 등분산은 가정할 수 없으므로 t.test()을 사용하여 모평균 차이에 대하여 다음과 같이 가설검정을 하는데, var.equal = FALSE로 가설검정하여야 한다. 그리고 대립가설은 “greater”로 설정된다. &gt; t.test(x_old, x_new, alternative = &quot;greater&quot;, var.equal = FALSE) Welch Two Sample t-test data: x_old and x_new t = 3.7379, df = 16.598, p-value = 0.0008483 alternative hypothesis: true difference in means is greater than 0 95 percent confidence interval: 0.2749873 Inf sample estimates: mean of x mean of y 4.975 4.460 t-검정을 통해 우리는 다음 사실을 알 수 있다. 표본 평균 \\(\\bar{x}_1\\)과 \\(\\bar{x}_2\\)는 각각 4.975, 4.46이다. p-값은 0.0008483222로 유의수준 0.05에서 귀무가설을 기각한다. (대립가설을 채택한다.) 즉, 가설검정 결과 신규공정의 지름이 더 작아졌다는 유의미한 통계적 증거가 있다고 판단한다. 12.2.3 데이터프레임에서 모평균 차이 검정 Example 12.4 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 이 과목은 최종점수(score)의 평균에 성별(gender) 차이가 있는지에 대해 유의수준 5%에서 가설검정하시오. Example 12.4처럼 모평군의 차이에 대한 가설 검정은 데이터프레임의 수치형 변수(score)를 범주형 변수(gender)의 값에 따라 두 집단으로 나누어 평균의 차이를 검정하는 경우가 많다. 이러한 경우 다음처럼 4.1.4 절에서 배운 벡터의 필터을 사용하여 수치형 변수를 범주형 변수의 값에 따라 두 벡터로 나누어 지금까지 사용한 t.test()와 var.test()를 이용하여 가설검정을 수행할 수 있다. &gt; library(bizstatp) &gt; score_F &lt;- course$score[course$gender == &quot;F&quot;] &gt; score_M &lt;- course$score[course$gender == &quot;M&quot;] &gt; var.test(score_F, score_M) F test to compare two variances data: score_F and score_M F = 0.36437, num df = 17, denom df = 26, p-value = 0.0343 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.1560132 0.9246962 sample estimates: ratio of variances 0.3643656 &gt; t.test(score_F, score_M, alternative = &quot;two.sided&quot;) Welch Two Sample t-test data: score_F and score_M t = 0.20677, df = 42.686, p-value = 0.8372 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -7.518363 9.235770 sample estimates: mean of x mean of y 71.97611 71.11741 그러나 매번 범주의 값에 따라 수치형 변수의 데이터를 나누는 일은 번거로운 일이기 때문에 var.test()와 t.test() 모두 첫번째 인수로 수식을 사용하여 범주형 변수의 값에 따라 수치형 변수의 값을 나누어 가설검정하도록 지정할 수 있다. 수식의 왼편에는 검정할 수치형 변수가, 오른편에는 수치형 변수를 나눌 범주형 변수가 지정된다. 그리고 data 인수에 사용할 데이터 프레임이 지정된다. var.test(수치형_변수 ~ 범주형_변수, data = 데이터) t.test(수치형_변수 ~ 범주형_변수, data = 데이터, alternative, var.equal) 성별로 최종점수(score)에 차이가 있었는지를 가설검정하기 위해서는 먼저 성별 최종점수가 각각 정규분포를 따르는지 확인해 보자. 다음 문법을 사용하면 수치형 변수를 범주형 변수로 나누어 정규성 검정을 수행할 수 있다. tapply(데이터$수치형_변수, 데이터$범주형_변수, shaprio.test) 다음은 성별 최종점수의 정규성을 검정한 결과이다. &gt; tapply(course$score, course$gender, shapiro.test) $F Shapiro-Wilk normality test data: X[[i]] W = 0.93595, p-value = 0.2467 $M Shapiro-Wilk normality test data: X[[i]] W = 0.87635, p-value = 0.004011 남학생의 최종점수가 정규분포를 따르지 않는 것으로 나온다. 중간과 기말고사를 안 본 학생 때문에 발생한 문제일 수 있으므로 이 학생을 제외하고 정규성 검정을 다시해 보자. &gt; course_omitted &lt;- na.omit(course) &gt; tapply(course_omitted$score, course_omitted$gender, shapiro.test) $F Shapiro-Wilk normality test data: X[[i]] W = 0.93595, p-value = 0.2467 $M Shapiro-Wilk normality test data: X[[i]] W = 0.94984, p-value = 0.23 예외적인 데이터를 제외하니 남자와 여자 모두 최종점수의 정규성 가정을 기각할 만한 통계적 증거를 가지고 있지 않다. 성별 최종점수의 평균 차이를 가설검정을 하려면 등분산을 가정할 수 있는지를 확인해 보아야 한다. &gt; var.test(score ~ gender, data = course_omitted) F test to compare two variances data: score by gender F = 0.69443, num df = 17, denom df = 25, p-value = 0.4409 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.2942656 1.7696899 sample estimates: ratio of variances 0.6944266 등분산 검정 결과에서 p-값이 큰 값이 나왔으므로 남녀 간의 최종성적의 분산은 같다는 귀무가설을 채택한다. 따라서 등분산으로 남녀의 최종성적의 평균의 차이에 대해 가설검정을 한다. &gt; t.test(score ~ gender, data = course_omitted, + alternative = &quot;two.sided&quot;, var.equal = TRUE) Two Sample t-test data: score by gender t = -0.41353, df = 42, p-value = 0.6813 alternative hypothesis: true difference in means between group F and group M is not equal to 0 95 percent confidence interval: -8.772914 5.788982 sample estimates: mean in group F mean in group M 71.97611 73.46808 t-검정을 통해 우리는 다음 사실을 알 수 있다. 표본 평균 \\(\\bar{x}_1\\)과 \\(\\bar{x}_2\\)는 각각 71.9761111, 73.4680769이다. p-값은 0.6813205로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 즉, 남녀의 최종성적의 평균 차이가 있다는 유의미한 통계적 증거를 찾지 못했다. 마찬가지로 다음은 분반별 최종성적의 차이에 대해 가설검정한 결과이다. 분반으로 최종점수를 나누어도 정규성과 등분산성이 만족되었고, 최종점수의 평균에 대해 통계적으로 유의미한 차이는 없었다. &gt; tapply(course_omitted$score, course_omitted$class, shapiro.test) $`1` Shapiro-Wilk normality test data: X[[i]] W = 0.94064, p-value = 0.2041 $`2` Shapiro-Wilk normality test data: X[[i]] W = 0.95717, p-value = 0.4343 &gt; var.test(score ~ class, data = course_omitted) F test to compare two variances data: score by class F = 1.0552, num df = 21, denom df = 21, p-value = 0.9032 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.4381008 2.5415554 sample estimates: ratio of variances 1.055205 &gt; t.test(score ~ class, data = course_omitted, + alternative = &quot;two.sided&quot;, var.equal = TRUE) Two Sample t-test data: score by class t = -1.7005, df = 42, p-value = 0.09643 alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0 95 percent confidence interval: -12.786513 1.091967 sample estimates: mean in group 1 mean in group 2 69.93409 75.78136 12.2.4 짝진 표본에서의 모평균 차이에 대한 가설검정 지금까지 설명한 두 모집단의 모평균 차이에 대한 가설검정은 두 표본이 서로 다른 모집단에서 독립적으로 추출되는 경우에 사용하는 가설검정이다. 그런데 어떤 경우에는 두 표본이 서로 대응되어 추출되는 것이 더 좋은 경우가 있다. 이렇게 두 표본이 서로 짝지어져 추출된 표본을 짝진 표본 또는 대응 표본이라고 한다. 두 모집단의 모평균 차이에 대한 가설검정을 할 때, 두 모집단에서 추출된 표본은 동질적이어야만 정확한 가설검정을 할 수 있다. 예를 들어 두 종류의 타이어의 마모성 차이에 대한 가설검정을 하기위해 실험에 참여한 자동차를 두 그룹으로 나누어 각기 다른 종류의 타이어를 장착한 후 동일한 거리를 운행한 뒤 타이어가 마모된 정도의 평균을 측정하였다고 하자. 이러한 실험이 정확하기 위해서는 두 표본 사이에 자동차의 종류가 고르게 분포되어야 할 것이다. 예를 들어 한 표본에는 중형차가 매우 많이 분포되어 있고 다른 한 표본에는 경차가 많이 분포되어 있다면 자동차의 중량의 차이 때문에 타이어 종류에 따른 마모성을 정확히 판단하기 어렵다. 또한 운전자의 운전 습관이 두 표본 사이에서 차이가 크다면 이 또한 타이어 마모 차이에 대한 공정한 결과를 얻기 힘들다. 이러한 문제점을 해결하는 방법 중 하나가 찍진 표본을 구성하여 실험을 수행하는 것이다. 실험단위를 동질적인 쌍으로 묶어 실험을 하면 실험에서 확인하고자 하는 요인을 제외한 다른 요인들은 동일하게 통제되므로 실험하고자 하는 요인에 의한 평균의 차이만 검정할 수 있다. 예를 들어 두 종류의 타이어를 동일한 차의 오른쪽과 왼쪽에 장착하여 마모 정도를 테스트하면, 자동차의 종류나 운전자의 운전습관이 모두 동일하므로 타이어 종류에 따른 마모 효과만 측정할 수 있다. 이 경우 타이어가 차의 오른쪽과 왼쪽 어디에 장착되는가가 마모에 영향을 미칠수도 있으므로 동일한 종류의 타이어가 왼쪽과 오른쪽에 균등하게 분배되도록 실험을 설계하여야 한다. 정규모집단으로부터 \\(n\\) 개의 짝지은 데이터 \\((x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\)을 표본으로 관측하였다고 하자. 짝진 표본의 관측치의 차이를 \\(d_i = x_i - y_i\\) 라고 할 때 두 모집단의 모평균 \\(\\mu_x\\)와 \\(\\mu_y\\)의 차이 \\(\\mu_d = \\mu_x - \\mu_y\\)에 대한 검정은 다음과 같이 수행한다. 귀무가설은 ‘두 모집단의 모평균의 차이 \\(\\mu_d\\) 가 특정 값 \\(\\delta_0\\)이다’이고 대립가설은’\\(\\mu_d\\)가 특정 값 \\(\\delta_0\\)가 아니다’, ‘더 크다’, ’더 작다’이다. 짝진 표본의 관측값의 차이에 대한 평균 \\(\\bar{d}\\)와 분산 \\(s_d^2\\)이 다음과 같이 정의한다. \\[\\begin{align} \\bar{d} =&amp; \\frac{1}{n} \\sum_{i=1}^{n} d_i \\\\ s_d^2 =&amp; \\frac{1}{n-1} \\sum_{i=1}^{n} \\left( d_i- \\bar{d} \\right)^2 \\end{align}\\] 그러면 짝진 표본의 모평균 차이에 대한 검정통계량 \\(T\\)는 다음과 같고 자유도가 \\((n-1)\\)인 t-분포를 따른다. \\[ T = \\frac{\\bar{d} - \\delta_0}{ s_d / \\sqrt{n}} \\, \\sim \\, t(n-1) \\] 대립가설에 따라 유의수준 \\(\\alpha\\)에 대해 기각역은 다음 표와 같다. 귀무가설 (\\(H_0\\)) 대립가설 (\\(H_1\\)) 기각역 \\(\\mu_d = \\delta_0\\) \\(\\mu_d \\neq \\delta_0\\) \\(T \\ge t_{\\alpha/2}(n-1), T \\le -t_{\\alpha/2}(n-1)\\) \\(\\mu_d = \\delta_0 \\, (\\mu_d \\ge \\delta_0)\\) \\(\\mu_d &lt; \\delta_0\\) \\(T \\le -t_{\\alpha}(n-1)\\) \\(\\mu_d = \\delta_0 \\, (\\mu_d \\le \\delta_0)\\) \\(\\mu_d &gt; \\delta_0\\) \\(T \\ge t_{\\alpha}(n-1)\\) R에서 짝진 표본의 검정은 t.test()를 사용하여 다음과 같이 수행한다. 표본1과 표본2는 서로 짝진 순서대로 기술되어야 한다. t.test(짝진_표본1, 짝진_표본2, alternative = &quot;대립가설_종류&quot;, paired = TRUE) Example 12.5 10명의 학생에게 영어 학습을 시킨 후 학습 전후의 영어 시험 점수가 다음과 같이 주어졌다. 유의수준 5% 하에 학습 후에 점수가 향상되었는지를 가설검정하시오. 학생번호 1 2 3 4 5 6 7 8 9 10 ---------------------------------------------- 학습 전 74 66 64 60 58 72 67 78 77 79 학습 후 89 80 76 65 54 66 84 76 86 79 Example 12.5는 동일한 학생에 대하여 학습 전과 후의 점수를 측정한 것이므로 짝진 표본 문제이다. \\(\\mu_x\\)를 학습 전 시험 점수의 평균, \\(\\mu_y\\)를 학습 후 시험 점수의 평균이라고 하고, \\(\\mu_d = \\mu_x - \\mu_y\\)라고 하자. 학습의 효과가 있는가를 검정하는 것이므로 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: &amp; \\quad \\mu_d = 0 \\\\ H_1: &amp; \\quad \\mu_d &lt; 0 \\end{align} \\] 위의 가설을 t-분포로 가설검정하려면 점수의 차이가 정규분포를 따르는지 먼저 확인해 보아야 한다. 이 때 주의할 점은 짝진 표본의 정규성은 표본 각각에 대해서 검정하는 것이 아니라 짝진 표본의 차이 \\((d_1, d_2, \\dots, d_n)\\)이 정규분포를 따르는지를 검정한다. shapito.test(짝진_표본1 - 짝진_표본2) 다음은 학습 전과 학습 후의 점수 차이의 정규성에 대하여 가설검정한 예이다. &gt; x_before &lt;- c(74, 66, 64, 60, 58, 72, 67, 78, 77, 79) &gt; x_after &lt;- c(89, 80, 76, 65, 54, 66, 84, 76, 86, 79) &gt; d &lt;- x_before - x_after &gt; shapiro.test(d) Shapiro-Wilk normality test data: d W = 0.91571, p-value = 0.3226 shapiro.test()로 분포의 정규성에 대하여 가설검정을 한 결과 p-값이 크게 나왔으므로 분포가 정규분포를 따른다는 귀무가설을 채택한다. 분포의 정규성을 가정할 수 있으므로 t.test()을 사용하여 짝진 표본의 모평균 차이에 대한 가설검정을 수행할 수 있다. t.test() 함수에서 paired = TRUE로 설정하면 된다. &gt; t.test(x_before, x_after, alternative = &quot;less&quot;, paired = TRUE) Paired t-test data: x_before and x_after t = -2.2224, df = 9, p-value = 0.02668 alternative hypothesis: true mean difference is less than 0 95 percent confidence interval: -Inf -1.050972 sample estimates: mean difference -6 t-검정을 통해 우리는 다음 사실을 알 수 있다. 표본에서 학습 전 후의 차이의 평균 \\(\\bar{d}\\) -6이다. p-값은 0.0266777로 유의수준 0.05에서 귀무가설을 기각한다. (대립가설을 채택한다.) 즉, 학습 전후로 6점 정도의 평균 상승이 있었고, 이러한 상승은 유의수준 5%에서 ’학습이 성적 향상에 통계적으로 유의미한 효과가 있었다’고 판단 될 수 있다. Example 12.6 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 중간고사와 기말고사의 난이도에 차이가 있어서 점수 차이가 발생하였는지를 확인하고자 한다. 이 과목의 중간고사 점수에 비해 기말고사의 평균 점수에 차이가 있는지에 대해 유의수준 5%에서 가설검정하시오. Example 12.6는 동일한 학생에 대하여 중간과 기말고사 점수를 측정한 것이므로 짝진 표본 문제이다. \\(\\mu_x\\)를 중간고사 점수의 평균, \\(\\mu_y\\)를 기말고사 점수의 평균이라고 하고, \\(\\mu_d = \\mu_x - \\mu_y\\)라고 하자. 점수에 변화가 있었는지를 검정하는 것이므로 귀무가설과 대립가설은 다음과 같다. \\[ \\begin{align} H_0: &amp; \\quad \\mu_d = 0 \\\\ H_1: &amp; \\quad \\mu_d \\neq 0 \\end{align} \\] 위의 가설을 t-분포로 가설검정하려면 점수의 차이가 정규분포를 따르는지 먼저 확인해 보아야 한다. &gt; d &lt;- course$mid - course$final &gt; shapiro.test(d) Shapiro-Wilk normality test data: d W = 0.98863, p-value = 0.9378 shapiro.test()로 분포의 정규성에 대하여 가설검정을 한 결과 p-값이 크게 나왔으므로 분포가 정규분포를 따른다는 귀무가설을 채택한다. 분포의 정규성을 가정할 수 있으므로 t.test()을 사용하여 짝진 표본의 모평균 차이에 대하여 가설검정을 할 수 있다. t.test() 함수에서 paired = TRUE로 설정하면 된다. &gt; t.test(course$mid, course$final, alternative = &quot;two.sided&quot;, paired = TRUE) Paired t-test data: course$mid and course$final t = -0.90422, df = 43, p-value = 0.3709 alternative hypothesis: true mean difference is not equal to 0 95 percent confidence interval: -4.992287 1.901378 sample estimates: mean difference -1.545455 t-검정을 통해 우리는 다음 사실을 알 수 있다. 표본에서 점수 차이의 평균 \\(\\bar{d}\\) -1.5454545이다. p-값은 0.3709153로 유의수준 0.05에서 귀무가설을 채택한다. (대립가설을 기각한다.) 즉, 기말 고사에서 1.5454545점 정도의 평균 상승이 있었으나, 이러한 상승이 통계적으로 유의미하지는 않은 것으로 판단된다. 12.3 셋 이상의 모집단에서의 모평균 차이에 대한 검정 모집단이 세 개 이상이 되면 모평균의 차이에 대한 가설검정을 t-분포를 이용하여 더 이상 할 수 없게 된다. 이 경우에는 13 장에서 설명하는 분산분석을 사용하여 가설검정을 수행하여야 한다. 분산분석은 여러 모집단의 모평균의 차이 검정뿐 아니라 더 넓은 분야에서 사용되기 때문에 별도의 장에서 설명하도록 한다. 12.4 정규성을 따르지 않을 때의 가설검정 지금까지 수치 변수가 정규 분포를 따른다고 가정하여 t-분포를 사용하여 가설검정을 수행하였다. 만약 검정하고자 하는 수치 변수가 정규 분포를 따르지 않으면 어떻게 해야 할까? 정규성을 따르지 않을 때 사용할 수 있는 방법은 크게 다음 네 가지 방법을 고려할 수 있다. 수치 변수를 정규성을 만족하도록 변환한다. 8.1.3 절에서 설명하였듯이, 수치 변수가 왼쪽으로 치우친(오른쪽으로 꼬리가 긴) 분포일 경우 로그나 제곱근 변환 등으로 정규 분포에 가까운 분포로 변환할 수 있는 경우가 많다. 이러한 방법의 단점은 변환환 수치 변수의 의미를 해석하기 어려울 수 있다는 것이다. 수치 변수를 구간으로 나누어 범주형 변수로 변환하여 범주형 변수에 사용되는 가설검정을 사용한다. 이러한 방법의 문제점은 수치 변수를 적절하게 나누는 방법을 결정하는 것이 쉽지 않고, 범주화로 인해 수치 변수의 정보가 손실된다는 것이다. 비모수적 가설검정(nonparametric tests)을 수행한다. 비모수적 가설검정에서는 수치 변수의 분포를 가정하지 않고 수치 변수의 순위를 사용하여 검정을 수행한다. 분포에 대한 가정을 하지 않는다는 점은 장점이지만, 그렇기 때문에 평균 대신 순서 통계량인 중위수로 가설검정을 한다. 순열검정법(permutation tests)을 사용하여 가설검정을 한다. 순열검정은 두 개 이상의 표본을 결합하여 무작위로 재표본(resampling)을 반복하여 가설검정을 수행한다. 분포를 가정하지 않고 평균의 차이 등 다양한 검정통계량에 대해 가설검정을 할 수 있다는 것이 장점이나, 반복하여 표본을 추출하는 작업이 필요하기 때문에 계산 시간이 오래 걸리는 단점이 있다. 그러나 컴퓨터의 계산 속도가 매우 빨라졌기 때문에 현재 자주 사용되는 방법이다. 본 절에서는 세 번째와 네 번째 방법에 대하여 설명을 한다. 12.4.1 두 모집단의 중위수에 대한 비모수적 가설검정 두 모집단의 중위수에 대한 가설검정은 Wilconx Rank-Sum 검정을 사용한다. Wilcox Rank-Sum 검정은 Mann-Whitney U 검정이라고도 알려져 있는데, 두 모집단에 추출된 표본을 섞어서 순위를 구한 후, 순위합으로 두 집단의 중위수가 같은지 다른지를 가설검정한다. Wilcox Rank-Sum 검정의 기본 가정은 두 모집단의 분포의 모양은 같은데, 위치(location)은 서로 다를 수 있다고 가정한다. Wilcox Rank-Sum 검정에서는 두 모집단의 위치(location)은 동일하다는 귀무가설를 검정한다. Example 12.7 course 데이터는 어떤 과목의 수강생에 대한 정보이다. 이 과목의 숙제점수(hw)의 중위수가 성별(gender) 차이가 있는지에 대해 유의수준 5%에서 가설검정하시오. Example 12.7에 대한 가설검정을 하기 위해 먼저 정규성을 확인해 보자. &gt; tapply(course_omitted$hw, course_omitted$gender, shapiro.test) $F Shapiro-Wilk normality test data: X[[i]] W = 0.86236, p-value = 0.01335 $M Shapiro-Wilk normality test data: X[[i]] W = 0.92743, p-value = 0.06732 shapiro.test() 결과에서 보듯이 남녀 숙제점수는 정규 분포와는 어느 정도 차이를 보인다. 다음은 남녀 숙제점수의 중위수를 계산하고, 분포를 상자 그래프로 그린 결과이다. 남녀의 숙제점수의 중위수가 매우 근접해 있는 것을 확인할 수 있다. &gt; tapply(course_omitted$hw, course_omitted$gender, median) F M 84.8 84.3 &gt; ggplot(course_omitted, aes(x = gender, y = hw)) + + geom_boxplot() 두 모집단의 중위수의 동일성에 대하여 가설검정을 하려면 stat 패키지의 wilcox.test() 함수를 사용한다. 이 함수의 인수는 t.test()와 거의 동일하다. &gt; wilcox.test(hw ~ gender, data = course_omitted, + alternative = &quot;two.sided&quot;) Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): tie가 있어 정확한 p값을 계산할 수 없습니다 Wilcoxon rank sum test with continuity correction data: hw by gender W = 253, p-value = 0.6583 alternative hypothesis: true location shift is not equal to 0 Wilcox Rank-Sum 검정은 순위로 검정을 하기 때문에 동률이 있는 경우 계산의 정확도가 떨어지므로 경고를 출력하였다. 가설검정의 결과에서 보듯이 p-값이 5%보다 크므로 두 집단의 중위수의 차이가 없었다는 귀무가설을 받아들인다. 12.4.2 짝진표본에 대한 검정 12.4.3 순열 검정 "],["ch-anova.html", "Chapter 13 분산 분석 13.1 일원분류 분산 분석 13.2 이원분류 분산 분석 13.3 공분산 분석", " Chapter 13 분산 분석 앞 장에서 두 모집단의 모평균의 차이에 대한 가설검정을 하는 방법을 보았다. 만약 모집단이 세 개 이상으로 늘어나면, t-분포를 사용하여 더 이상 가설검정을 할 수 없다. 이 경우에는 Fisher에 의해 개발된 분산 분석(ANalysis Of VAriance; ANOVA) 기법을 사용하여 검정을 수행하여야 한다. 분산 분석은 역사적으로 실험계획과 밀접한 관계를 가지며 발전해 왔다. 특히 농업 분야의 실험과 연관되어 발전하였다. 비료에 의해 얻어지는 어떤 농작물의 산출물의 양을 측정하는 실험을 고려해 보자. 이 실험을 위해 다른 조건을 같게 한 후, A, B, C라는 서로 다른 비료를 사용하여 산출물의 양을 실험하였다고 하자. 이러한 실험계획에서 비료의 종류를 요인(factors)이라고 한다. 서로 다른 비료 A, B, C를 수준(levels) 또는 처리(treatments)라고 한다. 실험의 최종 결과인 산출물의 양을 반응변수(response variables)라고 한다. 수준에 따라 반응변수의 평균에 차이가 나는 것을 요인의 효과(effects)라고 한다. 분산 분석은 ’요인의 효과는 없다’라는 귀무가설과 ’요인의 효과가 있다’라는 대립가설에 대한 가설검정을 수행한다. 분산 분석에서 수준이 2개인 경우는 앞선 본 두 모집단의 모평균의 차이 검정으로 효과의 차이를 분석할 수 있으나, 수준이 3 개 이상이면 분산 분석을 통해 가설검정을 수행하여야 한다. 분산 분석은 요인이 한 개인 경우뿐 아니라 두 개인 경우에도 분석이 가능하다. 예를 들어 앞의 실험에서 비료의 효과만 보는 것이 아니라 토양의 특성에 따라 비료의 효과가 달라지는지를 보고자 한다면, 비료라는 한 요인과 토질이라는 또 다른 요인이 농작물의 산출에 주는 효과를 분석하게 된다. 요인이 하나인 분산 분석을 일원분류 분산 분석(one-way ANOVA)이라 하고, 요인이 두 개인 분산 분석을 이원분류 분산 분석(two-way ANOVA)라고 한다. 13.1 일원분류 분산 분석 13.1.1 개념 수준이 \\(I\\)개인 요인으로 실험을 한다고 하자. 예를 들어 앞의 비료라는 요인은 수준이 A, B, C이므로, \\(I=3\\)인 요인이 된다. 각 수준을 수준 \\(i\\)라고 할 때, 수준 \\(i\\)에 대해 \\(n_i\\) 번만큼 실험을 했다고 하자. 단, \\(i=1, 2, \\ldots, I\\). 그리고 \\(y_{ik}\\)를 수준 \\(i\\)에 대해서 \\(k\\) 번째 실험을 했을 때의 반응변수의 값이라고 하면, 일원분류 분산 분석은 다음과 같은 모형을 가정한다. \\[ y_{ik} = \\mu_i + \\varepsilon_{ik} = \\mu + \\alpha_i + \\varepsilon_{ik} \\] 단, \\(\\mu_i\\)는 수준 \\(i\\)에서의 반응변수의 평균, \\(\\mu\\)는 전체 모평균, \\(\\alpha_i = \\mu_i - \\mu\\)는 수준 \\(i\\)의 효과이다. 그리고 오차항 독립이고 동일한 \\(\\varepsilon_{ik} \\sim N(0, \\sigma^2)\\) 분포를 따른다고 가정한다. 즉, 모든 수준에서 오차항은 평균이 0이고 분산이 같은 i.i.d. 정규분포를 따른다. 일원분류 분산 분석의 귀무가설은 요인의 효과가 없다는 것으로 다음과 같이 표현할 수 있다. \\[ H_0: \\quad \\mu_1 = \\mu_2 = \\cdots = \\mu_I \\quad \\] 또는 \\[ H_0: \\quad \\alpha_1 = \\alpha_2 = \\cdots = \\alpha_I = 0 \\] 대립가설은 위의 등식 중 하나 이상이 성립하지 않는다는 것이다. ANOVA의 가설검정은 전체 평균을 중심으로 데이터가 변동하는 이유를 요인에 의해 발생하는 분산과 무작위 오차에 의한 분산으로 분할하여 분석을 한다. (그렇기 때문에 분산 분석이라는 이름이 붙게 되었다.) 표본 데이터의 전체 평균과 각 수준의 평균을 다음처럼 정의하자. \\[\\begin{align} \\bar{y} =&amp; \\frac{\\sum_{i=1}^{I} \\sum_{k=1}^{n_i} y_{ik}}{n} \\\\ \\bar{y}_{i.} =&amp; \\frac{\\sum_{k=1}^{n_i} y_{ik}}{n_i} \\end{align}\\] 단, \\(n = \\sum_{i=1}^{I} n_i\\). 그러면 표본의 전체 평균 \\(\\bar{y}\\)와 각 데이터의 편차의 제곱은 다음처럼 분해된다. \\[\\begin{eqnarray} \\sum_{i=1}^{I} \\sum_{k=1}^{n_i} (y_{ik} - \\bar{y})^2 &amp;=&amp; \\sum_{i=1}^{I} (\\bar{y}_{i.} - \\bar{y})^2 &amp;+&amp; \\sum_{i=1}^{I} \\sum_{k=1}^{n_i} (y_{ik} - \\bar{y}_{i.})^2 \\\\ TSS &amp;=&amp; SST &amp;+&amp; SSE \\end{eqnarray}\\] 전체 평균에서 데이터의 변동을 TSS(total sum of squares)라고 하고, 전체 평균에서 수준의 평균의 변동을 SST(sum of squares for treatment), 수준의 평균에서 데이터의 변동을 SSE(sum of squares for residual)라고 한다. 일원분류 분산 분석에서의 검정통계량 \\(F\\)는 다음과 같이 정의되고, \\(F\\)는 자유도가 \\((I-1)\\)과 \\((n-I)\\)인 F-분포를 따른다. \\[ F = \\frac{MST}{MSE} = \\frac{SST / (I-1)}{ SSE / (n-I)} \\sim F(I-1, n-I) \\] 귀무가설이 맞지 않으면 요인의 효과에 의해 SST가 커지므로 가설검정은 오른쪽 단측검정을 하게 된다. 일원분류 분산 분석의 결과는 다음과 같은 분산 분석표로 보통 요약된다. 변동 원인 자유도 제곱합 평균제곱합 F-통계량 요인 \\(I-1\\) SST MST F 오차 \\(n-I\\) SSE MSE 13.1.2 aov() 함수 R에서 ANOVA 분석을 수행하는 함수는 aov() 함수이다. 참고로 R에는 anova() 함수도 있는데 이 함수는 회귀 모형 등이 적합된 후 모형들 사이의 분산 분석을 수행할 때 이용된다. aov() 함수는 첫번째 인수로 ANOVA 모형을 나타내는 수식을, 두번째 인수로 사용할 데이터를 입력받는다. 일원분류 분산 분석은 반응변수를 나타내는 열이 y, 요인을 나타내는 열이 f라고 하면 다음 형식으로 수식이 입력된다. aov(y ~ f, data) 요인이 둘 이상인 이원분류 분산 분석이나 다른 수치형 변수의 효과를 고려하여 분산 분석을 하는 공분산 분석의 경우 수식의 표현이 좀 더 복잡해 진다. 이에 대해서는 각각의 모형을 다룰 때 설명하도록 한다. 이 장에서는 R에서 분산 분석을 하는 방법을 설명하기 위해 bizstatp 패키지의 course 데이터를 사용할 것이다. 그런데 course 데이터에서 중간과 기말고사를 보지 않은 학생 정보가 있다. 우리는 이 학생의 정보를 제거한 course_omitted 데이터를 만들어 앞으로 이 데이터를 주로 분석에 사용할 것이다. &gt; library(bizstatp) &gt; course_omitted &lt;- na.omit(course) Example 13.1 course_omitted 데이터는 어떤 과목의 수강생에 대한 정보이다. 이 과목의 최종 점수의 평균이 학년별로 차이가 있었는지에 대해 유의수준 5%에서 가설검정하시오. Example 13.1는 2, 3, 4 학년의 최종 점수 평균의 차이를 검정하는 문제이다. 3개 이상의 모집단의 평균을 비교해야 하므로 분산 분석을 수행해야 한다. \\(\\mu_i\\)를 \\(i\\)-학년의 최종 점수의 평균이라고 하자. 평균 점수에 차이가 있었는지를 검정하는 것이므로 귀무가설은 다음과 같다. \\[ \\begin{align} H_0: &amp; \\quad \\mu_2 = \\mu_3 = \\mu_4 \\\\ \\end{align} \\] 위의 가설을 ANOVA로 가설검정하려면 먼저 학년별 최종 점수가 동일한 분산의 정규분포를 따르는지 확인해 보아야 한다. 그런데 일반적으로 각 수준별로 정규성을 검정하는 작업은 번거롭기 때문에 ANOVA 분석을 한 후 잔차(residuals)가 동일한 분산의 정규분포를 따르는지 확인하는 것이 좋다. 현재 year 열은 순서형 범주로 입력되어 있다. ANOVA 분석을 위해 순서형 볌주를 다음처럼 명목형 범주로 변경을 한다. &gt; course_omitted$year &lt;- factor(course_omitted$year, ordered = F) 다음은 각 학년의 최종점수가 동일한 분산의 정규분포를 따른다는 가정 하에 aov()을 사용하여 분산 분석을 수행한 결과이다. aov() 함수는 기본적으로 요인과 잔차에 대한 제곱합과 자유도만 출력한다. &gt; result &lt;- aov(score ~ year, data = course_omitted) &gt; result Call: aov(formula = score ~ year, data = course_omitted) Terms: year Residuals Sum of Squares 286.022 5552.534 Deg. of Freedom 2 41 Residual standard error: 11.63734 Estimated effects may be unbalanced 분산 분석 결과에서 분산 분석표를 출력하려면 summary() 함수 또는 anova()를 사용하여 분산 분석 결과를 출력해 보아야 한다. &gt; summary(result) Df Sum Sq Mean Sq F value Pr(&gt;F) year 2 286 143.0 1.056 0.357 Residuals 41 5553 135.4 &gt; anova(result) Analysis of Variance Table Response: score Df Sum Sq Mean Sq F value Pr(&gt;F) year 2 286.0 143.01 1.056 0.3571 Residuals 41 5552.5 135.43 p-값이 0.3571148로 유의수준 0.05이므로 귀무가설을 채택한다. (대립가설을 기각한다.) 즉, 학년별 성적의 차이가 있었다는 통계적 증거는 찾지 못하였다. 아울러 aov() 함수의 결과는 여러 하위 요소를 가지고 있다. 이 요소 중 coefficients를 확인하면 각 수준별 평균을 확인할 수 있다. &gt; result$coefficients (Intercept) year3 year4 71.447813 3.958854 8.802188 (Intercept)라고 표현한 항이 year 열의 기준이 되는 첫번째 수준의 평균이다. 현재 2학년이 첫번째 수준으로 정의되어 있으므로 2학년의 최종점수의 평균이다. year3과 year4는 기준이 되는 2학년 평균에서 3학년과 4학년 학생의 평균의 차이를 나타낸다. 따라서 3학년과 4학년 학생의 평균은 각각 75.4066667와 80.25이다. 전체 평균에서 각 수준의 평균의 차이 \\(\\alpha_i\\)를 확인하려면 model.tables() 함수를 사용한다. 각 수준의 평균과 전체 평균의 차이와 아울러 데이터의 수가 몇개 였는지를 알려준다. &gt; model.tables(result) Tables of effects year 2 3 4 -1.41 2.549 7.392 rep 32.00 9.000 3.000 그런데 앞서 설명한 바와 같이 분산 분석은 각 수준에서의 오차의 분포에 대해 정규성과 등분산성을 가정한다. 이러한 가정이 성립하는지를 시각적으로 확인하는 한 방법은, plot() 함수를 사용하여 잔차 그래프를 그리고, 잔차에 대해 Q-Q 그림을 그려보는 것이다. plot() 함수의 첫 번째 그림은 각 수준의 평균 대비 잔차의 그래프를 보여준다. 현재 2학년의 평균이 가장 낮고 학년이 올라갈수록 평균이 커지고 있으므로, 가로축을 기준으로 2, 3, 4학년 학생의 잔차를 보여준다. 전체적으로 잔차가 0을 기준으로 대칭적으로 분포하고 있으나, 4학년의 잔차가 2, 3학년의 잔차보다 퍼진 정도가 줄어들고 있는데, 이러한 현상이 데이터가 줄어들어 발생한 우연적인 현상인지, 아니면 등분산을 가정하기 어렵다는 통계적 증거인지 가설검정해 볼 필요가 있다. plot() 함수의 두 번째 그림은 모든 수준의 잔차를 이론적인 정규분포와 대비하여 Q-Q 그림을 그린 결과이다. 전체적으로 정규분포를 잘 따르고 있지만 양 꼬리로 갈수록 이론적인 정규분포에 비해 더 중앙 쪽으로 몰리는 경향을 보인다. plot() 함수의 세 번째 그림은 수준 별로 표준화된 잔차의 절대값에 제곱근을 취한 값의 분포를 보여준다. 등분산일수록 평균선을 나타내는 빨간 선이 직선의 형태를 취한다. &gt; plot(result) 잔차의 정규성을 확인하기 위해서 aov() 함수의 결과에서 residuals를 뽑아서 정규성에 대해 가설검정을 해보았다. p-값이 크게 나와서 잔차의 정규성을 기각하는 통계적 증거를 찾지 못했음을 알 수 있다. &gt; shapiro.test(result$residuals) Shapiro-Wilk normality test data: result$residuals W = 0.96798, p-value = 0.2564 등분산성을 가설검정할 때 요인의 수준이 2 개인 경우에는 두 모집단의 분산의 차이 검정을 F-분포를 사용하여 수행할 수 있다. 이 경우에는 var.test() 함수를 이용하여 가설검정을 수행하였다. 그러나 요인의 수준이 3 개 이상인 경우에는 bartlet.test()을 사용한다. 역시 p-값이 크게 나와서 등분산 가정을 배척해야 할 통계적 증거를 찾지 못했다. &gt; bartlett.test(score ~ year, data = course_omitted) Bartlett test of homogeneity of variances data: score by year Bartlett&#39;s K-squared = 1.2141, df = 2, p-value = 0.545 13.1.3 다중 비교 Example 13.2 multcomp 패키지의 cholesterol 데이터는 50 명의 환자에게 5개의 콜레스테롤 감소 약을 처방한 후 그 효과를 측정한 데이터이다. 처방에 따라 콜레스테롤 감소에 차이가 있었는지에 대해 유의수준 5%에서 가설검정하시오. Example 13.2를 가설검정하기 위해서는 multcomp 패키지에 대한 설치와 적재가 필요하다. &gt; install.packages(&quot;multcomp&quot;) &gt; library(multcomp) &gt; summary(cholesterol) trt response 1time :10 Min. : 2.304 2times:10 1st Qu.: 8.409 4times:10 Median :12.605 drugD :10 Mean :12.738 drugE :10 3rd Qu.:17.519 Max. :27.244 실험 요인인 trt의 세 수준은 같은 약을 20mg씩 하루에 한 번, 10mg씩 하루에 두 번, 5mg씩 하루에 네 번 투약한 것이고, 다른 두 수준은 이 약과 경쟁하고 있는 콜레스테롤 약 D와 E를 투여한 것이다. 각 수준 별로 콜레스테롤 감소량(response)의 평균과 상자 그림을 그리면 다음과 같다 &gt; aggregate(response ~ trt, data = cholesterol, mean) trt response 1 1time 5.78197 2 2times 9.22497 3 4times 12.37478 4 drugD 15.36117 5 drugE 20.94752 &gt; ggplot(cholesterol, aes(x = trt, y = response)) + + geom_boxplot(notch = T) 결과에서 자주 투여할수록 효과가 좋았으며, 약 D와 E의 효과가 더 좋은 것을 볼 수 있다. 과연 이러한 차이가 통계적으로 차이가 있는지 확인해 보자. &gt; result &lt;- aov(response ~ trt, data = cholesterol) &gt; anova(result) Analysis of Variance Table Response: response Df Sum Sq Mean Sq F value Pr(&gt;F) trt 4 1351.37 337.84 32.433 9.819e-13 *** Residuals 45 468.75 10.42 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 p-값은 9.8185163^{-13}로 유의수준 0.05에서 귀무가설을 기각한다. (대립가설을 채택한다.) 즉, 약물 처리에 따라 콜레스테롤 감소에 차이가 있었다. 위 가설검정이 가정하고 있는 정규성과 등분산성을 확인해 보자. &gt; plot(result, which=1:3) 전체적으로 모든 수준에서 잔차가 고르게 분포되어 있고 Q-Q 그림에서도 정규분포에 가깝게 나와 정규성과 등분산성을 만족할 것으로 보인다. 실제 그런지 가설검정을 해보자. 두 검정 모두에서 p-값이 크게 나와 정규성과 등분산성 가정을 기각하지 못했으므로, 앞선 ANOVA 분석의 가정이 만족된다고 판단된다. &gt; shapiro.test(result$residuals) Shapiro-Wilk normality test data: result$residuals W = 0.98864, p-value = 0.9094 &gt; bartlett.test(response ~ trt, data = cholesterol) Bartlett test of homogeneity of variances data: response by trt Bartlett&#39;s K-squared = 0.57975, df = 4, p-value = 0.9653 그런데 ANOVA 분석을 통해 평균이 같다는 귀무가설이 기각되면, 어는 수준 간의 차이에 의해 귀무가설이 기각되었는지 살펴보아야 한다. 이를 살펴보는 방법 중 하나가 가능한 모든 두 수준 간에 평균의 차이가 있었는지를 가설검정해 보는 것이다. 이는 두 모집단 간의 모평균 비교와 같아진다. 다만 수준이 많은 경우 단순히 두 수준 간의 평균의 차이를 가설검정하는 것은 여러 개의 가설을 동시적으로 검정하는 것이 되어서 기각역 또는 p-값의 조정이 필요하다. R의 기본 기능에 포함되어 있는 TukeyHSD() 함수는 이러한 수준별 쌍 비교를 수행해 준다. &gt; TukeyHSD(result) Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = response ~ trt, data = cholesterol) $trt diff lwr upr p adj 2times-1time 3.44300 -0.6582817 7.544282 0.1380949 4times-1time 6.59281 2.4915283 10.694092 0.0003542 drugD-1time 9.57920 5.4779183 13.680482 0.0000003 drugE-1time 15.16555 11.0642683 19.266832 0.0000000 4times-2times 3.14981 -0.9514717 7.251092 0.2050382 drugD-2times 6.13620 2.0349183 10.237482 0.0009611 drugE-2times 11.72255 7.6212683 15.823832 0.0000000 drugD-4times 2.98639 -1.1148917 7.087672 0.2512446 drugE-4times 8.57274 4.4714583 12.674022 0.0000037 drugE-drugD 5.58635 1.4850683 9.687632 0.0030633 위의 결과에서 유의수준 0.05에서 평균에 차이가 없었던 수준의 쌍은 2times-1time, 4times-2times, drugD-4times였다. 그 외에는 두 수준 간에 통계적으로 유의미한 차이가 발생하였다. plot() 함수를 이용하면 다중 비교에 대한 95% 신뢰구간을 그려볼 수 있다. 신뢰구간이 0을 포함하고 있는 비교 쌍은 유의수준 5%에서 차이가 유의미하지 않은 수준 쌍을 의미한다. 0에서 멀리 떨어져서 신뢰구간이 생성된 쌍은 두 처리 간에 효과의 차이가 매우 큰 쌍을 의미한다. &gt; par(las=2, mar=c(5, 8, 4, 2)) &gt; plot(TukeyHSD(result)) 만약 첫번째 수준과 그 외의 다른 수준과의 차이를 비교하고 싶으면 Dunnett 방법을 사용하여 다중 비교를 하면 된다. Dunnett 방식으로 다중 비교를 하려면 일반적인 선형 가설검정을 해주는 함수인 glht() 함수를 사용하여 linfct = mcp(요인 = \"Dunnett\")으로 다중 비교를 수행한다. 결과에서 1times는 2times를 제외한 다른 모든 수준과 평균에서 유의미한 차이가 발생하였음을 확인할 수 있다. &gt; dunnett &lt;- glht(result, linfct = mcp(trt = &quot;Dunnett&quot;)) &gt; summary(dunnett) Simultaneous Tests for General Linear Hypotheses Multiple Comparisons of Means: Dunnett Contrasts Fit: aov(formula = response ~ trt, data = cholesterol) Linear Hypotheses: Estimate Std. Error t value Pr(&gt;|t|) 2times - 1time == 0 3.443 1.443 2.385 0.07 . 4times - 1time == 0 6.593 1.443 4.568 &lt;0.001 *** drugD - 1time == 0 9.579 1.443 6.637 &lt;0.001 *** drugE - 1time == 0 15.166 1.443 10.507 &lt;0.001 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Adjusted p values reported -- single-step method) 13.2 이원분류 분산 분석 반응변수에 영향을 미치는 요인이 두 개인 경우에는 이원분류 분산 분석을 한다. 요인이 세 개 이상인 경우에도 분산 분석을 수행할 수 있다. 그러나 분석해야 할 요인들이 많아지면 선형회귀모형으로 분석하는 것이 더 간편하다. 13.2.1 교호작용이 없는 이원분류 분산 분석 R에서 이원분류 분산 분석은 일원분류 분산 분석과 마찬가지로 aov() 함수를 사용한다. 다만 수식의 오른편에 요인을 + 연산자로 연결하여 표현한다. 이 때 요인이 기술되는 순서가 매우 중요하다. aov(y ~ A + B) aov(y ~ B + A) 위의 수식 표현에서 두 요인이 결합된 모든 수준에서 관측 수가 동일하면 수식에 기술되는 요인의 순서는 중요하지 않다. 그러나 관측 수가 수준 별로 서로 다른 경우에는 어떤 요인을 먼저 기술하였는지가 중요하다. R에서는 ANOVA 분석을 할 때 먼저 기술된 요인의 반응변수에 미치는 효과가 제거되었을 때, 뒤에 나오는 변수가 반응변수에 미치는 효과가 있는지를 가설검정한다. 수준 별 관측 수가 동일한 경우에는 각 요인의 효과가 독립적으로 분할되므로 순서가 중요하지 않지만 그렇지 않은 경우에는 기술 순서에 주의하여야 한다. 일반적으로 가설 검정을 통해 증명하고자 하는 변수가 뒤에 기술된다. 그리고 통제 변수에 해당되는 변수가 앞에 기술된다. 예를 들어 두 약의 효과를 비교할 때 성별 차이가 발생할 수 있다. 성별 차이를 제외하고 두 약만의 효과를 보고자 한다면, 성별 변수를 통제 요인으로 먼저 기술하고 약의 종류를 두 번째 요인으로 기술한다. 다음의 예를 가지고 이원분류 분산 분석에 대하여 설명해 보자. Example 13.3 ToothGrowth 데이터는 60 마리의 쥐에게 비타민 C 추출물과 오렌지 주스의 형태로 비타민 C를 투여하여 이빨의 성장을 측정한 데이터이다. 투여량(dose)에 따른 효과를 제외하였을 때 비타민 C의 투여 방식(supp)에 따른 이빨의 성장에 차이가 있었는지에 대해 유의수준 5%에서 가설검정하시오. 먼저 ToothGrowth 데이터를 요약해 보자. 그리고 투여 방식과 처방량에 따른 이빨 성장의 평균과 데이터 개수를 확인해 보고 상자 그림으로 분포도 확인해 보자. 상자 그림을 그릴 때 투여량(dose)가 수치 변수이기 때문에 범주형 변수로 바꾸기 위해 factor() 함수를 사용하여 요인으로 변경하였다. &gt; summary(ToothGrowth) len supp dose Min. : 4.20 OJ:30 Min. :0.500 1st Qu.:13.07 VC:30 1st Qu.:0.500 Median :19.25 Median :1.000 Mean :18.81 Mean :1.167 3rd Qu.:25.27 3rd Qu.:2.000 Max. :33.90 Max. :2.000 &gt; aggregate(len ~ supp + dose, data = ToothGrowth, + function(x) c(n = length(x), mean = mean(x)) + ) supp dose len.n len.mean 1 OJ 0.5 10.00 13.23 2 VC 0.5 10.00 7.98 3 OJ 1.0 10.00 22.70 4 VC 1.0 10.00 16.77 5 OJ 2.0 10.00 26.06 6 VC 2.0 10.00 26.14 &gt; ggplot(ToothGrowth, aes(x = factor(dose), y = len, fill = supp)) + + geom_boxplot() 투여 방식과 투여량을 각각 독립적으로 일원분류 분산 분석을 해 보자. 일원분류 분산 분석으로 각 요인의 효과를 분석해 보면, 유의 수준 5% 하에 투여 방식에 따른 이빨 성장의 차이는 보이지 않았고, 투여량은 이빨 성장의 차이를 만들어 내는 효과가 있는 것으로 판단된다. &gt; result_supp &lt;- aov(len ~ supp, data = ToothGrowth) &gt; anova(result_supp) Analysis of Variance Table Response: len Df Sum Sq Mean Sq F value Pr(&gt;F) supp 1 205.4 205.35 3.6683 0.06039 . Residuals 58 3246.9 55.98 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 &gt; result_dose &lt;- aov(len ~ factor(dose), data = ToothGrowth) &gt; anova(result_dose) Analysis of Variance Table Response: len Df Sum Sq Mean Sq F value Pr(&gt;F) factor(dose) 2 2426.4 1213.2 67.416 9.533e-16 *** Residuals 57 1025.8 18.0 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 그러나 이원분류 분산 분석을 해 보면 투여량의 효과와 투여량의 차이를 통제하였을 때의 투여 방식의 효과 모두 유의미한 것으로 나타난다. 일원분류 분산 분석과 이원분류 분산 분석에서 왜 이러한 차이가 났을까? 앞의 상자 그래프에서 보듯이 투여량에 따른 효과가 투여 방식의 효과를 압도하고 있기 때문에 투여량 요인을 모형에 도입하지 않으면 투여량의 효과가 모두 잔차 효과로 나타난다. 따라서 투여 방식만을 가지고 일원분류 분산 분석을 하면 투여량의 효과가 모두 랜덤한 효과로 간주되어 투여 방식의 효과가 랜덤한 효과가 아니라고 보기 어려워진다. &gt; result_both &lt;- aov(len ~ factor(dose) + supp, data = ToothGrowth) &gt; anova(result_both) Analysis of Variance Table Response: len Df Sum Sq Mean Sq F value Pr(&gt;F) factor(dose) 2 2426.43 1213.22 82.811 &lt; 2.2e-16 *** supp 1 205.35 205.35 14.017 0.0004293 *** Residuals 56 820.43 14.65 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 앞의 예에서 보듯이 어떤 요인의 효과를 분석할 때, 영향력이 강한 다른 요인을 모형에서 제외하고 분석을 하면 잘못된 결론에 도달 할 수 있다. ToothGrowth 데이터는 각 수준의 조합별로 관측치의 수가 같으므로 사실 다음처럼 두 요인의 순서를 바꾸어도 동일한 결과가 나옴을 볼 수 있다. 그러나 관측치의 수가 다르면 동일한 결과가 나오지 않으므로 주의하여야 한다. &gt; anova(aov(len ~ supp + factor(dose), data = ToothGrowth)) Analysis of Variance Table Response: len Df Sum Sq Mean Sq F value Pr(&gt;F) supp 1 205.35 205.35 14.017 0.0004293 *** factor(dose) 2 2426.43 1213.22 82.811 &lt; 2.2e-16 *** Residuals 56 820.43 14.65 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 13.2.2 교호작용이 있는 이원분류 분산 분석 많은 경우 두 요인의 효과가 서로 독립적이지 않고 교호 작용(interaction effects)이 있는 경우가 많다. 예를 들어 어떤 두 약 M와 N가 있을 때, 남자인 경우에는 M 약이 더 효과가 있고 여자인 경우에는 N 약이 더 효과가 있을 수 있다. 이러한 예는 성별 요인과 약의 종류라는 요인이 서로 교호 작용이 있는 경우이다. 두 요인의 교효작용이 있다는 것은 두 요인의 반응변수에 대한 효과가 서로 독립이 아니라는 것을 의미한다. 만약 교호작용이 없다고 한다면 두 요인의 반응변수에 대한 효과가 서로 독립적으로 작용한다는 것을 의미한다. R에서 교호 작용을 분석하려면 aov() 함수의 수식에 교호 작용 항을 기술하면 된다. 요인이 A와 B라면 교호작용 항은 A:B로 표현한다. 일반적으로 두 요인의 개별적인 효과를 제외하고 남은 차이에서 교호작용을 분석하기 때문에 교호작용 항을 수식에서 맨 나중에 기술한다. R의 수식에서 두 변수와 두 변수의 교호작용을 모두 기술할 때는 A*B 형식으로 기술할 수 있다. 이 경우에도 순서가 중요한데 먼저 기술된 변수의 효과가 먼저 분석되고, 그 변수가 통제된 후 뒤에 나오는 변수의 효과가 분석되고, 마지막으로 두 변수의 교호작용 항의 효과가 분석된다. aov(y ~ A + B + A:B) aov(y ~ A*B) Example 13.4 ToothGrowth 데이터는 60 마리의 쥐에게 비타민 C 추출물과 오렌지 주스의 형태로 비타민 C를 투여하여 이빨의 성장을 측정한 데이터이다. 투여량(dose)과 비타민 C의 투여 방식(supp)에 따른 이빨의 성장의 차이를 통제하였을 때, 투여량과 투여 방식의 교호작용 효과가 있었는지에 대해 유의수준 5%에서 가설검정하시오. Example 13.4의 교호작용에 대한 가설검정은 다음과 같이 수행한다. &gt; result_int &lt;- aov(len ~ factor(dose) * supp, data = ToothGrowth) &gt; anova(result_int) Analysis of Variance Table Response: len Df Sum Sq Mean Sq F value Pr(&gt;F) factor(dose) 2 2426.43 1213.22 92.000 &lt; 2.2e-16 *** supp 1 205.35 205.35 15.572 0.0002312 *** factor(dose):supp 2 108.32 54.16 4.107 0.0218603 * Residuals 54 712.11 13.19 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ANOVA 분석 결과 유의수준 5% 하에서 교호작용의 유의미한 효과가 있었다. 교호작용 요소 중에 어떤 요소가 주로 효과가 있었는지를 확인하려면 interaction.plot 함수를 사용하여 두 요인의 교호작용을 시각화해 볼 수 있다. interaction.plot의 첫 번째 인수는 가로축에 표시될 요인 변수가, 두 번째 인수는 교호작용에 참여하는 다른 요인 변수가, 세 번째 인수는 반응변수가 정의된다. &gt; with(ToothGrowth, interaction.plot(factor(dose), supp, len)) 교효작용 도표는 교호작용이 없다면 첫 번째 요인의 수준 별로 두 번째 요인의 효과의 차이가 유지된다. 만약 선분에서 차이가 유지되지 않거나 교차한다면 교호작용이 있는 것이다. 다음 교호작용 그림은 VC와 OJ라는 supp에 따른 효과가 dose에 따라 다르게 나타남을 보여준다. 투여량이 작을수록 비타민 C 추출물보다는 오렌지 주스를 사용하여 투여하는 방법이 이빨의 성장에 더 효과적이었음을 볼 수 있다. 그러나 투여량이 2가 되면 두 방법의 차이는 거의 없었음을 볼 수 있다. 마지막으로 ANOVA 분석의 정규성과 등분산성을 만족하는지 검토해 보자. 등분산 검정을 위해 R의 기본 interaction() 함수를 사용하여 supp와 dose를 합친 요인을 새로 만들었다. bartlett.test()는 오직 한 요인에 대해서만 등분산을 검정하므로 두 요인을 합친 새로운 요인으로 등분산성을 검정한다. &gt; plot(result_int, which = 1:3) &gt; shapiro.test(result_int$residuals) Shapiro-Wilk normality test data: result_int$residuals W = 0.98499, p-value = 0.6694 &gt; bartlett.test(len ~ interaction(supp, dose), data = ToothGrowth) Bartlett test of homogeneity of variances data: len by interaction(supp, dose) Bartlett&#39;s K-squared = 6.9273, df = 5, p-value = 0.2261 13.3 공분산 분석 분산 분석을 할 때 반응변수에 크게 영향을 주는 수치형 변수가 있을 수 있다. 이 경우 수치형 변수의 효과를 통제한 후 요인에 대한 분산 분석을 수행하는 것이 좋다. 이런 식으로 수치형 변수의 효과를 제외하고 요인의 효과를 분석하는 방법을 공분산 분석(ANalysis of COVAriance; ANCOVA)라고 한다. 그리고 분석에 들어가는 수치형 변수를 공변인(covariate)라고 부른다. R에서 공분산 분석을 하는 방법은 aov() 함수의 수식의 우변항에 수치형 변수를 넣어주면 된다. 이 때 주의할 것은 공변인을 요인보다 먼저 수식에 기술해야 한다는 것이다. 그래야 공변인의 효과가 제외하였을 때의 요인의 반응변수에 대한 효과를 검정할 수 있다. Example 13.5 ggplot2 패키지의 diamonds 데이터에서 로그 변환한 다이아몬드 가격(price)에 대한 다이아몬드 투명도(clarity)의 효과를 검정하려고 한다. 로그 변환된 다이아몬드 중량(carat)의 효과를 제외했을 때, 다이아몬드 투명도가 다이아몬드 로그 가격에 영향을 미치는지 유의수준 5%에서 가설검정하시오. 8.2.5 절에서 다이아몬드의 가격이 중량에 영향을 많이 받기 때문에 투명도의 효과를 정확하게 확인하기 어려웠다. 공분산 분석을 하면 수치형 변수의 영향력을 제외하고 범주형 변수의 효과를 살펴볼 수 있다. &gt; set.seed(123) &gt; diamonds_sample &lt;- sample_frac(diamonds, size = 0.05) &gt; result &lt;- aov(log(price) ~ log(carat) + clarity, data = diamonds_sample) &gt; anova(result) Analysis of Variance Table Response: log(price) Df Sum Sq Mean Sq F value Pr(&gt;F) log(carat) 1 2622.67 2622.67 77756.29 &lt; 2.2e-16 *** clarity 7 83.37 11.91 353.11 &lt; 2.2e-16 *** Residuals 2688 90.66 0.03 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 만약 중량과 투명도의 교호작용의 효과도 같이 보기를 원하면 다음처럼 분석하면 된다. &gt; result &lt;- aov(log(price) ~ log(carat) * clarity, data = diamonds_sample) &gt; anova(result) Analysis of Variance Table Response: log(price) Df Sum Sq Mean Sq F value Pr(&gt;F) log(carat) 1 2622.67 2622.67 78194.5897 &lt; 2e-16 *** clarity 7 83.37 11.91 355.0997 &lt; 2e-16 *** log(carat):clarity 7 0.74 0.11 3.1646 0.00246 ** Residuals 2681 89.92 0.03 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 그리고 다음처럼 중량과 투명도 효과를 제외했을 때 다이아몬드의 가공품질(cut)의 가격 결정 효과가 있는지도 가설검정할 수 있다. &gt; result &lt;- aov(log(price) ~ log(carat) + clarity + cut, data = diamonds_sample) &gt; anova(result) Analysis of Variance Table Response: log(price) Df Sum Sq Mean Sq F value Pr(&gt;F) log(carat) 1 2622.67 2622.67 79452.447 &lt; 2.2e-16 *** clarity 7 83.37 11.91 360.812 &lt; 2.2e-16 *** cut 4 2.07 0.52 15.659 1.135e-12 *** Residuals 2684 88.60 0.03 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 마지막으로 분산 분석과 공분산 분석 모두 선형회귀 모형을 사용하여 분석될 수 있다. &gt; result &lt;- lm(log(price) ~ log(carat) * clarity, data = diamonds_sample) &gt; anova(result) Analysis of Variance Table Response: log(price) Df Sum Sq Mean Sq F value Pr(&gt;F) log(carat) 1 2622.67 2622.67 78194.5897 &lt; 2e-16 *** clarity 7 83.37 11.91 355.0997 &lt; 2e-16 *** log(carat):clarity 7 0.74 0.11 3.1646 0.00246 ** Residuals 2681 89.92 0.03 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
